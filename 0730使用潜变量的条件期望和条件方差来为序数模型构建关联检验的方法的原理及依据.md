fit_ordinal_null_model 的原理是通过**潜变量模型**，将一个无法直接分析的序数表型问题，巧妙地**转化**成了一个等价的、具有**数值化残差和权重**的问题。然后，它将这个转化的结果**包装**成一个STAAR认识的标准glmmkin对象格式。

我们来详细拆解条件期望的计算方法及其背后的理论依据。

---

### **理论依据：截断正态分布**

这个计算的理论基础是**截断分布的矩（moments of a truncated distribution）**。

让我们回到潜变量模型：

`Y* = Xβ + ε`

其中，`ε ~ N(0, 1)`（假设是probit链接，所以残差服从标准正态分布）。

对于一个特定的样本`i`，我们已经通过`clm`模型得到了它的线性预测值 `ηᵢ = Xᵢβ`。我们观察到它的表型是等级 `k`。这意味着它的潜变量 `Y*` 落在了某个区间内：

`θ_{k-1} < Y* ≤ θ_k`

将 `Y* = ηᵢ + εᵢ` 代入，我们得到：

`θ_{k-1} < ηᵢ + εᵢ ≤ θ_k`

整理一下，这就给出了关于残差 `εᵢ` 的一个不等式：

`θ_{k-1} - ηᵢ < εᵢ ≤ θ_k - ηᵢ`

我们令 `aᵢ = θ_{k-1} - ηᵢ` 和 `bᵢ = θ_k - ηᵢ`。那么，对于这个样本 `i`，我们知道它的残差 `εᵢ` 是从一个标准正态分布中抽出的，但它被**截断（truncated）在了区间 `(aᵢ, bᵢ]` 内。

**我们的目标就是计算这个被截断在`(aᵢ, bᵢ]`区间内的随机变量 `εᵢ` 的期望值和方差。**

---

### **条件期望的计算步骤**

我们想要求 `E[ε | a < ε ≤ b]`，其中 `ε` 服从标准正态分布 `N(0, 1)`。

设 `φ(z)` 为标准正态分布的**概率密度函数 (PDF)**，`Φ(z)` 为其**累积分布函数 (CDF)**。

#### **1. 截断分布的概率密度函数 (PDF)**

首先，一个随机变量 `ε` 被截断在 `(a, b]` 区间内的概率是 `P(a < ε ≤ b) = Φ(b) - Φ(a)`。

根据条件概率的定义，在这个区间内的条件PDF，我们称之为 `f_T(z)`，是：

`f_T(z) = φ(z) / (Φ(b) - Φ(a))`  对于 `a < z ≤ b`
`f_T(z) = 0`                      对于其他 `z`

#### **2. 计算条件期望 `E[ε | a < ε ≤ b]`**

根据期望的定义，我们需要计算积分 `∫ z * f_T(z) dz`：

`E[ε | a < ε ≤ b] = ∫[a, b] z * [φ(z) / (Φ(b) - Φ(a))] dz`
`= (1 / (Φ(b) - Φ(a))) * ∫[a, b] z * φ(z) dz`

现在，关键在于求解积分 `∫ z * φ(z) dz`。我们知道 `φ(z) = (1/sqrt(2π)) * exp(-z²/2)`。
注意到 `d(φ(z))/dz = -z * φ(z)`。
所以，`∫ z * φ(z) dz = -φ(z)`。

将这个结果代入定积分：
`∫[a, b] z * φ(z) dz = [-φ(z)]` 从 `a` 到 `b`
`= -φ(b) - (-φ(a))`
`= φ(a) - φ(b)`

最后，把这个积分结果代回到期望的公式中，我们就得到了最终的计算公式：

**`E[ε | a < ε ≤ b] = (φ(a) - φ(b)) / (Φ(b) - Φ(a))`**

这正是代码中 `residuals <- (phi_a - phi_b) / prob_in_interval` 这一行的数学原理。

*   `phi_a` 和 `phi_b` 分别是 `φ(a)` 和 `φ(b)`。
*   `prob_in_interval` 是 `Φ(b) - Φ(a)`。

#### **3. 计算条件方差 `Var(ε | a < ε ≤ b]` (用于计算权重)**

计算方差稍微复杂一点，它需要用到二阶矩 `E[ε² | a < ε ≤ b]`。
公式是：`Var(ε) = E[ε²] - (E[ε])²`。

我们需要计算 `E[ε² | a < ε ≤ b] = ∫[a, b] z² * f_T(z) dz`。

这个积分的求解需要用到分部积分法，并且利用 `d(z*φ(z))/dz = φ(z) - z²*φ(z)` 这个关系。最终可以得到：

`∫[a, b] z² * φ(z) dz = [Φ(z) - z*φ(z)]` 从 `a` 到 `b`
`= (Φ(b) - b*φ(b)) - (Φ(a) - a*φ(a))`
`= (Φ(b) - Φ(a)) - (b*φ(b) - a*φ(a))`

所以，二阶矩为：
`E[ε² | a < ε ≤ b] = 1 - (b*φ(b) - a*φ(a)) / (Φ(b) - Φ(a))`

现在，我们可以计算条件方差了：
`Var(ε | a < ε ≤ b) = E[ε²] - (E[ε])²`
`= [1 - (b*φ(b) - a*φ(a)) / (Φ(b) - Φ(a))] - [(φ(a) - φ(b)) / (Φ(b) - Φ(a))]²`

在 `fit_ordinal_null_model` 代码中，这个计算过程是这样的：

*   `term1 <- (lower_bounds_eps * phi_a - upper_bounds_eps * phi_b) / prob_in_interval`
    *   这里有一个小小的符号差异，但本质是一样的。`aφ(a) - bφ(b)` 对应 `lower_bounds_eps * phi_a - upper_bounds_eps * phi_b`。
*   `var_y <- var_dist + term1 - residuals^2`
    *   `var_dist` 是原始未截断分布的方差（对于标准正态分布是1）。
    *   `term1` 对应 `(aφ(a) - bφ(b)) / (Φ(b) - Φ(a))`。
    *   `residuals^2` 就是 `(E[ε])²`。
    *   所以 `var_dist + term1` 就对应 `1 + (aφ(a) - bφ(b)) / (Φ(b) - Φ(a))`，这正好是 `E[ε²]`。
    *   因此，`var_y` 就是 `E[ε²] - (E[ε])²`，即条件方差。

---

### **总结：从理论到代码**

| 理论概念 | 数学公式 | `fit_ordinal_null_model` 中的代码 |
| :--- | :--- | :--- |
| **残差截断下界 `a`** | `θ_{k-1} - η` | `lower_bounds_eps` |
| **残差截断上界 `b`** | `θ_k - η` | `upper_bounds_eps` |
| **截断区间的概率** | `Φ(b) - Φ(a)` | `prob_in_interval = Phi_b - Phi_a` |
| **条件期望 (新残差)** | `(φ(a) - φ(b)) / (Φ(b) - Φ(a))` | `residuals = (phi_a - phi_b) / prob_in_interval` |
| **条件方差 (新权重的倒数)** | `1 + (aφ(a) - bφ(b))/(Φ(b)-Φ(a)) - E[ε]²` | `var_y = var_dist + term1 - residuals^2` |
| **权重** | `1 / Var(ε | ...)` | `weights_squared = 1 / var_y` |

因此，`fit_ordinal_null_model` 的计算完全是基于**截断正态分布的矩理论**。它通过精确的数学推导，将序数模型中隐含的、不可见的潜变量残差的信息，以条件期望和条件方差的形式提取出来，从而为下游的 Score 检验提供了所需的、理论上严谨的数值化输入。



我们来详细解释为什么条件方差的倒数可以作为权重。

答案的核心在于：**使用方差的倒数作为权重，等价于执行一个“加权最小二乘法”（Weighted Least Squares, WLS），这种方法对于异方差（heteroscedasticity）数据是最优的，并且与最大似然估计（Maximum Likelihood Estimation, MLE）紧密相关。**

让我们分层次来理解：

---

### **层次一：直观理解 (Intuitive Level)**

想象你在做一个科学实验，测量了很多次数据。有些测量是在非常精密的仪器上完成的（误差小，方差小），有些是在不太稳定的条件下完成的（误差大，方差大）。当你要整合所有数据得到一个最终结论时，你会怎么做？

很自然地，你会更相信那些精密仪器测得的数据，赋予它们更高的**权重**；而对于那些误差大的数据，你会打些折扣，赋予它们较低的权重。

**方差（Variance）**正是衡量数据不确定性或误差大小的指标。
*   **方差小** -> 不确定性低 -> 信息量高 -> **权重应该大**。
*   **方差大** -> 不确定性高 -> 信息量低 -> **权重应该小**。

**方差的倒数 `1/Var`** 正好完美地满足了这个反比关系。所以，使用方差的倒数作为权重，在直觉上是完全合理的。

---

### **层次二：加权最小二乘法 (WLS) 的视角**

标准的线性回归（普通最小二乘法, OLS）有一个基本假设：所有观测的残差方差都是相等的，即**同方差性（homoscedasticity）**。它的目标是最小化残差平方和（Residual Sum of Squares, RSS）：

`RSS_OLS = Σ (yᵢ - Xᵢβ)²`

然而，在我们的 `fit_ordinal_null_model` 中，我们计算出的条件方差 `var_y` 对于每个样本是**不同**的。这意味着数据是**异方差（heteroscedastic）**的。直接使用OLS是不高效的。

这时就需要**加权最小二乘法 (WLS)**。WLS的目标是最小化**加权的**残差平方和：

`RSS_WLS = Σ wᵢ * (yᵢ - Xᵢβ)²`

为了让WLS得到最优（即方差最小）的估计量，理论证明，最佳的权重 `wᵢ` 应该是**残差方差的倒数**：

`wᵢ = 1 / Var(εᵢ) = 1 / σᵢ²`

为什么呢？我们可以通过一个简单的变换来理解。如果我们用 `sqrt(wᵢ)` 去乘以模型的两边：

`sqrt(wᵢ) * yᵢ = sqrt(wᵢ) * Xᵢβ + sqrt(wᵢ) * εᵢ`

令 `y* = sqrt(wᵢ) * yᵢ`， `X* = sqrt(wᵢ) * Xᵢ`， `ε* = sqrt(wᵢ) * εᵢ`。
新模型的残差 `ε*` 的方差是：
`Var(ε*ᵢ) = Var(sqrt(wᵢ) * εᵢ) = wᵢ * Var(εᵢ) = (1 / σᵢ²) * σᵢ² = 1`

看！通过这个变换，我们把一个异方差的模型变成了一个**同方差**（方差恒为1）的模型。现在，我们对这个新模型使用普通最小二乘法，其目标是最小化 `Σ (ε*ᵢ)²`，也就是：

`Σ (sqrt(wᵢ) * (yᵢ - Xᵢβ))² = Σ wᵢ * (yᵢ - Xᵢβ)²`

这正是WLS的目标函数。因此，**使用方差的倒数作为权重，本质上是将异方差问题转换为一个标准的同方差问题，从而得到最有效（BLUE - Best Linear Unbiased Estimator）的估计。**

---

### **层次三：Score检验和信息矩阵的视角 (最理论的层面)**

在 `fit_ordinal_null_model` 中，我们最终的目标是服务于STAAR的**Score检验**。Score检验的统计量通常形式如下：

`U = (∂l/∂β_G)' * [I(β)]⁻¹ * (∂l/∂β_G)`

其中：
*   `∂l/∂β_G` 是对数似然函数 `l` 对基因效应 `β_G` 的一阶导数（也叫Score函数）。
*   `I(β)` 是**费雪信息矩阵（Fisher Information Matrix）**。

在广义线性模型（GLM）的框架下，对于一个样本 `i`，其对数似然的贡献是：
`lᵢ = (yᵢθᵢ - b(θᵢ)) / a(φ) + c(yᵢ, φ)`

经过推导可以证明，Score函数（对基因效应 `g` 求导）可以写成：
`∂l/∂β_g = Σ (yᵢ - μᵢ) * gᵢ / Var(yᵢ)`

而Score检验的方差（也就是信息矩阵的逆的相应元素）与 `gᵢ² / Var(yᵢ)` 成正比。

这里的 `1 / Var(yᵢ)` 就是我们所说的权重！

**费雪信息量**的直观意义是“一次观测所能提供的关于未知参数的信息量的大小”。方差越大，不确定性越高，提供的信息量就越小。费雪信息量正好与方差成反比。

在STAAR的Score检验公式 `U = G' * W * (Y - μ)` 中：
*   `(Y - μ)` 是残差。
*   `W` 是一个对角矩阵，其对角线元素就是**权重 `wᵢ`**。
*   这个权重 `W` 正是来自信息矩阵。对于GLM，这个权重矩阵的对角元就是 `1 / Var(yᵢ)`。

因此，**在Score检验的理论框架下，使用条件方差的倒数作为权重，并不仅仅是一种启发式的选择，而是从最大似然理论和信息矩阵中直接推导出来的必然结果。它确保了检验统计量具有正确的分布和最优的统计功效。**

---

### **总结**

将条件方差的倒数作为权重，是基于以下层层递进的理由：

1.  **直观上**：它赋予信息量高（方差小）的观测更大的影响力。
2.  **在WLS模型中**：这是将异方差数据转换为同方差数据的标准方法，能得到最优的参数估计。
3.  **在Score检验理论中**：这个权重直接来源于费雪信息矩阵，是构建具有最佳统计特性的检验统计量的理论要求。

`fit_ordinal_null_model` 正是遵循了这一深刻的统计学原理，通过计算每个观测的条件方差并取其倒数作为权重，为STAAR提供了一个理论上严谨、统计上高效的零模型。




---

### **指数分布族 (Exponential Dispersion Family)**

这个家族包含了很多我们熟知的概率分布，比如正态分布、二项分布、泊松分布、伽马分布等等。

一个分布如果属于指数分布族，它的概率密度函数（或概率质量函数）`f(y)` 都可以被写成一种标准形式：

`f(y | θ, φ) = exp[ (yθ - b(θ)) / a(φ) + c(y, φ) ]`

取个对数，就得到了我们讨论的**对数似然函数** `lᵢ` 的形式：

`lᵢ = (yᵢθᵢ - b(θᵢ)) / a(φ) + c(yᵢ, φ)`

---


