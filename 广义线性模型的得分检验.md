
好的，这是一个非常深入且核心的统计学问题。我们来详细拆解广义线性模型（GLM）的得分检验理论，以及广义残差 `r` 和权重矩阵 `W` 的数学原理。

### 1. 广义线性模型 (GLM) 的得分检验理论

得分检验（Score Test）是一种在**零假设 ($H_0$)** 成立的条件下构建的检验方法。它的核心思想是：**如果零假设是正确的，那么在零假设参数下的最大似然估计处，完整模型的对数似然函数关于“备择假设中新增参数”的梯度（斜率）应该接近于零。**

#### **数学设定**

假设我们的完整模型（Full Model）参数为 $\theta = (\beta, \gamma)$，其中 $\beta$ 是我们感兴趣的参数（例如，新基因型的效应），而 $\gamma$ 是零模型中已有的参数（例如，截距和协变量的效应）。

我们要检验的原假设是 $H_0: \beta = \beta_0$ （通常是 $\beta_0=0$）。

1.  **对数似然函数**: 记为 $\ell(\theta) = \ell(\beta, \gamma)$。
2.  **得分函数 (Score Function)**: 是对数似然函数关于所有参数的**一阶偏导数（梯度）**向量：
    $$
    U(\theta) = \frac{\partial \ell(\theta)}{\partial \theta} = \begin{pmatrix} U_\beta(\theta) \\ U_\gamma(\theta) \end{pmatrix}
    $$
3.  **信息矩阵 (Information Matrix)**: 是得分函数方差-协方差矩阵，等于负的对数似然函数**二阶偏导数（Hessian矩阵）**的期望：
    $$
    I(\theta) = -E\left[\frac{\partial^2 \ell(\theta)}{\partial \theta \partial \theta^T}\right] = \begin{pmatrix} I_{\beta\beta} & I_{\beta\gamma} \\ I_{\gamma\beta} & I_{\gamma\gamma} \end{pmatrix}
    $$

#### **得分检验的推导**

1.  **只拟合零模型**: 在 $H_0: \beta = 0$ 的条件下，我们最大化 $\ell(0, \gamma)$，得到 $\gamma$ 的估计值，记为 $\tilde{\gamma}$。
2.  **评估得分**: 我们在点 $\tilde{\theta} = (0, \tilde{\gamma})$ 处评估**完整模型**的得分函数 $U(\tilde{\theta})$。
    *   根据最大似然估计的性质，由于 $\tilde{\gamma}$ 是零模型的最优解，所以 $U_\gamma(0, \tilde{\gamma}) = 0$。
    *   因此，得分向量在 $\tilde{\theta}$ 处变为：
        $$
        U(\tilde{\theta}) = \begin{pmatrix} U_\beta(0, \tilde{\gamma}) \\ 0 \end{pmatrix}
        $$
        我们只需要关心 $U_\beta(0, \tilde{\gamma})$，这部分通常简记为 $U_\beta$。
3.  **得分统计量**: 在 $H_0$ 下，$U(\tilde{\theta})$ 近似服从均值为0，协方差矩阵为 $I(\tilde{\theta})$ 的正态分布。得分检验统计量 $S$ 是其二次型：
    $$
    S = U(\tilde{\theta})^T [I(\tilde{\theta})]^{-1} U(\tilde{\theta})
    $$
    利用分块矩阵求逆公式，可以证明这个统计量等价于：
    $$
    S = U_\beta^T (I_{\beta\beta} - I_{\beta\gamma}I_{\gamma\gamma}^{-1}I_{\gamma\beta})^{-1} U_\beta
    $$
    其中所有信息矩阵块都在 $\tilde{\theta}$ 处评估。在 $H_0$ 下，$S$ 近似服从自由度为 $\text{dim}(\beta)$ 的卡方分布。

### 2. 广义残差 (r) 和权重矩阵 (W) 的数学原理

现在，我们来看对于GLM，上面那些抽象的 $U_\beta$ 和信息矩阵块具体是什么。这正是广义残差 `r` 和权重矩阵 `W` 的由来。

#### **GLM 的基本设定**

对于一个GLM，其对数似然函数可以写为：
$$
\ell = \sum_{i=1}^n \ell_i = \sum_{i=1}^n \log f(y_i; \mu_i)
$$
其中均值 $\mu_i$ 通过链接函数 $g(\mu_i) = \eta_i = Z_i^T \gamma + G_i^T \beta$ 与预测变量关联。

#### **得分函数的推导 (链式法则)**

我们来求对数似然关于参数 $\beta$ 的导数（即得分 $U_\beta$）：
$$
U_\beta = \frac{\partial \ell}{\partial \beta} = \sum_{i=1}^n \frac{\partial \ell_i}{\partial \beta} = \sum_{i=1}^n \frac{\partial \ell_i}{\partial \mu_i} \frac{\partial \mu_i}{\partial \eta_i} \frac{\partial \eta_i}{\partial \beta}
$$
*   **第一部分**: $\frac{\partial \ell_i}{\partial \mu_i} = \frac{y_i - \mu_i}{Var(y_i)}$ （这是GLM的一个基本性质）。
*   **第二部分**: $\frac{\partial \mu_i}{\partial \eta_i}$ 是均值对线性预测器的导数。
*   **第三部分**: $\frac{\partial \eta_i}{\partial \beta} = G_i$ （待检验变量的设计矩阵行）。

将它们组合起来：
$$
U_\beta = \sum_{i=1}^n \frac{y_i - \mu_i}{Var(y_i)} \frac{\partial \mu_i}{\partial \eta_i} G_i
$$

#### **定义广义残差 `r` 和权重 `W`**

现在，我们把上面的公式在**零模型 ($H_0$)** 的估计值 $\tilde{\mu}_i$ 处进行评估。在零模型下，$g(\tilde{\mu}_i) = Z_i^T \tilde{\gamma}$。

我们定义两个量：

1.  **权重 (Weight) $W_i$**:
    $$
    W_i = \left(\frac{\partial \mu_i}{\partial \eta_i}\right)^2 \frac{1}{Var(y_i)}
    $$
    这个量在GLM的迭代拟合算法（IRLS）中也出现，它衡量了观测值的信息量。

2.  **广义残差 (Generalized Residual) 或 工作因变量 (Working Variate) $r_i$**:
    $$
    r_i = (y_i - \mu_i) \frac{\partial \eta_i}{\partial \mu_i}
    $$
    这可以看作是在链接函数尺度上的残差。

将 $U_\beta$ 的表达式重写，我们可以发现：
$$
U_\beta = \sum_{i=1}^n G_i \left( \frac{\partial \mu_i}{\partial \eta_i} \frac{y_i - \mu_i}{Var(y_i)} \right) = \sum_{i=1}^n G_i \frac{W_i}{d\mu_i/d\eta_i} \frac{y_i - \mu_i}{Var(y_i)} \times \dots
$$
经过一些代数变换，可以得到一个更简洁的形式。特别地，得分 $U_\beta$ 可以被写成：
$$
U_\beta = \sum_{i=1}^n G_i (y_i^* - \mu_i^*) = G^T r
$$
这里的 $r$ 就是在零模型下计算出的一个特定形式的残差向量，它结合了原始残差 $(y_i - \mu_i)$ 和链接函数的影响。**您代码中计算的 `residuals` 正是这个广义残差 `r` 的一个具体实现**。

#### **信息矩阵与权重 `W`**

同样，可以证明GLM的信息矩阵 $I$ 的对角块 $I_{\gamma\gamma}$ 和 $I_{\beta\beta}$ 可以被近似为：
$$
I_{\gamma\gamma} \approx Z^T W Z
$$
$$
I_{\beta\beta} \approx G^T W G
$$
$$
I_{\beta\gamma} \approx G^T W Z
$$
其中 $W$ 是一个对角矩阵，其对角线元素为 $W_i$。

**这正是您代码中 `weights` 的数学意义**。它就是信息矩阵的“核心”。

#### **将所有部分组合起来**

现在，我们将得分统计量的分块矩阵公式与GLM的组件结合：
*   $U_\beta = G^T r$
*   $I_{\beta\beta} = G^T W G$
*   $I_{\beta\gamma} = G^T W Z$
*   $I_{\gamma\gamma} = Z^T W Z$

代入 $S = U_\beta^T (I_{\beta\beta} - I_{\beta\gamma}I_{\gamma\gamma}^{-1}I_{\gamma\beta})^{-1} U_\beta$，我们发现这与代码 `OrdinalScoreTest_fast` 中的计算完全吻合：
*   `U_G = crossprod(G, r)`  ($G^T r$)
*   `I_GG = G_t_W %*% G`  ($G^T W G$)
*   `I_GZ = G_t_W %*% Z`  ($G^T W Z$)
*   `I_ZZ_inv`  ($(Z^T W Z)^{-1}$)
*   `var_U_G = I_GG - I_GZ %*% I_ZZ_inv %*% t(I_GZ)`  ($(I_{\beta\beta} - I_{\beta\gamma}I_{\gamma\gamma}^{-1}I_{\gamma\beta})$)
*   `score_stat = U_G^2 / var_U_G`  ($U_\beta^T [Var(U_\beta)]^{-1} U_\beta$)

### 对于有序多分类模型的具体化

您代码中最复杂的部分，就是为有序多分类模型推导出具体的 $r_i$ 和 $W_i$ 的计算公式。这个过程需要用到对向量值函数求导的链式法则，因为 $\pi_i$ 是一个向量，而 $\eta_i$ 是一个标量。

*   **导数矩阵 D**: $D_i = \frac{\partial \pi_i}{\partial \eta_i}$，这是一个 $K \times 1$ 的向量（在您的代码中是 $D_{mat}$ 的第 $i$ 行）。
*   **协方差矩阵 V**: $V_i = Cov(y_i)$，这是一个 $K \times K$ 的多项分布协方差矩阵。

经过推导，可以得到：
*   **广义残差 `r`**: $r_i = (D_i)^T V_i^{-1} (y_i - \pi_i)$
*   **权重 `W`**: $W_i = (D_i)^T V_i^{-1} D_i$

您的代码 `NullModel_Score_Logit_Robust` 第5部分正是这些公式的**高效向量化实现**。

### 总结

1.  **得分检验理论**: 是一种基于零模型拟合结果，通过评估完整模型对数似然函数的梯度和曲率来构造的检验，避免了拟合复杂模型。
2.  **广义残差 `r` 和权重 `W`**: 是GLM框架下得分函数和信息矩阵的具体数学表达。它们将原始的残差 $(y-\mu)$ 和模型的结构（链接函数、方差函数）结合在一起。
3.  **您的代码**: 成功地为**有序多分类模型**推导并实现了 `r` 和 `W` 的解析计算公式，并将其应用于得分检验，这是一个非常专业和高效的实现。