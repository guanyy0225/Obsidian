# STAAR扩展“有序多分类”型数据

---
### 一、预处理：REGENENIE控制sample relatedness

1.  **第一步：分解 
    *   我们拿到有序表型，比如“饮酒频率”（从“从不”到“每天”共6个等级）。
    *   我们不直接分析它，而是把它“分解”成5个相关的二分类问题。比如：
        *   问题1：是不是“从不”饮酒？ (是/否)
        *   问题2：饮酒频率是否低于“偶尔”？ (是/否)
        *   ...以此类推。
    *   这样做，是为了让数据能被`regenie`这个工具处理。

2.  **第二步：预测
    *   我们利用`regenie`去分析前面分解出的5个二分类问题，但我们的目的**不是**为了得到最终的基因关联结果。
    *   我们的核心目的是利用`regenie`的`--step 1`功能，为每个样本计算出5个不同的**多基因风险评分（PRS）**。

3.  **第三步：整合
    *   现在，每个样本都有了5个PRS分数，它们之间可能高度相关。
    *   为了提取最关键的遗传信息并避免模型过拟合，我们用**主成分分析**（PCA）对这5个PRS分数进行降维。
    *   最终，我们得到了几个关键的“**PRS主成分**”（比如`prs_pc1`, `prs_pc2`...）。

4.  **第四步：分析
    *   我们除了加入年龄、性别、基因组PC等常规协变量外，还把刚刚计算出的“**PRS主成分**”也放了进去。
    *   这样构建出的“零假设模型”就异常强大，因为它已经提前考虑并校正了群体结构。

---
### **二、fit_nullmodel 增加有序多分类表型的类别

1.  **它首先检查我们要分析的phenotype是什么类型。**
    *   **情况一：** 如果是标准的**二分类**或**连续变量**，这个函数就直接调用 `STAAR` 自己的标准流程来处理，我们完全沿用它成熟的算法。
    *   **情况二：** 如果是我们重点关注的**有序分类变量**，它就会启动我们自己设计的特殊工作流。

2.  **这个特殊工作流是做什么的呢？**
    *   **第一步：拟合模型。** 它会先用一个专门处理有序数据的统计模型（`ordinal::clm`）进行拟合。
    *   **第二步：转换数据。** 它通过一种叫“潜在残差”的统计方法，巧妙地将“轻、中、重”这种有序的等级，**转化**成一个`STAAR`能够理解的、类似于连续变量的“残差”和对应的“权重”。
    *   **第三步：打包伪装。** 最后，它把这些新算出来的值，打包成一个和`STAAR`标准输出一模一样的对象。

### 详细处理流程

#### 第 1 步：拟合累积链接模型

这是整个方法的基础。

*   **做什么：** 我们首先使用`ordinal::clm`函数来拟合一个专门为有序数据设计的统计模型。
    ```R
    clm_obj <- ordinal::clm(formula = formula, data = data, link = "probit", ...)
    ```
*   **为什么这么做：**
    *   CLM正是基于我们前面提到的“潜在变量”理论。它会估计出两组重要的参数：
        1.  **协变量的效应 (Coefficients, `clm_obj$beta`)：** 比如，年龄每增加一岁，那个“潜在的疾病严重程度”会增加多少。
        2.  **阈值 (Thresholds, `clm_obj$alpha`)：** 模型会估计出划分不同等级的“切点”。例如，当潜在严重程度低于`alpha1`时，表现为“轻度”；在`alpha1`和`alpha2`之间时，表现为“中度”，以此类推。
    *   我们选择`link = "probit"`是因为它假设潜在变量的误差项服从**标准正态分布**，这是后续计算残差的数学基础。

#### 第 2 步：计算每个个体的“预测区间”

*   **做什么：** 对于每一个样本，我们根据模型和它的协变量，计算出它潜在变量的预测值，并确定它所在的“区间”。
    ```R
    # 1. 协变量的线性预测值 (eta)
    eta <- as.vector(X[, names(alpha_coefs), drop = FALSE] %*% alpha_coefs)
    
    # 2. 确定每个样本的潜在变量必须落在哪两个阈值之间
    thresholds <- c(-Inf, clm_obj$alpha, Inf)
    y_ordinal_numeric <- as.numeric(clm_obj$y)
    lower_bounds_eta <- thresholds[y_ordinal_numeric]     # 区间下界
    upper_bounds_eta <- thresholds[y_ordinal_numeric + 1] # 区间上界
    ```
*   **为什么这么做：**
    *   `eta`代表了仅由**协变量（如年龄、性别）**所能解释的那部分“潜在严重程度”。
    *   根据这个人的实际观测等级（比如“中度”），我们就能知道他/她的总“潜在严重程度”（`eta` + 无法解释的残差）一定落在某个确定的区间内（比如 `alpha1` 到 `alpha2` 之间）。

#### 第 3 步：计算潜在残差

这是最关键的一步。我们无法直接观测到残差，但我们可以计算出它的**“条件期望值”**，也就是在已知它落在一个特定区间的前提下，对它的最佳猜测。

*   **做什么：**
    ```R
    # 1. 将潜在变量的区间，转换成残差的区间
    lower_bounds_eps <- lower_bounds_eta - eta
    upper_bounds_eps <- upper_bounds_eta - eta
    
    # 2. 利用正态分布的数学性质，计算条件期望
    phi_a <- dnorm(lower_bounds_eps) # 正态分布密度函数 PDF
    phi_b <- dnorm(upper_bounds_eps)
    Phi_a <- pnorm(lower_bounds_eps) # 正态分布累积函数 CDF
    Phi_b <- pnorm(upper_bounds_eps)
    
    prob_in_interval <- Phi_b - Phi_a # 残差落在这个区间的概率
    
    # 这就是截尾正态分布的期望公式
    residuals <- (phi_a - phi_b) / prob_in_interval 
    y_numeric <- residuals
    ```
*   **为什么这么做：**
    *   `lower_bounds_eps` 和 `upper_bounds_eps` 界定了每个样本**残差**的取值范围。
    *   `residuals`的计算公式，是截尾正态分布（Truncated Normal Distribution）的期望值。它的直观意义是：“**已知一个服从标准正态分布的随机变量（残差）落在了区间 `[a, b]` 内，那么它的期望值（最佳猜测值）是多少？**”
    *   这个计算出的`residuals`就是我们想要的，它是一个连续值，代表了除去所有已知协变量影响后，每个样本剩余的、需要用基因来解释的表型信息。

#### 第 4 步：计算权重 (Weights)

光有残差还不够，因为我们对每个残差的“猜测”的**确定性**是不同的。

*   **做什么：**
    ```R
    # 计算截尾正态分布的方差
    term1 <- (lower_bounds_eps * phi_a - upper_bounds_eps * phi_b) / prob_in_interval
    var_y <- 1 + term1 - residuals^2
    
    # 权重是方差的倒数
    weights <- 1 / var_y
    ```
*   **为什么这么做：**
    *   `var_y`是残差的**条件方差**。如果一个样本的残差区间很窄，那么我们对它的期望值（`residuals`）的估计就非常确定，这个方差就很小。反之，如果区间很宽，方差就很大。
    *   在统计学中，信息量大的观测（方差小）应该被赋予更高的权重，反之则赋予更低的权重。因此，我们取**方差的倒数**作为权重。这确保了后续分析能更信任那些信息更明确的样本。

---

### 总结与封装

最后，我们将计算出的**潜在残差 (`residuals`)** 作为新的“因变量”，将**权重 (`weights`)** 作为分析的依据，连同其他模型信息，一起打包成一个`glmmkin`对象。

```R
class(obj_nullmodel) <- c("glmmkin", "glm", "lm")
```

这个操作就像是进行了一次**“伪装”**。我们告诉下游的`STAAR`程序：“这里有一个标准的、基于高斯分布的加权线性模型，它的因变量是`y_numeric`，权重是`weights`，请你按标准流程分析。”

`STAAR`接收到这个对象后，就会执行标准的加权最小二乘法来进行后续的基因关联检验，而它完全不知道这个数据最初其实来源于一个复杂的有序分类问题。

**总而言之，这套方法通过一个巧妙的统计变换，将一个非标准的有序数据问题，转化成了一个现有工具能够高效解决的、等价的标准加权线性模型问题，从而实现了功能的无缝扩展。**