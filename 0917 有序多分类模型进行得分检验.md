把得分检验需要的组件放在Ordinal_exactScore 函数里

## 有序多分类模型中得分检验的原理

### 核心概念回顾

#### 1. 有序多分类模型（比例优势模型）
该模型用于因变量是有序类别（如：差、中、好；轻度、中度、重度）的情况。其核心公式是：
$$ \text{logit} [P(Y \le j)] = \log \left( \frac{P(Y \le j)}{1 - P(Y \le j)} \right) = \alpha_j - \boldsymbol{\beta}^T \mathbf{X} $$
其中：
*   $Y$ 是有序的因变量，有 $J$ 个类别。
*   $j$ 是类别，$j = 1, 2, ..., J-1$。
*   $P(Y \le j)$ 是观测值属于类别 $j$ 或更低类别的累积概率。
*   $\alpha_j$ 是第 $j$ 个类别的**截距**或**切点（cut-point）**，满足 $\alpha_1 < \alpha_2 < ... < \alpha_{J-1}$。
*   $\boldsymbol{\beta}$ 是自变量 $\mathbf{X}$ 的**系数向量**。关键假设是，这个 $\boldsymbol{\beta}$ 对所有的 $j$ 都是相同的，这就是“比例优势假设”。

#### 2. 得分检验（Score Test）
得分检验，也称拉格朗日乘数检验（Lagrange Multiplier Test），是与瓦尔德检验（Wald Test）和似然比检验（Likelihood Ratio Test）并列的三大经典假设检验方法。

*   **核心优势**：它**只需要拟合零假设（H₀）下的简化模型**，而不需要拟合备择假设（Hₐ）下的复杂模型。这在复杂模型难以收敛时特别有用。
*   **基本原理**：检验的核心思想是评估在零假设模型参数估计处，对数似然函数关于“被约束为零的参数”的梯度（或称得分，Score）是否显著不为零。如果梯度很陡峭，说明如果释放这个参数的约束，似然函数值会显著增加，因此我们应该拒绝零假设。

### 如何对有序多分类模型进行得分检验

得分检验最常见的用途是检验**一个或多个新自变量的系数是否显著不为零**。

#### 步骤

**假设：**
*   我们有一个已经拟合好的模型（零假设模型 H₀），包含自变量集合 $\mathbf{X}_1$。
*   我们想检验是否应该加入新的自变量集合 $\mathbf{X}_2$。

**检验的假设：**
*   **H₀**: 新增变量的系数为零 ($\boldsymbol{\beta}_2 = \mathbf{0}$)。
*   **Hₐ**: 新增变量的系数至少有一个不为零 ($\boldsymbol{\beta}_2 \neq \mathbf{0}$)。

**执行过程：**

1.  **拟合零假设模型**：
    只使用自变量 $\mathbf{X}_1$ 拟合比例优势逻辑回归模型：
    $$ \text{logit} [P(Y \le j)] = \alpha_j - \boldsymbol{\beta}_1^T \mathbf{X}_1 $$
    得到在 H₀ 下的参数最大似然估计值 $\tilde{\boldsymbol{\alpha}}$ 和 $\tilde{\boldsymbol{\beta}}_1$。

2.  **计算得分向量（Score Vector）**：
    得分向量 $U(\boldsymbol{\theta})$ 是对数似然函数 $L(\boldsymbol{\theta})$ 关于所有参数 $\boldsymbol{\theta} = (\boldsymbol{\alpha}, \boldsymbol{\beta}_1, \boldsymbol{\beta}_2)$ 的一阶偏导数。
    $$ U(\boldsymbol{\theta}) = \frac{\partial L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} $$
    我们需要计算在 H₀ 模型估计值处的得分，即 $U(\tilde{\boldsymbol{\theta}})$，其中 $\tilde{\boldsymbol{\theta}} = (\tilde{\boldsymbol{\alpha}}, \tilde{\boldsymbol{\beta}}_1, \mathbf{0})$。
    根据最大似然估计的性质，得分向量中与 $\boldsymbol{\alpha}$ 和 $\boldsymbol{\beta}_1$ 对应的部分在 $\tilde{\boldsymbol{\theta}}$ 处的值为零。因此，我们只需要关注与 $\boldsymbol{\beta}_2$ 相关的部分 $U_{\boldsymbol{\beta}_2}(\tilde{\boldsymbol{\theta}})$。

3.  **计算信息矩阵（Information Matrix）**：
    信息矩阵 $I(\boldsymbol{\theta})$ 是对数似然函数负二阶偏导数的期望值。它反映了参数估计的精度。
    $$ I(\boldsymbol{\theta}) = -E \left[ \frac{\partial^2 L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta} \partial \boldsymbol{\theta}^T} \right] $$
    同样，我们在 H₀ 模型估计值处计算信息矩阵 $I(\tilde{\boldsymbol{\theta}})$。

4.  **构建得分检验统计量**：
    得分检验统计量 $S$ 的一般形式是：
    $$ S = U(\tilde{\boldsymbol{\theta}})^T [I(\tilde{\boldsymbol{\theta}})]^{-1} U(\tilde{\boldsymbol{\theta}}) $$
    由于 $U_{\boldsymbol{\alpha}}$ 和 $U_{\boldsymbol{\beta}_1}$ 部分为零，这个公式可以简化为只涉及 $U_{\boldsymbol{\beta}_2}$ 和信息矩阵对应分块的二次型。

5.  **判断显著性**：
    在零假设 H₀ 成立的条件下，得分统计量 $S$ 近似服从**卡方分布（Chi-squared distribution）**。
    *   **自由度（df）**：等于被检验的参数个数，即自变量集合 $\mathbf{X}_2$ 中变量的数量。
    *   **决策**：计算出 $S$ 的值后，根据卡方分布和自由度计算 P 值。如果 P 值小于预设的显著性水平（如 0.05），则拒绝零假设，认为新加入的变量 $\mathbf{X}_2$ 是显著的。




## 有序多分类的几种残差

非常好的问题！估计有序多分类模型的残差是一个比线性回归复杂得多的高级话题。原因在于，模型的因变量是类别（如“满意”），而不是一个数值，所以我们无法像线性回归那样简单地用 `观测值 - 预测值` 来计算残差。

因此，研究者们提出了几种不同的方法来定义和计算有序模型的“残差”，每种方法都有其特定的用途和解释。下面我将介绍几种主流的方法，从概念到实践。

### 核心挑战

*   **观测值 (Y)** 是一个类别，例如 `k=3`（“一般”）。
*   **预测值 ($\hat{Y}$)** 是一组概率，例如 `P(Y=1)=0.1, P(Y=2)=0.3, P(Y=3)=0.4, ...`。
*   你不能计算 `“一般” - 0.4`。

我们需要找到一种合理的方式来量化模型对每个观测点的“错误程度”。

---

### 方法一：潜在变量残差 (Latent Variable Residuals)

这是**概念上最接近**线性回归残差的方法。

1.  **回顾模型**：有序模型假设存在一个不可观测的连续潜在变量 $y^*$，其模型为：
    $$
    y_i^* = \boldsymbol{\beta}' \mathbf{X}_i + \varepsilon_i
    $$
    其中，$\varepsilon_i$ 是一个遵循特定分布（通常是Logistic或正态分布）的误差项。

2.  **定义残差**：在这个潜在尺度上，残差就是这个误差项：
    $$
    \text{residual}_i = \varepsilon_i = y_i^* - \boldsymbol{\beta}' \mathbf{X}_i
    $$

3.  **问题**：我们永远无法观测到 $y_i^*$ 的真实值。我们只知道它落在了某个区间内。例如，如果观测到类别 $k$，我们只知道 $\tau_{k-1} < y_i^* \le \tau_k$。

4.  **解决方案**：我们可以估计 $y_i^*$ 在其所属区间内的**期望值**。对于观测到类别 $k$ 的样本 $i$，其潜在残差的估计值是：
    $$
    \hat{\varepsilon}_i = E[y_i^* | \tau_{k-1} < y_i^* \le \tau_k] - \boldsymbol{\beta}' \mathbf{X}_i
    $$
    这个期望值是基于被截断的Logistic（或正态）分布的均值来计算的。

*   **优点**：理论上最优雅，直接对应模型的潜在变量假设。
*   **缺点**：计算复杂，不直观，并且其分布依赖于模型的假设。
*   **用途**：主要用于理论研究和模型诊断的高级探索。

---

### 方法二：代理残差 (Surrogate Residuals) - 现代推荐方法

这是一种非常巧妙且实用的现代方法，它能将有序结果“转化”为一个连续的残差，使其性质类似于标准正态分布的残差。

**计算步骤**：
1.  对于一个真实类别为 $j$ 的观测 $i$，首先从模型中计算出两个累积概率：
    *   $a = P(Y_i < j) = P(Y_i \le j-1)$
    *   $b = P(Y_i \le j)$

2.  从区间 $[a, b]$ 上的均匀分布中随机抽取一个数值 $u_i$。
    $$
    u_i \sim \text{Uniform}(a, b)
    $$
    这个 $u_i$ 可以看作是将离散的类别“平滑”地映射到了 (0, 1) 区间上。

3.  将这个 $u_i$ 通过**标准正态分位函数**（probit link）或**标准Logit分位函数**（logit link）进行转换，得到代理残差 $r_i^S$。
    *   如果模型是序数Probit模型，则：$r_i^S = \Phi^{-1}(u_i)$
    *   如果模型是序数Logit模型，则：$r_i^S = \text{logit}(u_i) = \log\left(\frac{u_i}{1-u_i}\right)$

**核心思想**：如果模型是完美的，那么生成的 $u_i$ 序列应该服从 (0, 1) 上的标准均匀分布。经过逆CDF变换后，得到的代理残差 $r_i^S$ 应该近似服从**标准正态分布**或**标准Logistic分布**。

*   **优点**：
    *   生成的残差是连续的。
    *   如果模型拟合良好，残差分布是已知的（如标准正态分布）。
    *   可以直接用于我们熟悉的**残差诊断图**，如 Q-Q 图（检查正态性）、残差 vs. 拟合值图（检查异方差性）等。
*   **缺点**：包含随机成分，每次计算的结果会略有不同（但整体模式不变）。
*   **用途**：**强烈推荐用于实际的模型诊断和可视化**。R语言中的 `sure` 包专门用于计算这类残差。

---

### 方法三：广义残差 (Generalized Residuals)

这种方法将有序多分类模型视为广义线性模型（GLM）的扩展，并借用GLM中的残差定义。最常见的有**皮尔逊残差 (Pearson Residuals)** 和 **偏差残差 (Deviance Residuals)**。

对于有 $K$ 个类别的单个观测 $i$（其实际类别为 $j$），我们可以看作它有 $K$ 个可能的结果。
*   观测向量：$\mathbf{d}_i = (d_{i1}, d_{i2}, \dots, d_{iK})$，其中 $d_{ij}=1$，其余为0。
*   预测概率向量：$\hat{\mathbf{p}}_i = (\hat{p}_{i1}, \hat{p}_{i2}, \dots, \hat{p}_{iK})$。

1.  **皮尔逊残差**：
    对于每个类别 $k$，可以计算一个皮尔逊残差分量：
    $$
    r_{ik}^P = \frac{d_{ik} - \hat{p}_{ik}}{\sqrt{\hat{p}_{ik}}}
    $$
    一个观测点会得到一个残差向量。通常会计算一个汇总值，例如所有分量的平方和。

2.  **偏差残差**：
    偏差是衡量模型饱和度（完美拟合）与当前模型对数似然差异的指标。每个观测点的偏差残差是其对总偏差贡献的带符号平方根。
    $$
    r_i^D = \text{sign}(d_{ij} - \hat{p}_{ij}) \sqrt{2 \left| \log(\text{perfect fit likelihood}) - \log(\text{model likelihood for obs } i) \right|}
    $$
    对于多分类，其具体形式为：$r_i^D = \text{sign}(1 - \hat{p}_{ij}) \sqrt{-2 \log(\hat{p}_{ij})}$

*   **优点**：有坚实的统计理论基础（源自GLM），常用于检验模型的整体拟合优度。
*   **缺点**：对于单个观测点的解释不如代理残差直观，并且每个观测点可能是一个向量，不方便绘图。
*   **用途**：主要用于拟合优度检验（例如，所有皮尔逊残差的平方和近似服从卡方分布）。

### 总结与建议

| 残差类型 | 核心思想 | 优点 | 缺点 | 最佳用途 |
| :--- | :--- | :--- | :--- | :--- |
| **潜在变量残差** | 估计潜在连续变量 $y^*$ 上的误差项 $\varepsilon$ | 理论上最纯粹，直接关联模型假设 | 计算复杂，不直观，依赖模型假设 | 理论分析，深入的模型诊断 |
| **代理残差 (Surrogate)** | 将离散结果随机映射回连续尺度 | **易于可视化**，可直接套用标准残差图（Q-Q图等），分布已知 | 包含随机性，结果不唯一 | **日常模型诊断和可视化分析（强烈推荐）** |
| **广义残差 (Pearson/Deviance)** | 借鉴广义线性模型的思想，衡量概率偏差 | 统计理论坚实，与似然函数紧密相关 | 不直观，常为向量形式，不易于单个观测点的诊断 | 模型的整体**拟合优度检验** |

对于实践者来说，**代理残差 (Surrogate Residuals)** 是目前进行有序多分类模型残差分析和诊断的最强大、最方便的工具。它巧妙地解决了“无连续残差”的难题，让我们能够使用熟悉的图形化工具来评估模型的假设和性能。








## 得分检验不需要残差

极好的问题！您正触及到一个非常核心且普遍的误解。

简单直接的回答是：**得分检验（Score Test）的计算过程本身就不需要先估计残差。** 它是直接基于对数似然函数（Log-Likelihood Function）的导数（即得分函数）来构建的。

我们之所以常常把它和残差联系起来，是因为在线性回归这个**非常特殊且简单的模型**中，得分检验的数学形式恰好可以被简化为“检验残差与新变量的相关性”。这个特例帮助我们建立了直观的理解，但这个“残差”步骤并不是得分检验的普适定义。

### 2. 数学上的实现（为什么不需要残差）

我们用 $\ell(\boldsymbol{\beta})$ 表示包含所有变量的模型的对数似然函数。其中 $\boldsymbol{\beta}$ 包含了所有参数，包括您想检验的基因变量的系数 $\beta_{gene}$。

*   **原假设 ($H_0$)**: $\beta_{gene} = 0$。

得分检验的步骤如下：
1.  **拟合零模型**：在 $\beta_{gene} = 0$ 的约束下，最大化 $\ell(\boldsymbol{\beta})$，得到除了 $\beta_{gene}$ 之外其他所有参数的估计值，我们记为 $\tilde{\boldsymbol{\beta}}_0$。
2.  **计算得分**：计算**备择模型**的对数似然函数在 $\beta_{gene}$ 方向上的导数（得分），并代入**零模型**的估计值：
    $$ U_{gene} = \frac{\partial \ell(\boldsymbol{\beta})}{\partial \beta_{gene}} \Bigg|_{\boldsymbol{\beta}=(\tilde{\boldsymbol{\beta}}_0, \beta_{gene}=0)} $$
3.  **计算信息矩阵**：计算信息矩阵 $I(\boldsymbol{\beta})$，并代入**零模型**的估计值 $\tilde{\boldsymbol{\beta}}=(\tilde{\boldsymbol{\beta}}_0, 0)$。
4.  **构建检验统计量**：得分检验统计量（通常记为 $S$）是一个标准化的、平方后的得分值：
    $$ S = U_{gene}' [I(\tilde{\boldsymbol{\beta}})^{-1}]_{gene, gene} U_{gene} $$
    这个统计量近似服从**卡方分布**，其自由度等于新加入变量的个数（在这里是1）。

这个公式就是统计软件（如R的 `add1` 函数）在后台为您计算的内容。它直接操作对数似然函数的导数，完全绕过了残差。

### 3. “残差”的误解是从哪里来的？

这个直观但具有误导性的想法来自于**普通最小二乘法（OLS）线性回归**。在这个模型里，会发生一个美妙的巧合：

*   在线性回归模型 $y = \mathbf{X}\boldsymbol{\beta} + \varepsilon$ 中，对数似然函数关于某个新变量 $x_k$ 的系数 $\beta_k$ 的得分（一阶导数）可以被证明**正比于**：
    $$ \sum_{i=1}^{n} (y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0) \cdot x_{ik} $$
    其中，$(y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0)$ 正是**零模型的残差** $\tilde{e}_i$！
*   所以，得分检验统计量在这种情况下正比于**（零模型残差与新变量 $x_k$ 的相关系数）的平方**。

**结论**：在线性回归中，“检验得分”恰好简化成了“检验残差与新变量的相关性”。但这个简化形式并不适用于像有序逻辑回归这样更复杂的模型。对于这些模型，我们必须回到得分检验的原始定义——**基于对数似然函数的导数**。

### 总结

*   **得分检验的核心是“似然函数”**，而不是“残差”。
*   它通过评估在**零模型**的最优点上，向**备择模型**方向前进的“坡度”有多大，来判断新变量是否重要。
*   您**不需要，也不能**简单地通过计算某种残差然后看它和基因的相关性来手动完成得分检验（因为有序模型的残差形式复杂且不唯一）。
*   幸运的是，统计软件已经为您封装好了这个复杂的计算过程。当您调用类似 `add1(..., test="score")` 的函数时，它就是在后台执行上述基于导数的计算，为您提供一个可靠的卡方统计量和P值。

所以，您的思路是完全正确的，只是在实现上，我们应该信任并使用统计软件内置的、更具普适性的得分检验功能，而不是试图去手动复制线性回归中那个“残差”的特例。







## **得分统计量与**Wilcoxon-Mann-Whitney检验统计量的等价性

这是一个非常棒的问题，它触及了统计建模中一个既深刻又优美的连接点。您引用的那段话完全正确，而其背后的原因在于**得分统计量的数学结构**与**Wilcoxon-Mann-Whitney检验统计量的数学结构**，在特定条件下是完全一致的。

让我们一步步揭开这个等价关系的面纱。

### 1. 回顾两个核心概念

#### (a) Wilcoxon-Mann-Whitney (WMW) 检验

*   **核心思想**：比较两组数据的位置（中位数）是否有差异。
*   **计算基础**：**秩 (Ranks)**。它将两组数据合并排序，然后计算其中一组的**秩和 (Rank-Sum)**。
*   **检验统计量 (W)**：$W = \sum R_1$，即第一组所有观测值的秩的总和。检验时，会将这个观测到的秩和与它在零假设（两组无差异）下的期望值进行比较。

#### (b) 得分检验 (Score Test)

*   **核心思想**：检验在零假设（例如，某个系数 $\beta=0$）成立时，对数似然函数关于该系数的梯度（得分）是否显著不为零。
*   **计算基础**：**对数似然函数的一阶导数 (Score Function)**。
*   **检验统计量 (U)**：$U = \frac{\partial \ell(\boldsymbol{\theta})}{\partial \beta} \Big|_{\beta=0, \hat{\alpha}}$，其中 $\ell$ 是对数似然函数，检验是在零假设（$\beta=0$）下进行的，其他参数（如截距 $\alpha$）则使用它们在零假设下的最大似然估计值。

### 2. 揭示等价性：数学推导的直观解释

要证明两者等价，关键在于证明：**比例优势模型（Proportional Odds Model）中，用于检验组间差异的得分统计量 $U$，其数学形式可以被简化为Wilcoxon秩和统计量 $W$ 的一个线性函数。**

这个推导在McCullagh (1980) 的经典论文中有详细阐述，阿格雷斯蒂的书也引用了这一结论。下面是这个推导的直观步骤和逻辑：

#### 步骤一：写出比例优势模型的对数似然函数

对于比较两个组（用指示变量 $x_i=0$ 或 $x_i=1$ 表示）的比例优势模型，其形式为：
$$
\text{logit}[P(Y_i \le j)] = \alpha_j - \beta x_i
$$
其对数似然函数 $\ell(\alpha, \beta)$ 是基于所有观测数据的多项式概率构建的。

#### 步骤二：计算得分函数 $U$

我们需要计算对数似然函数 $\ell$ 关于我们感兴趣的参数 $\beta$ 的偏导数，并在零假设（$H_0: \beta=0$）下进行评估。
$$
U = \frac{\partial \ell}{\partial \beta} \Bigg|_{\beta=0}
$$
经过一系列复杂的求导和代数运算后，这个得分函数 $U$ 可以被简化成一个非常简洁的形式：
$$
U = \sum_{i=1}^{n} x_i (R_i - \bar{R})
$$
让我们来解读这个惊人的结果：

*   $x_i$ 是第 $i$ 个观测所属的组别（例如，1代表实验组，0代表对照组）。
*   $R_i$ 是第 $i$ 个观测在**所有合并样本**中的**平均秩 (midrank)**。
*   $\bar{R}$ 是所有观测的平均秩，即 $(n+1)/2$。

这个公式告诉我们，得分统计量 $U$ 正是**实验组 ($x_i=1$) 的所有观测的秩与其总体平均秩的离差之和**。

#### 步骤三：连接到Wilcoxon秩和统计量

现在，我们来看看Wilcoxon秩和统计量 $W$。
*   $W_1$ 是第一组（实验组，$x_i=1$）的秩和：$W_1 = \sum_{i \in \text{Group 1}} R_i$。
*   在零假设下，$W_1$ 的期望值为 $E(W_1) = n_1 \frac{n+1}{2} = n_1 \bar{R}$。

现在，我们再看一下得分统计量 $U$ 的公式：
$$
U = \sum_{i=1}^{n} x_i (R_i - \bar{R})
$$
由于 $x_i$ 只在第一组时为1，其他时候为0，所以这个求和只对第一组的成员有效：
$$
U = \sum_{i \in \text{Group 1}} (R_i - \bar{R}) = \left( \sum_{i \in \text{Group 1}} R_i \right) - \sum_{i \in \text{Group 1}} \bar{R}
$$
这可以被写作：
$$
U = W_1 - n_1 \bar{R} = W_1 - E(W_1)
$$
**这就是最终的、最核心的等价关系！**

**比例优势模型中检验组间差异的得分统计量 $U$，恰好等于Wilcoxon秩和统计量 $W_1$ 与其在零假设下期望值的差。**

由于一个统计量减去它的期望值只是一个中心化的线性变换，这并不改变其标准化后的检验结果。因此，基于 $U$ 的得分检验和基于 $W_1$ 的Wilcoxon秩和检验在数学上是**等价的**。

### 3. 为什么这个等价性如此重要？

这个发现不仅仅是一个数学巧合，它揭示了深刻的统计思想：

1.  **模型化的非参数方法**：比例优势模型可以被看作是**对WMW检验的一种模型化、参数化的推广**。WMW检验只能告诉你两组是否有差异，而比例优势模型还能告诉你差异的大小（通过 $\beta$ 的估计值），并且可以加入其他协变量进行调整。
2.  **理论的统一性**：它将看似分离的两个领域——参数模型（广义线性模型）和非参数检验（秩和检验）——完美地统一了起来。这表明，许多经典的非参数方法背后，都隐藏着一个潜在的、可以被参数化的模型。
3.  **稳健性来源的解释**：这个联系也解释了为什么比例优势模型对数据的分布具有稳健性。因为它在本质上是基于数据的**秩**来构建的，所以它继承了WMW检验对异常值和非正态分布的稳健性。

### 总结

得分检验和WMW检验之所以等价，是因为比例优势模型的对数似然函数经过求导和在零假设下简化后，其最终的数学形式**恰好是**Wilcoxon秩和统计量的中心化形式。

*   **WMW检验的核心是：(秩和 - 期望秩和)。**
*   **比例优势模型得分检验的核心也是：(秩和 - 期望秩和)。**

两者是同一枚硬币的两面。您的书中所引用的这个结论，是现代统计学中一个非常经典的例子，它展示了不同统计方法之间内在的、深刻的统一性。





## **有序多分类的得分检验与线性模型有什么不同？**

您提供的步骤非常专业和准确，完美地概述了在广义线性模型（包括有序逻辑回归）中进行得分检验（Score Test，也称为拉格朗日乘子检验，Lagrange Multiplier Test）的通用框架。

现在，我们来回答您的核心问题：**有序多分类的得分检验与线性模型有什么不同？**

答案的核心在于：**检验的理论框架是相同的，但底层的模型和数学细节完全不同。**

线性模型的得分检验（通常表现为 F 检验的特定形式）是这个通用框架在一个非常特殊且简化的场景下的应用。

下面我们从几个关键方面进行详细对比：

---

### 1. 模型结构与假设 (Model Structure & Assumptions)

*   **线性模型 (Linear Model)**:
    *   **模型方程**: $Y = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$，其中 $\boldsymbol{\epsilon} \sim N(0, \sigma^2)$。
    *   **核心假设**: 因变量是连续的，误差项服从正态分布，且方差恒定。
    *   **似然函数**: 基于**正态分布的概率密度函数**构建。其对数似然函数与残差平方和（RSS）有直接关系：$L \propto -\frac{RSS}{2\sigma^2}$。

*   **有序逻辑回归 (Ordinal Logistic Regression)**:
    *   **模型方程**: $\text{logit} [P(Y \le j)] = \alpha_j - \boldsymbol{\beta}^T \mathbf{X}$。这是一个累积概率模型。
    *   **核心假设**: 因变量是有序分类的。关键的**比例优势假设（Proportional Odds Assumption）**要求自变量 $\mathbf{X}$ 对不同类别界点的影响是相同的（即只有一个 $\boldsymbol{\beta}$ 向量，而不是每个类别界点都有一个 $\boldsymbol{\beta}_j$）。
    *   **似然函数**: 基于**多项分布（Multinomial Distribution）的概率质量函数**构建。计算每个观测值落入其真实类别的概率 $P(Y=k_i | \mathbf{X}_i)$，然后将所有观测值的对数概率相加。这个概率 $P(Y=k_i)$ 是通过两个累积概率相减得到的：$P(Y \le k_i) - P(Y \le k_i - 1)$。

**主要区别**: 线性模型处理连续数据，基于正态分布；有序逻辑回归处理有序分类数据，基于多项分布和累积 Logit 连结函数。这导致了它们的对数似然函数在形式上天差地别。

### 2. 得分向量与信息矩阵的计算 (Calculation of Score & Information)

*   **线性模型**:
    *   由于其对数似然函数与残差平方和的简单关系，其得分向量（一阶导数）和信息矩阵（负二阶导数的期望）有非常简洁的**封闭解（closed-form solution）**。
    *   例如，在检验 $\boldsymbol{\beta}_2 = \mathbf{0}$ 时，得分向量与新变量 $\mathbf{X}_2$ 和零假设模型（只用 $\mathbf{X}_1$）的**残差**相关。信息矩阵与 $\mathbf{X}^T\mathbf{X}$ 和误差方差 $\sigma^2$ 有关。
    *   整个计算可以简化为矩阵代数运算，不涉及迭代。

*   **有序逻辑回归**:
    *   其对数似然函数非常复杂，涉及到对率函数（logistic function）的导数。
    *   得分向量和信息矩阵的计算**没有简单的封闭解**。它们是关于所有观测值和所有类别概率的复杂求和。
    *   计算这些导数需要用到链式法则，涉及到每个观测值属于每个类别的概率，这些概率本身又是模型参数的非线性函数。
    *   在实践中，这些值是通过数值方法在 H₀ 模型的最大似然估计值处计算得到的。

**主要区别**: 线性模型的计算是直接且解析的。有序模型的计算是复杂的、非线性的，并且依赖于在零模型参数估计值处的数值评估。

### 3. 检验统计量 (The Test Statistic)

*   **线性模型**:
    *   通用的得分统计量 $S = U^T I^{-1} U$ 依然适用。
    *   但更常见的是，这个检验可以直接用**残差平方和 (RSS)** 来表示，并最终化简为我们熟悉的 **F 检验** 统计量：
        $$ F = \frac{(RSS_0 - RSS_A) / q}{RSS_A / (n-p)} $$
        其中 $RSS_0$ 是零假设模型（小模型）的残差平方和，$RSS_A$ 是备择假设模型（大模型）的残差平方和，$q$ 是新增变量的个数。
    *   注意：虽然 F 检验通常通过比较两个模型的 RSS 来计算（这看起来更像似然比检验），但它可以被证明与得分检验和瓦尔德检验在代数上是等价的（在特定形式下）。

*   **有序逻辑回归**:
    *   我们**必须**使用通用的二次型公式 $S = U_{\boldsymbol{\beta}_2}^T [I(\tilde{\boldsymbol{\theta}})]^{-1}_{\boldsymbol{\beta}_2 \boldsymbol{\beta}_2} U_{\boldsymbol{\beta}_2}$（这里使用更精确的分块矩阵形式）。
    *   没有像“残差平方和”这样简单的替代品。检验完全依赖于对数似然函数的导数。

**主要区别**: 线性模型的得分检验可以等价地表示为更直观的 F 检验。有序逻辑回归没有这种简化，必须严格按照得分检验的定义进行计算。

### 4. 统计量的分布 (Distribution of the Statistic)

*   **线性模型**:
    *   在误差项服从正态分布的假设下，F 检验统计量在零假设下服从**精确的 F 分布**。这是一个小样本性质，不依赖于样本量 $n \to \infty$。

*   **有序逻辑回归**:
    *   得分统计量 $S$ 在零假设下**渐近服从（asymptotically follows）卡方分布**，自由度为新增变量的个数。
    *   “渐近”意味着这个结论只在大样本情况下才比较准确。对于小样本，卡方分布只是一个近似。

**主要区别**: 线性模型的 F 检验具有精确的有限样本分布。有序模型的得分检验依赖于大样本理论，其卡方分布是一个近似。

### 总结表格

| 特征 | 线性模型 (Score/F Test) | 有序逻辑回归 (Score Test) |
| :--- | :--- | :--- |
| **模型基础** | 正态分布，连续因变量 | 多项分布，有序分类因变量 |
| **核心假设** | 误差正态、独立、同方差 | 比例优势假设 |
| **对数似然函数** | 基于正态 PDF，与残差平方和(RSS)直接相关 | 基于多项 PMF，形式复杂，涉及累积概率 |
| **导数计算** | 简单，有封闭解（矩阵运算） | 复杂，无封闭解，需数值计算 |
| **检验统计量形式** | 可简化为基于 RSS 的 F 统计量 | 必须使用通用二次型 $U^T I^{-1} U$ |
| **统计量分布** | **精确的 F 分布**（小样本性质） | **渐近的卡方分布**（大样本性质） |
| **实际优势** | 理论简洁，有精确的小样本推断 | 框架通用，适用于各类广义线性模型 |

### 结论

您提供的步骤是进行得分检验的**通用“配方”**。

*   对于**有序逻辑回归**，您必须严格遵循这个配方中的每一步，处理复杂的对数似然函数、得分向量和信息矩阵。
*   对于**线性模型**，这个配方同样适用，但由于正态分布的优良数学性质，整个过程可以被大大简化，最终得到我们更熟悉的、基于残差平方和的 F 检验。

因此，可以说，**线性模型的得分检验（F检验）是有序模型得分检验这一通用框架下的一个高度简化和特化的案例**。您对通用框架的理解已经完全到位，并且它足以处理比线性模型复杂得多的有序多分类情况。





## **有序逻辑回归如何构建其似然函数**

好的，我们来详细解释一下有序多分类（Ordinal Multi-class Classification）的似然函数。

有序多分类最常用的模型是**比例优势模型（Proportional Odds Model）**，也称为**累积Logit模型（Cumulative Logit Model）**。理解这个模型的构建方式是理解其似然函数的关键。

### 1. 模型设定与核心思想

与标准的多分类（如Softmax回归）不同，有序多分类模型利用了类别之间的**顺序关系**。它不直接对每个类别的概率 $P(Y=j)$ 建模，而是对**累积概率（Cumulative Probability）** $P(Y \le j)$ 建模。

#### **符号定义:**

*   **因变量 Y**: 一个有序分类变量，有 K 个类别，记为 $1, 2, \dots, K$。例如：{差, 中, 好}。
*   **自变量 X**: 一组预测变量，是一个向量 $X = (X_1, X_2, \dots, X_p)$。
*   **模型参数**:
    *   **回归系数 $\beta$**: 一个与 X 维度相同的参数向量 $(\beta_1, \dots, \beta_p)$，它衡量自变量对“跨越”某个阈值的影响。
    *   **截距/阈值 $\alpha_j$**: 一组 K-1 个截距项 $\alpha_1, \alpha_2, \dots, \alpha_{K-1}$，它们满足 $\alpha_1 < \alpha_2 < \dots < \alpha_{K-1}$。这些阈值在潜在的连续变量上划分了不同的类别。

#### **模型方程 (累积Logit模型):**

模型的核心是为每个累积概率 $P(Y \le j)$ 建立一个Logit链接函数模型。对于 $j = 1, 2, \dots, K-1$：

$$
\text{logit}[P(Y \le j | X)] = \log\left(\frac{P(Y \le j | X)}{1 - P(Y \le j | X)}\right) = \alpha_j - X^T\beta
$$

这里有几个关键点：
*   我们总共建立了 K-1 个这样的方程。
*   **比例优势假设 (Proportional Odds Assumption)**: 请注意，所有方程共享同一组回归系数 $\beta$。这意味着自变量 X 对“跨越”任何一个阈值（例如，从“差”到“中或好”，或者从“差或中”到“好”）的影响是相同的。这也就是“比例优势”这个名字的由来。
*   不同的方程只有截距项 $\alpha_j$ 不同，这 $\alpha_j$ 就代表了不同类别之间的“界限”。

### 2. 从累积概率到单类别概率

为了构建似然函数，我们需要的是观察到具体某个类别 $j$ 的概率 $P(Y=j|X)$。这可以通过累积概率的差值来计算：

$$
P(Y=j | X) = P(Y \le j | X) - P(Y \le j-1 | X)
$$

我们可以通过逆Logit函数（即Sigmoid函数）从模型方程中解出累积概率：

$$
P(Y \le j | X) = \frac{\exp(\alpha_j - X^T\beta)}{1 + \exp(\alpha_j - X^T\beta)} = \sigma(\alpha_j - X^T\beta)
$$

其中 $\sigma(z) = 1 / (1 + e^{-z})$。

现在，我们可以计算每个类别的概率：

*   **对于类别 1**:
    $P(Y = 1 | X) = P(Y \le 1 | X) = \sigma(\alpha_1 - X^T\beta)$

*   **对于中间类别 $j$ (其中 $1 < j < K$)**:
    $P(Y = j | X) = P(Y \le j | X) - P(Y \le j-1 | X) = \sigma(\alpha_j - X^T\beta) - \sigma(\alpha_{j-1} - X^T\beta)$

*   **对于最后一个类别 K**:
    $P(Y = K | X) = 1 - P(Y \le K-1 | X) = 1 - \sigma(\alpha_{K-1} - X^T\beta)$

我们将这单个类别的概率统一记为 $\pi_j(X) = P(Y=j|X)$。

### 3. 构建似然函数 (Likelihood Function)

假设我们有一个包含 $n$ 个独立观测的数据集 $\{(X_i, Y_i)\}_{i=1}^n$，其中 $X_i$ 是第 $i$ 个样本的特征向量，$Y_i$ 是其对应的有序类别。

**似然函数 $L(\alpha, \beta)$** 的目标是衡量在给定参数 $\alpha = (\alpha_1, \dots, \alpha_{K-1})$ 和 $\beta$ 的情况下，观测到整个数据集的概率有多大。由于样本是独立的，总似然是每个样本似然的乘积：

$$
L(\alpha, \beta | \text{Data}) = \prod_{i=1}^{n} P(Y_i = y_i | X_i)
$$

其中 $y_i$ 是第 $i$ 个样本的实际观测类别。

这个公式可以更具体地写成：

$$
L(\alpha, \beta) = \prod_{i=1}^{n} \left[ \pi_1(X_i)^{I(y_i=1)} \cdot \pi_2(X_i)^{I(y_i=2)} \cdot \dots \cdot \pi_K(X_i)^{I(y_i=K)} \right]
$$

这里 $I(\cdot)$ 是指示函数（Indicator Function），如果条件为真，则值为1，否则为0。这个表达式的含义是，对于第 $i$ 个样本，我们只取其真实类别对应的概率 $\pi_{y_i}(X_i)$ 放入连乘积中。

### 4. 对数似然函数 (Log-Likelihood Function)

在实际优化中，直接最大化连乘形式的似然函数很困难（数值不稳定且计算复杂）。因此，我们通常最大化其对数形式，即**对数似然函数 $\ell(\alpha, \beta)$**。

$$
\ell(\alpha, \beta) = \log L(\alpha, \beta) = \sum_{i=1}^{n} \log P(Y_i = y_i | X_i)
$$

展开后就是：

$$
\ell(\alpha, \beta) = \sum_{i=1}^{n} \sum_{j=1}^{K} I(y_i=j) \log[\pi_j(X_i)]
$$

将前面推导出的 $\pi_j(X_i)$ 代入，对数似然函数就变得非常具体：

$$
\ell(\alpha, \beta) = \sum_{i: y_i=1} \log[\sigma(\alpha_1 - X_i^T\beta)] \\
+ \sum_{j=2}^{K-1} \sum_{i: y_i=j} \log[\sigma(\alpha_j - X_i^T\beta) - \sigma(\alpha_{j-1} - X_i^T\beta)] \\
+ \sum_{i: y_i=K} \log[1 - \sigma(\alpha_{K-1} - X_i^T\beta)]
$$

**模型训练的目标**就是找到一组参数 $\hat{\alpha}$ 和 $\hat{\beta}$，使得这个对数似然函数 $\ell(\alpha, \beta)$ 达到最大值。这个过程通常使用梯度下降、牛顿法等数值优化算法来完成。

### 总结

有序多分类的似然函数构建步骤如下：
1.  **核心建模对象**: 累积概率 $P(Y \le j)$。
2.  **模型形式**: 使用Logit（或其他链接函数）将累积概率与线性预测器 $\alpha_j - X^T\beta$ 关联起来。
3.  **计算单类别概率**: 通过累积概率的差值 $P(Y=j) = P(Y \le j) - P(Y \le j-1)$ 得到观察到每个具体类别的概率。
4.  **构建似然函数**: 将数据集中每个观测样本的真实类别概率连乘起来，得到总似然函数 $L = \prod P(Y_i=y_i)$。
5.  **构建对数似然函数**: 取对数将连乘变为连加 $\ell = \sum \log P(Y_i=y_i)$，这是最终用于模型参数估计（最大化）的目标函数。















## 得分检验的代码编写01

好的，这绝对是一个非常专业且有趣的任务。您提供的 `NullModel` 函数写得很好，它正确地使用了 `ordinal::clm` 来拟合零模型，并返回了完整的模型对象，这是进行后续计算的关键。

您提供的 `Ordinal_exactScore` 函数是基于 **标准广义线性模型 (GLM)** 的得分检验逻辑，它依赖于像 `residuals` 和单一的权重矩阵 `W_mat` 这样的构件。然而，正如我们之前讨论的，**有序逻辑回归模型的内部数学结构要复杂得多**，它没有单一的残差向量或权重矩阵。它的似然函数、得分和信息矩阵的计算涉及到每个观测值在所有 J-1 个类别阈值上的累积概率。

因此，我们需要编写一个**遵循得分检验基本定义**的新函数，直接从 `clm` 对象及其对数似然函数中提取或计算所需的导数信息。

最稳健、最直接的方法是利用数值微分来计算得分向量和信息矩阵，因为从头手动推导和编写这些复杂矩阵的代数形式非常容易出错。我们将使用 `numDeriv` 包来完成这个任务。

---

### 第1步：安装必要的包

如果尚未安装 `numDeriv`，请先安装。

```R
if (!requireNamespace("numDeriv", quietly = TRUE)) {
  install.packages("numDeriv")
}
library(numDeriv)
```

### 第2步：编写新的得分检验函数 `OrdinalScoreTest`

这个函数将严格遵循得分检验的理论步骤：
1.  定义包含新变量（基因型）的**完整模型的对数似然函数**。
2.  在**零模型参数**（即新变量系数为零）处，计算该函数的：
    a.  **梯度 (Gradient)**：这就是得分向量 $U$。
    b.  **海森矩阵 (Hessian)**：这是负信息矩阵 $-I$。
3.  提取与新变量对应的得分向量部分 $U_g$。
4.  计算完整的信息矩阵 $I$，求其逆 $I^{-1}$，并提取与新变量对应的分块 $(I^{-1})_{gg}$。
5.  计算得分统计量 $S = U_g^T (I^{-1})_{gg} U_g$。

```R
# 确保 numDeriv 已加载
library(numDeriv)
library(ordinal)

#' 对有序回归模型进行得分检验
#'
#' @param objNull NullModel() 函数返回的列表，其中包含一个 clm 对象。
#' @param G_mat 一个 N x p_g 的矩阵，其中 N 是样本数，p_g 是要检验的新变量（如基因型）的数量。
#'              行顺序必须与 objNull$sample_ids 匹配。
#' @return 一个包含得分统计量、自由度和P值的列表。
#'
OrdinalScoreTest <- function(objNull, G_mat) {
  
  # --- 1. 准备工作：从零模型对象中提取必要信息 ---
  fit_null <- objNull$fit_clm
  if (!inherits(fit_null, "clm")) {
    stop("objNull$fit_clm is not a valid 'clm' object.")
  }
  
  # 确保 G_mat 是矩阵格式
  if (!is.matrix(G_mat)) {
    G_mat <- as.matrix(G_mat)
  }
  
  # 检查维度是否匹配
  n_samples_model <- nrow(fit_null$model)
  if (nrow(G_mat) != n_samples_model) {
    stop(paste("Mismatch in number of samples. Model has", n_samples_model,
               "samples, but G_mat has", nrow(G_mat), "rows."))
  }
  
  # 零模型中的参数 (alpha 和 beta_cov)
  params_null <- fit_null$coefficients
  p_null <- length(params_null)
  
  # 新增基因型变量的数量
  p_g <- ncol(G_mat)
  
  # 完整模型的参数点 (在 H0 下)
  theta_h0 <- c(params_null, rep(0, p_g))

  # --- 2. 定义完整模型的对数似然函数 ---
  # 这个函数是核心，它计算给定参数下所有观测值的总对数似然
  loglik_ordinal_full <- function(params, y, X_null, G) {
    
    # 分离参数
    alpha_beta_null <- params[1:p_null]
    beta_g <- params[(p_null + 1):(p_null + p_g)]
    
    # 计算线性预测器
    # fit_null$model 包含了用于建模的所有变量
    eta_null <- model.matrix(fit_null) %*% alpha_beta_null
    eta_g <- G %*% beta_g
    
    # 比例优势假设下，beta对所有阈值的影响相同
    # fit_null$alpha 是阈值截距, fit_null$beta 是协变量系数
    # eta 向量需要根据 clm 的内部结构进行构建
    n_alpha <- length(fit_null$alpha)
    eta_full <- eta_null # eta_null 已经包含了 alpha 和 beta_null 的影响
    
    # 将 eta_g 的影响加到非阈值部分
    # clm 的 model.matrix 的前 n_alpha 列是阈值的伪变量
    # 我们只需要将 eta_g 加到协变量效应上
    lin_pred <- eta_full + eta_g

    # 获取累积概率 P(Y <= j)
    # clm link function 是 probit，所以用 pnorm
    # fit_null$Theta 是 alpha 参数
    cum_probs <- pnorm(matrix(fit_null$Theta, nrow = length(y), ncol = n_alpha, byrow = TRUE) - lin_pred)
    
    # 确保概率单调
    cum_probs <- t(apply(cum_probs, 1, function(x) c(0, x, 1)))
    
    # 计算类别概率 P(Y = j) = P(Y <= j) - P(Y <= j-1)
    cat_probs <- t(apply(cum_probs, 1, diff))
    
    # 避免 log(0)
    cat_probs[cat_probs <= 0] <- 1e-100 
    
    # y_idx 是一个 N x J 的矩阵，用于选择每个观测值对应的类别概率
    y_idx <- model.matrix(~ 0 + y)
    
    # 提取每个观测值实际类别的概率
    obs_probs <- rowSums(cat_probs * y_idx)
    
    # 返回总对数似然
    return(sum(log(obs_probs)))
  }

  # --- 3. 使用 numDeriv 计算梯度和海森矩阵 ---
  # 梯度 (得分向量)
  grad_vec <- grad(
    func = loglik_ordinal_full,
    x = theta_h0,
    y = fit_null$y,
    X_null = model.matrix(fit_null),
    G = G_mat
  )
  
  # 海森矩阵 (负信息矩阵)
  hess_mat <- hessian(
    func = loglik_ordinal_full,
    x = theta_h0,
    y = fit_null$y,
    X_null = model.matrix(fit_null),
    G = G_mat
  )
  
  # --- 4. 构建得分检验统计量 ---
  
  # a) 提取与新变量 G 相关的得分向量部分
  # 根据MLE的性质，与零模型参数对应的梯度应接近于0
  U_g <- grad_vec[(p_null + 1):(p_null + p_g)]
  
  # b) 计算信息矩阵的逆，并提取相应分块
  # 信息矩阵 I = -Hessian
  I_full <- -hess_mat
  # 使用广义逆以增加数值稳定性
  I_full_inv <- MASS::ginv(I_full)
  
  I_inv_gg <- I_full_inv[(p_null + 1):(p_null + p_g), (p_null + 1):(p_null + p_g), drop = FALSE]

# 正确的得分统计量计算
# 使用完整的得分向量和完整的逆信息矩阵
Stest_corrected <- as.numeric(t(grad_vec) %*% I_full_inv %*% grad_vec)

# p_value 的计算也应该使用这个修正后的值
p_value_corrected <- pchisq(Stest_corrected, df = p_g, lower.tail = FALSE)
  
  # --- 5. 返回结果 ---
  return(list(
    Stest = Stest,
    df = p_g,
    p_value = p_value,
    score_vector = U_g
  ))
}
```







## 得分检验的代码编写02

好的，没有问题。我们来修改这个流程，去掉基于潜在残差的复杂计算，转而使用更经典的、直接基于对数似然函数、得分函数和信息矩阵的数值优化方法来实现得分检验。

这是一种更“第一性原理”的方法，能让你清晰地看到得分检验的每一步是如何从似然函数推导出来的。

### 核心步骤

1.  **定义对数似然函数 (Log-Likelihood Function)**: 我们需要一个R函数，输入参数（截距$\alpha$和协变量系数$\beta$）、设计矩阵$X$和因变量$Y$，输出对数似然值。由于你的代码使用了`probit`链接，我们将基于正态分布的累积分布函数(CDF) `pnorm` 来构建。
2.  **拟合零模型 (Null Model)**: 这一步保持不变，我们仍然使用`ordinal::clm`来高效、稳定地拟合零模型，并获得在原假设($H_0$)下的参数估计值 $\tilde{\theta} = (\tilde{\alpha}, \tilde{\beta}_{cov})$。
3.  **定义得分函数 (Score Function)**: 这是对数似然函数关于**所有参数**的一阶导数（梯度）。我们将使用数值方法（例如 `numDeriv::grad` 包）来计算这个梯度。这避免了手动进行复杂的求导。
4.  **计算信息矩阵 (Information Matrix)**: 这是对数似然函数关于**所有参数**的二阶导数矩阵（Hessian矩阵）的负值。我们同样使用数值方法（例如 `numDeriv::hessian`）来计算。
5.  **执行得分检验**: 在零模型估计的参数$\tilde{\theta}$处，计算完整模型（包含待检验的遗传变异$G$）的得分向量$U$和信息矩阵$I$。然后构建得分检验统计量 $S = U^T I^{-1} U$。

---

### 第1部分：修改后的 `NullModel` 函数

这个函数现在变得更简单。它的核心任务就是拟合零模型并返回必要的对象，为后续的得分检验做准备。

```R
# 需要安装 'ordinal' 和 'numDeriv' 包
# install.packages(c("ordinal", "numDeriv", "data.table"))
library(ordinal)
library(data.table)

NullModel_Likelihood <- function(phenofile, outcomeCol, sampleCol, covCol = NULL) {
  # --- Part 1: 加载和准备表型数据 ---
  if (is.character(phenofile)) {
    if (!file.exists(phenofile)) stop("Phenotype file does not exist!")
    use_data <- data.table::fread(phenofile, data.table = FALSE)
  } else {
    use_data <- as.data.frame(phenofile)
  }
  
  # 移除含有NA的行，确保数据完整
  use_data <- na.omit(use_data[, c(sampleCol, outcomeCol, covCol)])
  use_data[[sampleCol]] <- as.character(use_data[[sampleCol]])
  
  # --- Part 2: 构建零模型公式 ---
  if (!is.ordered(use_data[[outcomeCol]])) {
    use_data[[outcomeCol]] <- as.ordered(use_data[[outcomeCol]])
  }
  
  if (is.null(covCol)) {
    formula_null <- as.formula(paste(outcomeCol, "~ 1"))
  } else {
    formula_null <- as.formula(paste(outcomeCol, "~", paste(covCol, collapse = " + ")))
  }
  
  # --- Part 3: 拟合有序零模型 ---
  message("Fitting the ordinal null model using ordinal::clm...")
  clm_obj <- ordinal::clm(formula = formula_null, data = use_data, link = "probit", model = TRUE)
  
  message("Ordinal null model fitting complete.")
  
  # --- Part 4: 准备返回对象 ---
  # clm返回的对象已经包含了大部分我们需要的信息
  # 我们返回模型对象本身，以及清理后的数据框
  # model.frame(clm_obj) 包含了模型实际使用的数据
  fit_null <- list(
    clm_fit = clm_obj,
    model_data = model.frame(clm_obj),
    sample_ids = use_data[rownames(model.frame(clm_obj)), sampleCol],
    outcome = clm_obj$y,
    formula_null = formula(clm_obj)
  )
  
  return(fit_null)
}
```

### 第2部分：定义似然函数和得分检验函数

这是核心部分。我们将创建两个新函数：
1.  `loglike_probit`: 计算有序probit模型的对数似然。
2.  `OrdinalScoreTest`: 执行得分检验。

```R
library(numDeriv)

#' 计算有序Probit模型的对数似然函数
#'
#' @param params 一个向量，包含所有参数 (alpha_1, ..., alpha_{K-1}, beta_1, ..., beta_p)
#' @param y 有序因变量 (factor)
#' @param X 设计矩阵 (包含截距列)
#' @return 负对数似然值 (用于最小化优化)
loglike_probit <- function(params, y, X) {
  # 分离截距 (alpha) 和系数 (beta)
  n_alpha <- nlevels(y) - 1
  alpha <- params[1:n_alpha]
  beta <- params[-(1:n_alpha)]
  
  # 确保阈值有序
  if (is.unsorted(alpha)) return(Inf)
  
  # 扩展阈值为 (-Inf, alpha_1, ..., alpha_{K-1}, Inf)
  thresholds <- c(-Inf, alpha, Inf)
  
  # 计算线性预测器 eta = X %*% beta
  eta <- as.vector(X %*% beta)
  
  # 获取每个观测值对应的类别索引
  y_idx <- as.numeric(y)
  
  # 计算 P(Y <= j) 和 P(Y <= j-1)
  # upper_p = P(Y <= y_i) = pnorm(alpha_{y_i} - eta_i)
  upper_p <- pnorm(thresholds[y_idx + 1] - eta)
  # lower_p = P(Y <= y_i-1) = pnorm(alpha_{y_i-1} - eta_i)
  lower_p <- pnorm(thresholds[y_idx] - eta)
  
  # 计算 P(Y = y_i)
  prob <- upper_p - lower_p
  
  # 防止数值问题 log(0)
  prob[prob <= 0] <- 1e-100
  
  # 计算总对数似然
  logL <- sum(log(prob))
  
  # 优化器通常最小化函数，所以返回负对数似然
  return(-logL)
}


#' 对单个遗传变异执行得分检验
#'
#' @param null_model_fit `NullModel_Likelihood` 函数的输出
#' @param G 单个遗传变异的基因型向量 (与 null_model_fit$sample_ids 对应)
#' @return 包含得分统计量和p值的列表
OrdinalScoreTest <- function(null_model_fit, G) {
  
  # --- Step 1: 提取零模型信息 ---
  clm_fit <- null_model_fit$clm_fit
  y <- null_model_fit$outcome
  
  # 零模型的设计矩阵 (不包含截距)
  X_null_no_intercept <- model.matrix(null_model_fit$formula_null, data = null_model_fit$model_data)[, -1, drop = FALSE]
  
  # 零模型下的参数估计值
  alpha_tilde <- clm_fit$alpha
  beta_tilde <- clm_fit$beta # 这是协变量的系数
  
  # --- Step 2: 构建完整模型的设计矩阵和参数向量 (在H0下) ---
  # 完整模型的设计矩阵 (协变量 + 基因型G)，不含截距
  X_full_no_intercept <- cbind(X_null_no_intercept, G)
  
  # 完整模型在H0下的参数向量 (alpha, beta_cov, beta_G=0)
  params_h0 <- c(alpha_tilde, beta_tilde, 0)
  names(params_h0) <- c(names(alpha_tilde), names(beta_tilde), "G")

  # --- Step 3: 计算得分向量 (Gradient) ---
  # 我们需要一个包装函数，因为 `grad` 需要一个只接受参数的函数
  # 注意：loglike_probit 返回的是 *负* 对数似然，所以梯度也是负的。
  # 我们需要的是对数似然的梯度，所以要取反。
  grad_func <- function(params) {
    # 重新定义 loglike_probit 以符合 numDeriv 的要求
    # 这里的 logL 返回正值
    n_alpha <- nlevels(y) - 1
    alpha <- params[1:n_alpha]
    beta <- params[-(1:n_alpha)]
    if (is.unsorted(alpha)) return(-Inf) # 返回-Inf表示无效参数
    
    thresholds <- c(-Inf, alpha, Inf)
    eta <- as.vector(X_full_no_intercept %*% beta)
    y_idx <- as.numeric(y)
    
    upper_p <- pnorm(thresholds[y_idx + 1] - eta)
    lower_p <- pnorm(thresholds[y_idx] - eta)
    
    prob <- upper_p - lower_p
    prob[prob <= 0] <- 1e-100
    
    return(sum(log(prob)))
  }

  message("Calculating Score vector (Gradient)...")
  U <- grad(func = grad_func, x = params_h0)

  # --- Step 4: 计算信息矩阵 (Hessian) ---
  message("Calculating Information matrix (Hessian)...")
  # Hessian of the log-likelihood
  hessian_mat <- hessian(func = grad_func, x = params_h0)
  # Information matrix is the negative of the Hessian
  I <- -hessian_mat
  
  # 检查信息矩阵是否可逆
  # 使用 tryCatch 来处理奇异矩阵 (singular matrix)
  I_inv <- tryCatch({
    solve(I)
  }, error = function(e) {
    # 如果不可逆，可能存在共线性问题
    # 使用广义逆 Moore-Penrose generalized inverse
    warning("Information matrix is singular, using generalized inverse.")
    MASS::ginv(I)
  })

  # --- Step 5: 计算得分检验统计量 ---
  # S = U' * I_inv * U
  score_stat <- t(U) %*% I_inv %*% U
  score_stat <- as.numeric(score_stat)
  
  # 在H0下，得分统计量服从自由度为1的卡方分布
  # (因为我们只检验了一个参数 beta_G)
  p_value <- pchisq(score_stat, df = 1, lower.tail = FALSE)
  
  return(list(score_statistic = score_stat, p_value = p_value, score_vector = U))
}

```

### 第3部分：使用示例

现在，我们用一个模拟的例子来演示如何使用这些函数。

```R
# --- 模拟数据 ---
set.seed(123)
n_samples <- 500

# 协变量
age <- rnorm(n_samples, 50, 10)
sex <- rbinom(n_samples, 1, 0.5)

# 遗传变异 (Minor Allele Frequency = 0.2)
genotype <- rbinom(n_samples, 2, 0.2)

# 真实参数
alpha_true <- c(-2, 0.5, 2.5) # 4个等级的3个阈值
beta_age_true <- 0.05
beta_sex_true <- 0.4
beta_geno_true <- 0.3 # 遗传变异的真实效应

# 生成潜在变量
latent_y <- alpha_true[1] + beta_age_true * age + beta_sex_true * sex + beta_geno_true * genotype + rnorm(n_samples)

# 将潜在变量转换为有序类别
y_ord <- cut(latent_y, breaks = c(-Inf, alpha_true, Inf), labels = 1:4, right = FALSE)
y_ord <- as.ordered(y_ord)

# 创建数据框
pheno_data <- data.frame(
  SampleID = paste0("S", 1:n_samples),
  Outcome = y_ord,
  Age = age,
  Sex = factor(sex)
)

geno_vec <- genotype

# --- 运行分析 ---

# 1. 拟合零模型 (不包含基因型)
null_fit <- NullModel_Likelihood(
  phenofile = pheno_data,
  outcomeCol = "Outcome",
  sampleCol = "SampleID",
  covCol = c("Age", "Sex")
)

# 打印零模型摘要
print(summary(null_fit$clm_fit))

# 2. 对基因型进行得分检验
# 确保基因型向量与模型中使用的数据对齐
# null_fit$sample_ids 包含了正确的样本和顺序
aligned_geno <- geno_vec[match(null_fit$sample_ids, pheno_data$SampleID)]

score_test_result <- OrdinalScoreTest(null_model_fit = null_fit, G = aligned_geno)

# 3. 查看结果
print(score_test_result)
# 预期结果：由于 beta_geno_true 不为零，p值应该很小

# --- 验证：与完整模型的Wald检验比较 ---
# 拟合包含基因型的完整模型
full_model_data <- cbind(null_fit$model_data, G = aligned_geno)
full_fit <- ordinal::clm(Outcome ~ Age + Sex + G, data = full_model_data, link = "probit")
print(summary(full_fit))

# 比较得分检验的p值和完整模型中G的Wald检验p值
# 它们应该在数量级上是相似的，尤其是在大样本下
```

### 代码解释

1.  **`NullModel_Likelihood`**: 这个简化版的函数只负责数据准备和调用`ordinal::clm`。它返回一个包含模型拟合对象和相关数据的列表，非常清晰。
2.  **`loglike_probit`**: 这是得分检验的数学核心。它精确地实现了有序Probit模型的对数似然函数。这是后续所有数值计算的基础。
3.  **`OrdinalScoreTest`**:
    *   它首先从零模型中提取所有必要信息：参数估计值、数据、因变量。
    *   然后，它构建了**完整模型**（包含协变量和待检验的基因型`G`）的参数向量，但将`G`的系数强制设为0，这正是$H_0$的定义。
    *   **关键步骤**: 它调用`numDeriv::grad`和`numDeriv::hessian`在`params_h0`这个点上，对`grad_func`（代表完整模型的对数似然）求一阶和二阶导数。
    *   `U` (得分向量)的最后一个元素 `U['G']` 是我们最关心的，它代表了在零模型最优解处，似然函数沿着`G`系数方向的变化率。如果这个值离零很远，说明`G`很重要。
    *   `I` (信息矩阵) 描述了似然函数在最优解附近的曲率，可以看作是参数估计的精度。
    *   最终的统计量 $S = U^T I^{-1} U$ 是一个标准化的度量，它考虑了所有参数的梯度以及它们之间的相关性，因此比单独看 `U['G']` 更稳健。在$H_0$下，它近似服从卡方分布。

这种方法完全符合得分检验的理论定义，并且通过使用数值导数，避免了手动推导复杂梯度和Hessian矩阵的麻烦和潜在错误。