把得分检验需要的组件放在Ordinal_exactScore 函数里

好的，这是一个非常专业的统计学问题。有序多分类模型（Ordered Multiclass Model），最常见的是**比例优势逻辑回归（Proportional Odds Logistic Regression）**，其得分检验（Score Test）是一种重要且高效的假设检验方法。

下面我将详细解释有序多分类模型中得分检验的原理、步骤和一个关键应用。

### 核心概念回顾

#### 1. 有序多分类模型（比例优势模型）
该模型用于因变量是有序类别（如：差、中、好；轻度、中度、重度）的情况。其核心公式是：
$$ \text{logit} [P(Y \le j)] = \log \left( \frac{P(Y \le j)}{1 - P(Y \le j)} \right) = \alpha_j - \boldsymbol{\beta}^T \mathbf{X} $$
其中：
*   $Y$ 是有序的因变量，有 $J$ 个类别。
*   $j$ 是类别，$j = 1, 2, ..., J-1$。
*   $P(Y \le j)$ 是观测值属于类别 $j$ 或更低类别的累积概率。
*   $\alpha_j$ 是第 $j$ 个类别的**截距**或**切点（cut-point）**，满足 $\alpha_1 < \alpha_2 < ... < \alpha_{J-1}$。
*   $\boldsymbol{\beta}$ 是自变量 $\mathbf{X}$ 的**系数向量**。关键假设是，这个 $\boldsymbol{\beta}$ 对所有的 $j$ 都是相同的，这就是“比例优势假设”。

#### 2. 得分检验（Score Test）
得分检验，也称拉格朗日乘数检验（Lagrange Multiplier Test），是与瓦尔德检验（Wald Test）和似然比检验（Likelihood Ratio Test）并列的三大经典假设检验方法。

*   **核心优势**：它**只需要拟合零假设（H₀）下的简化模型**，而不需要拟合备择假设（Hₐ）下的复杂模型。这在复杂模型难以收敛时特别有用。
*   **基本原理**：检验的核心思想是评估在零假设模型参数估计处，对数似然函数关于“被约束为零的参数”的梯度（或称得分，Score）是否显著不为零。如果梯度很陡峭，说明如果释放这个参数的约束，似然函数值会显著增加，因此我们应该拒绝零假设。

### 如何对有序多分类模型进行得分检验

得分检验最常见的用途是检验**一个或多个新自变量的系数是否显著不为零**。

#### 步骤

**假设：**
*   我们有一个已经拟合好的模型（零假设模型 H₀），包含自变量集合 $\mathbf{X}_1$。
*   我们想检验是否应该加入新的自变量集合 $\mathbf{X}_2$。

**检验的假设：**
*   **H₀**: 新增变量的系数为零 ($\boldsymbol{\beta}_2 = \mathbf{0}$)。
*   **Hₐ**: 新增变量的系数至少有一个不为零 ($\boldsymbol{\beta}_2 \neq \mathbf{0}$)。

**执行过程：**

1.  **拟合零假设模型**：
    只使用自变量 $\mathbf{X}_1$ 拟合比例优势逻辑回归模型：
    $$ \text{logit} [P(Y \le j)] = \alpha_j - \boldsymbol{\beta}_1^T \mathbf{X}_1 $$
    得到在 H₀ 下的参数最大似然估计值 $\tilde{\boldsymbol{\alpha}}$ 和 $\tilde{\boldsymbol{\beta}}_1$。

2.  **计算得分向量（Score Vector）**：
    得分向量 $U(\boldsymbol{\theta})$ 是对数似然函数 $L(\boldsymbol{\theta})$ 关于所有参数 $\boldsymbol{\theta} = (\boldsymbol{\alpha}, \boldsymbol{\beta}_1, \boldsymbol{\beta}_2)$ 的一阶偏导数。
    $$ U(\boldsymbol{\theta}) = \frac{\partial L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} $$
    我们需要计算在 H₀ 模型估计值处的得分，即 $U(\tilde{\boldsymbol{\theta}})$，其中 $\tilde{\boldsymbol{\theta}} = (\tilde{\boldsymbol{\alpha}}, \tilde{\boldsymbol{\beta}}_1, \mathbf{0})$。
    根据最大似然估计的性质，得分向量中与 $\boldsymbol{\alpha}$ 和 $\boldsymbol{\beta}_1$ 对应的部分在 $\tilde{\boldsymbol{\theta}}$ 处的值为零。因此，我们只需要关注与 $\boldsymbol{\beta}_2$ 相关的部分 $U_{\boldsymbol{\beta}_2}(\tilde{\boldsymbol{\theta}})$。

3.  **计算信息矩阵（Information Matrix）**：
    信息矩阵 $I(\boldsymbol{\theta})$ 是对数似然函数负二阶偏导数的期望值。它反映了参数估计的精度。
    $$ I(\boldsymbol{\theta}) = -E \left[ \frac{\partial^2 L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta} \partial \boldsymbol{\theta}^T} \right] $$
    同样，我们在 H₀ 模型估计值处计算信息矩阵 $I(\tilde{\boldsymbol{\theta}})$。

4.  **构建得分检验统计量**：
    得分检验统计量 $S$ 的一般形式是：
    $$ S = U(\tilde{\boldsymbol{\theta}})^T [I(\tilde{\boldsymbol{\theta}})]^{-1} U(\tilde{\boldsymbol{\theta}}) $$
    由于 $U_{\boldsymbol{\alpha}}$ 和 $U_{\boldsymbol{\beta}_1}$ 部分为零，这个公式可以简化为只涉及 $U_{\boldsymbol{\beta}_2}$ 和信息矩阵对应分块的二次型。

5.  **判断显著性**：
    在零假设 H₀ 成立的条件下，得分统计量 $S$ 近似服从**卡方分布（Chi-squared distribution）**。
    *   **自由度（df）**：等于被检验的参数个数，即自变量集合 $\mathbf{X}_2$ 中变量的数量。
    *   **决策**：计算出 $S$ 的值后，根据卡方分布和自由度计算 P 值。如果 P 值小于预设的显著性水平（如 0.05），则拒绝零假设，认为新加入的变量 $\mathbf{X}_2$ 是显著的。

### 一个至关重要的特殊应用：比例优势假设检验

在有序逻辑回归中，得分检验最常用、也最重要的一个特殊应用就是**检验比例优势假设（Proportional Odds Assumption）**。

*   **假设内容**：自变量 $\mathbf{X}$ 的影响（即系数 $\boldsymbol{\beta}$）在不同的累积概率切点上是相同的。
*   **检验思想**：如果这个假设不成立，那么对于某个自变量，它在区分“类别1”和“类别2及以上”时的作用，可能不同于它在区分“类别1和2”与“类别3及以上”时的作用。

**使用得分检验来检验该假设：**

1.  **H₀ 模型**：标准的比例优势模型，对每个自变量只有一个系数 $\beta_k$。
2.  **Hₐ 模型**：一个更广义的模型，允许每个自变量在每个切点 $j$ 都有一个不同的系数 $\beta_{kj}$（除了最后一个类别）。
3.  **检验过程**：得分检验会评估，从 H₀ 模型（所有 $\beta_{kj}$ 都相等）变为 Hₐ 模型（允许 $\beta_{kj}$ 不同）时，模型的拟合优度是否会显著提升。
4.  **结果解读**：
    *   **P 值 > 0.05**：不拒绝零假设，说明没有足够证据表明比例优势假设被违背。这是我们**希望看到的结果**，表明标准模型是合适的。
    *   **P 值 < 0.05**：拒绝零假设，说明比例优势假设可能不成立。这意味着至少有一个自变量的影响会随着类别的变化而改变，标准模型可能不适用。此时需要考虑备选模型，如部分比例优势模型（Partial Proportional Odds Model）或多分类逻辑回归（Multinomial Logistic Regression）。

这个检验在很多统计软件中都有实现，有时也被称为 **Brant 检验**（尽管 Brant 检验的原始形式是 Wald 检验，但很多软件提供了等价的得分检验版本）。






非常好的问题！估计有序多分类模型的残差是一个比线性回归复杂得多的高级话题。原因在于，模型的因变量是类别（如“满意”），而不是一个数值，所以我们无法像线性回归那样简单地用 `观测值 - 预测值` 来计算残差。

因此，研究者们提出了几种不同的方法来定义和计算有序模型的“残差”，每种方法都有其特定的用途和解释。下面我将介绍几种主流的方法，从概念到实践。

### 核心挑战

*   **观测值 (Y)** 是一个类别，例如 `k=3`（“一般”）。
*   **预测值 ($\hat{Y}$)** 是一组概率，例如 `P(Y=1)=0.1, P(Y=2)=0.3, P(Y=3)=0.4, ...`。
*   你不能计算 `“一般” - 0.4`。

我们需要找到一种合理的方式来量化模型对每个观测点的“错误程度”。

---

### 方法一：潜在变量残差 (Latent Variable Residuals)

这是**概念上最接近**线性回归残差的方法。

1.  **回顾模型**：有序模型假设存在一个不可观测的连续潜在变量 $y^*$，其模型为：
    $$
    y_i^* = \boldsymbol{\beta}' \mathbf{X}_i + \varepsilon_i
    $$
    其中，$\varepsilon_i$ 是一个遵循特定分布（通常是Logistic或正态分布）的误差项。

2.  **定义残差**：在这个潜在尺度上，残差就是这个误差项：
    $$
    \text{residual}_i = \varepsilon_i = y_i^* - \boldsymbol{\beta}' \mathbf{X}_i
    $$

3.  **问题**：我们永远无法观测到 $y_i^*$ 的真实值。我们只知道它落在了某个区间内。例如，如果观测到类别 $k$，我们只知道 $\tau_{k-1} < y_i^* \le \tau_k$。

4.  **解决方案**：我们可以估计 $y_i^*$ 在其所属区间内的**期望值**。对于观测到类别 $k$ 的样本 $i$，其潜在残差的估计值是：
    $$
    \hat{\varepsilon}_i = E[y_i^* | \tau_{k-1} < y_i^* \le \tau_k] - \boldsymbol{\beta}' \mathbf{X}_i
    $$
    这个期望值是基于被截断的Logistic（或正态）分布的均值来计算的。

*   **优点**：理论上最优雅，直接对应模型的潜在变量假设。
*   **缺点**：计算复杂，不直观，并且其分布依赖于模型的假设。
*   **用途**：主要用于理论研究和模型诊断的高级探索。

---

### 方法二：代理残差 (Surrogate Residuals) - 现代推荐方法

这是一种非常巧妙且实用的现代方法，它能将有序结果“转化”为一个连续的残差，使其性质类似于标准正态分布的残差。

**计算步骤**：
1.  对于一个真实类别为 $j$ 的观测 $i$，首先从模型中计算出两个累积概率：
    *   $a = P(Y_i < j) = P(Y_i \le j-1)$
    *   $b = P(Y_i \le j)$

2.  从区间 $[a, b]$ 上的均匀分布中随机抽取一个数值 $u_i$。
    $$
    u_i \sim \text{Uniform}(a, b)
    $$
    这个 $u_i$ 可以看作是将离散的类别“平滑”地映射到了 (0, 1) 区间上。

3.  将这个 $u_i$ 通过**标准正态分位函数**（probit link）或**标准Logit分位函数**（logit link）进行转换，得到代理残差 $r_i^S$。
    *   如果模型是序数Probit模型，则：$r_i^S = \Phi^{-1}(u_i)$
    *   如果模型是序数Logit模型，则：$r_i^S = \text{logit}(u_i) = \log\left(\frac{u_i}{1-u_i}\right)$

**核心思想**：如果模型是完美的，那么生成的 $u_i$ 序列应该服从 (0, 1) 上的标准均匀分布。经过逆CDF变换后，得到的代理残差 $r_i^S$ 应该近似服从**标准正态分布**或**标准Logistic分布**。

*   **优点**：
    *   生成的残差是连续的。
    *   如果模型拟合良好，残差分布是已知的（如标准正态分布）。
    *   可以直接用于我们熟悉的**残差诊断图**，如 Q-Q 图（检查正态性）、残差 vs. 拟合值图（检查异方差性）等。
*   **缺点**：包含随机成分，每次计算的结果会略有不同（但整体模式不变）。
*   **用途**：**强烈推荐用于实际的模型诊断和可视化**。R语言中的 `sure` 包专门用于计算这类残差。

---

### 方法三：广义残差 (Generalized Residuals)

这种方法将有序多分类模型视为广义线性模型（GLM）的扩展，并借用GLM中的残差定义。最常见的有**皮尔逊残差 (Pearson Residuals)** 和 **偏差残差 (Deviance Residuals)**。

对于有 $K$ 个类别的单个观测 $i$（其实际类别为 $j$），我们可以看作它有 $K$ 个可能的结果。
*   观测向量：$\mathbf{d}_i = (d_{i1}, d_{i2}, \dots, d_{iK})$，其中 $d_{ij}=1$，其余为0。
*   预测概率向量：$\hat{\mathbf{p}}_i = (\hat{p}_{i1}, \hat{p}_{i2}, \dots, \hat{p}_{iK})$。

1.  **皮尔逊残差**：
    对于每个类别 $k$，可以计算一个皮尔逊残差分量：
    $$
    r_{ik}^P = \frac{d_{ik} - \hat{p}_{ik}}{\sqrt{\hat{p}_{ik}}}
    $$
    一个观测点会得到一个残差向量。通常会计算一个汇总值，例如所有分量的平方和。

2.  **偏差残差**：
    偏差是衡量模型饱和度（完美拟合）与当前模型对数似然差异的指标。每个观测点的偏差残差是其对总偏差贡献的带符号平方根。
    $$
    r_i^D = \text{sign}(d_{ij} - \hat{p}_{ij}) \sqrt{2 \left| \log(\text{perfect fit likelihood}) - \log(\text{model likelihood for obs } i) \right|}
    $$
    对于多分类，其具体形式为：$r_i^D = \text{sign}(1 - \hat{p}_{ij}) \sqrt{-2 \log(\hat{p}_{ij})}$

*   **优点**：有坚实的统计理论基础（源自GLM），常用于检验模型的整体拟合优度。
*   **缺点**：对于单个观测点的解释不如代理残差直观，并且每个观测点可能是一个向量，不方便绘图。
*   **用途**：主要用于拟合优度检验（例如，所有皮尔逊残差的平方和近似服从卡方分布）。

### 总结与建议

| 残差类型 | 核心思想 | 优点 | 缺点 | 最佳用途 |
| :--- | :--- | :--- | :--- | :--- |
| **潜在变量残差** | 估计潜在连续变量 $y^*$ 上的误差项 $\varepsilon$ | 理论上最纯粹，直接关联模型假设 | 计算复杂，不直观，依赖模型假设 | 理论分析，深入的模型诊断 |
| **代理残差 (Surrogate)** | 将离散结果随机映射回连续尺度 | **易于可视化**，可直接套用标准残差图（Q-Q图等），分布已知 | 包含随机性，结果不唯一 | **日常模型诊断和可视化分析（强烈推荐）** |
| **广义残差 (Pearson/Deviance)** | 借鉴广义线性模型的思想，衡量概率偏差 | 统计理论坚实，与似然函数紧密相关 | 不直观，常为向量形式，不易于单个观测点的诊断 | 模型的整体**拟合优度检验** |

对于实践者来说，**代理残差 (Surrogate Residuals)** 是目前进行有序多分类模型残差分析和诊断的最强大、最方便的工具。它巧妙地解决了“无连续残差”的难题，让我们能够使用熟悉的图形化工具来评估模型的假设和性能。





当然可以。您提供的这本书——艾伦·阿格雷斯蒂（Alan Agresti）所著的《有序分类数据分析》（Analysis of Ordinal Categorical Data, Second Edition）——正是这个领域的权威著作。基于这本书的目录和核心内容，我来为您详细解答这两个问题。

### 问题一：对于有序多分类的情况是怎么建模的？

根据阿格雷斯蒂这本书的体系，有序多分类问题的建模是一个系统性的过程，其核心和重点在**第3章**，但前后章节也提供了重要的背景和扩展。

#### 1. 建模的核心思想：使用累积概率

与直接对每个类别的概率 `P(Y=k)` 建模不同，有序模型的核心是对**累积概率 (Cumulative Probabilities)** `P(Y ≤ j)` 进行建模。这意味着模型关注的是“响应变量的类别小于或等于某个特定等级 j 的概率”。

#### 2. 最核心的模型：累积Logit模型（比例优势模型）

本书**第3章 “Logistic Regression Models Using Cumulative Logits”** 详细阐述了最主流的有序多分类模型：
*   **模型形式**：该模型对每个累积概率的对数优势（Logit）进行建模。对于类别 $j=1, 2, ..., c-1$，模型的基本形式是：
    $$ \text{logit}[P(Y \le j)] = \alpha_j - \boldsymbol{\beta}' \mathbf{x} $$
    *   $\alpha_j$ 是每个累积分割点（cutpoint）特有的**截距项**（阈值）。
    *   $\mathbf{x}$ 是解释变量（或称自变量、特征）的向量。
    *   $\boldsymbol{\beta}$ 是解释变量的**回归系数向量**。

*   **关键特征：比例优势假设 (Proportional Odds Assumption)**
    一个极其重要的特点是，所有 $c-1$ 个方程共享**同一套回归系数 $\boldsymbol{\beta}$**。这意味着解释变量 $\mathbf{x}$ 对“跨越不同阈值”的影响是**恒定的**。正因为这个特性，该模型也被称为**比例优势模型**。
    *   **优点**：这个假设大大简化了模型，使其参数更少，更易于解释和估计。
    *   **检验**：本书 **第3.5节 “Checking Cumulative Logit Models”** 专门讨论了如何检验这个关键假设。

#### 3. 模型的其他变体和扩展

阿格雷斯蒂在书中也介绍了其他多种建模方式，以应对不同数据特征和研究问题：

*   **其他类型的Logits (第4章)**：除了累积Logit，还可以使用：
    *   **邻近类别Logit (Adjacent-Categories Logit Models)**：对相邻两个类别的对数优势建模，$\log[P(Y=j)/P(Y=j+1)]$。
    *   **连续比率Logit (Continuation-Ratio Logit Models)**：对“给定响应大于等于j时，响应为j”的条件概率进行建模，$\log[P(Y=j)/P(Y>j)]$。

*   **其他累积链接函数 (第5章)**：除了Logit链接，还可以使用其他函数来连接累积概率和线性预测器，形成**累积链接模型 (Cumulative Link Models)**：
    *   **累积Probit模型 (Cumulative Probit Models)**：使用标准正态分布的反函数（Probit链接），这在经济学等领域很常用。
    *   **累积互补log-log模型 (Cumulative Log-Log Links)**：适用于某些非对称的响应过程。

*   **更复杂的模型**：书中后续章节将这些基本模型扩展到更复杂的数据结构，例如：
    *   **聚类/重复测量数据**（第9章的边际模型和第10章的随机效应模型）。
    *   **贝叶斯方法**（第11章）。

**小结**：阿格雷斯蒂的书系统地指出，有序多分类问题的标准建模方法是**比例优势模型（即累积Logit模型）**，同时详细介绍了其多种替代和扩展形式。

---

### 问题二：有序多分类模型如何进行得分检验 (Score Test)？

“得分检验”（Score Test，也称拉格朗日乘子检验，Lagrange Multiplier Test）是统计推断中的三大经典检验方法之一（另两个是Wald检验和似然比检验）。在有序多分类模型的背景下，得分检验主要应用于以下两个关键场景：

#### 1. 检验解释变量的显著性 (Testing for Independence)

这是得分检验最常见的用途之一。我们要检验某个或某些解释变量的效应是否为零（即 $\boldsymbol{\beta} = \mathbf{0}$）。

*   **基本原理**：得分检验的特点是它**仅需要在原假设（$H_0$）下拟合模型**。它通过评估对数似然函数在原假设参数估计处的“梯度”（即得分函数）是否显著不为零来判断。如果梯度足够大，则说明参数稍微偏离原假设值就能显著提升似然函数，因此我们有理由拒绝原假设。
*   **与非参数检验的联系**：本书在 **第3.7节 “Connections with Nonparametric Rank Methods”** 中指出了一个非常深刻的联系：
    *   对于比较两个组的比例优势模型，检验组间差异（即 $\beta=0$）的**得分检验**在数学上**等价于**经典的非参数检验——**Wilcoxon-Mann-Whitney 检验**。
    *   对于比较多个组的情况，得分检验等价于 **Kruskal-Wallis 检验**。
    *   这完美地体现了有序回归模型是如何将经典的秩和检验思想模型化的。

#### 2. 检验比例优势假设 (Testing the Proportional Odds Assumption)

这是得分检验在有序模型中一个**非常特殊且重要的应用**，本书在 **第3.5.5节 “Testing the Proportional Odds Assumption”** 中有明确讨论。

*   **检验目的**：比例优势假设（即所有累积Logit共享同一个 $\boldsymbol{\beta}$）是模型的基础。我们需要检验这个假设是否成立。
*   **检验原理**：
    *   **原假设 ($H_0$)**: 比例优势模型成立（所有 $\beta_j$ 都相等，即 $\boldsymbol{\beta}_1 = \boldsymbol{\beta}_2 = \dots = \boldsymbol{\beta}_{c-1}$）。
    *   **备择假设 ($H_a$)**: 比例优势模型不成立（至少有一对 $\boldsymbol{\beta}_j$ 不相等）。
    *   得分检验通过在原假设（比例优势模型）下评估模型，来检验是否有证据表明允许每个累积Logit拥有自己独立的系数 $\boldsymbol{\beta}_j$ 会显著改善模型拟合。
*   **实用性**：这个检验非常实用，因为备择假设下的模型（非比例优势模型）可能很难直接拟合（有时会导致概率交叉等问题）。得分检验因为它只依赖于原假设下的模型拟合，所以总是可以计算的。
*   **软件实现**：许多统计软件（如SAS的PROC LOGISTIC）会自动报告这个比例优势假设的得分检验结果。

**总结**：根据阿格雷斯蒂的这本著作，有序多分类模型的核心建模方法是**比例优势模型**，它对累积概率的Logit进行建模。而**得分检验**在其中扮演两大角色：一是作为一种检验变量显著性的方法（并与传统非参数秩和检验有深刻联系），二是一个专门用来**诊断比例优势模型核心假设有效性**的关键工具。






极好的问题！您正触及到一个非常核心且普遍的误解。

简单直接的回答是：**得分检验（Score Test）的计算过程本身就不需要先估计残差。** 它是直接基于对数似然函数（Log-Likelihood Function）的导数（即得分函数）来构建的。

我们之所以常常把它和残差联系起来，是因为在线性回归这个**非常特殊且简单的模型**中，得分检验的数学形式恰好可以被简化为“检验残差与新变量的相关性”。这个特例帮助我们建立了直观的理解，但这个“残差”步骤并不是得分检验的普适定义。

下面，我将详细解释这个过程，让您彻底明白为什么不需要残差。

### 1. 得分检验的真正“配方”

想象一下，我们有两个模型：
*   **零模型 ($H_0$)**: 您的初始模型，不包含“基因”变量。
*   **备择模型 ($H_A$)**: 您考虑扩展成的模型，包含了“基因”变量。

得分检验的伟大之处在于，它**只需要拟合零模型**，就能判断备择模型是否会显著更好。它的“配方”包含两个核心要素：

1.  **得分函数 (Score Function)**: 这是**备择模型**的对数似然函数相对于新变量（基因）系数的一阶导数（梯度）。你可以把它想象成对数似然函数这个“山坡”在某个方向上的**陡峭程度**。
2.  **信息矩阵 (Information Matrix)**: 这是对数似然函数的负二阶导数的期望。你可以把它想象成山坡的**曲率**，它告诉我们山坡的形状。

**检验过程的直观比喻：**

1.  **定位**：我们首先通过拟合**零模型**，在参数空间中找到了一个最优点（山坡上的一个点）。在这个点上，“基因”变量的系数被强制固定为0。
2.  **测量坡度**：然后，我们站稳在这个点上，拿出“坡度计”（得分函数），测量一下沿着“基因”这个新方向，山坡有多陡。
3.  **判断**：
    *   如果山坡非常**陡峭**（得分函数的值很大），说明只要我们沿着“基因”这个方向走一小步，就能让模型变得更好（似然值显著上升）。因此，我们应该拒绝零模型，把基因变量加进来。
    *   如果山坡非常**平缓**（得分函数的值接近0），说明我们所处的位置已经很接近“基因”这个方向上的最高点了。再加入基因变量，对模型的改善不大。因此，我们没有理由拒绝零模型。

**请注意**：在整个过程中，我们从未计算或使用过“残差”这个词。我们只用到了对数似然函数的导数和零模型的参数估计。

### 2. 数学上的实现（为什么不需要残差）

我们用 $\ell(\boldsymbol{\beta})$ 表示包含所有变量的模型的对数似然函数。其中 $\boldsymbol{\beta}$ 包含了所有参数，包括您想检验的基因变量的系数 $\beta_{gene}$。

*   **原假设 ($H_0$)**: $\beta_{gene} = 0$。

得分检验的步骤如下：
1.  **拟合零模型**：在 $\beta_{gene} = 0$ 的约束下，最大化 $\ell(\boldsymbol{\beta})$，得到除了 $\beta_{gene}$ 之外其他所有参数的估计值，我们记为 $\tilde{\boldsymbol{\beta}}_0$。
2.  **计算得分**：计算**备择模型**的对数似然函数在 $\beta_{gene}$ 方向上的导数（得分），并代入**零模型**的估计值：
    $$ U_{gene} = \frac{\partial \ell(\boldsymbol{\beta})}{\partial \beta_{gene}} \Bigg|_{\boldsymbol{\beta}=(\tilde{\boldsymbol{\beta}}_0, \beta_{gene}=0)} $$
3.  **计算信息矩阵**：计算信息矩阵 $I(\boldsymbol{\beta})$，并代入**零模型**的估计值 $\tilde{\boldsymbol{\beta}}=(\tilde{\boldsymbol{\beta}}_0, 0)$。
4.  **构建检验统计量**：得分检验统计量（通常记为 $S$）是一个标准化的、平方后的得分值：
    $$ S = U_{gene}' [I(\tilde{\boldsymbol{\beta}})^{-1}]_{gene, gene} U_{gene} $$
    这个统计量近似服从**卡方分布**，其自由度等于新加入变量的个数（在这里是1）。

这个公式就是统计软件（如R的 `add1` 函数）在后台为您计算的内容。它直接操作对数似然函数的导数，完全绕过了残差。

### 3. “残差”的误解是从哪里来的？

这个直观但具有误导性的想法来自于**普通最小二乘法（OLS）线性回归**。在这个模型里，会发生一个美妙的巧合：

*   在线性回归模型 $y = \mathbf{X}\boldsymbol{\beta} + \varepsilon$ 中，对数似然函数关于某个新变量 $x_k$ 的系数 $\beta_k$ 的得分（一阶导数）可以被证明**正比于**：
    $$ \sum_{i=1}^{n} (y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0) \cdot x_{ik} $$
    其中，$(y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0)$ 正是**零模型的残差** $\tilde{e}_i$！
*   所以，得分检验统计量在这种情况下正比于**（零模型残差与新变量 $x_k$ 的相关系数）的平方**。

**结论**：在线性回归中，“检验得分”恰好简化成了“检验残差与新变量的相关性”。但这个简化形式并不适用于像有序逻辑回归这样更复杂的模型。对于这些模型，我们必须回到得分检验的原始定义——**基于对数似然函数的导数**。

### 总结

*   **得分检验的核心是“似然函数”**，而不是“残差”。
*   它通过评估在**零模型**的最优点上，向**备择模型**方向前进的“坡度”有多大，来判断新变量是否重要。
*   您**不需要，也不能**简单地通过计算某种残差然后看它和基因的相关性来手动完成得分检验（因为有序模型的残差形式复杂且不唯一）。
*   幸运的是，统计软件已经为您封装好了这个复杂的计算过程。当您调用类似 `add1(..., test="score")` 的函数时，它就是在后台执行上述基于导数的计算，为您提供一个可靠的卡方统计量和P值。

所以，您的思路是完全正确的，只是在实现上，我们应该信任并使用统计软件内置的、更具普适性的得分检验功能，而不是试图去手动复制线性回归中那个“残差”的特例。





