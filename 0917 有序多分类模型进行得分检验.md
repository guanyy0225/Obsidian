把得分检验需要的组件放在Ordinal_exactScore 函数里

好的，这是一个非常专业的统计学问题。有序多分类模型（Ordered Multiclass Model），最常见的是**比例优势逻辑回归（Proportional Odds Logistic Regression）**，其得分检验（Score Test）是一种重要且高效的假设检验方法。

下面我将详细解释有序多分类模型中得分检验的原理、步骤和一个关键应用。

### 核心概念回顾

#### 1. 有序多分类模型（比例优势模型）
该模型用于因变量是有序类别（如：差、中、好；轻度、中度、重度）的情况。其核心公式是：
$$ \text{logit} [P(Y \le j)] = \log \left( \frac{P(Y \le j)}{1 - P(Y \le j)} \right) = \alpha_j - \boldsymbol{\beta}^T \mathbf{X} $$
其中：
*   $Y$ 是有序的因变量，有 $J$ 个类别。
*   $j$ 是类别，$j = 1, 2, ..., J-1$。
*   $P(Y \le j)$ 是观测值属于类别 $j$ 或更低类别的累积概率。
*   $\alpha_j$ 是第 $j$ 个类别的**截距**或**切点（cut-point）**，满足 $\alpha_1 < \alpha_2 < ... < \alpha_{J-1}$。
*   $\boldsymbol{\beta}$ 是自变量 $\mathbf{X}$ 的**系数向量**。关键假设是，这个 $\boldsymbol{\beta}$ 对所有的 $j$ 都是相同的，这就是“比例优势假设”。

#### 2. 得分检验（Score Test）
得分检验，也称拉格朗日乘数检验（Lagrange Multiplier Test），是与瓦尔德检验（Wald Test）和似然比检验（Likelihood Ratio Test）并列的三大经典假设检验方法。

*   **核心优势**：它**只需要拟合零假设（H₀）下的简化模型**，而不需要拟合备择假设（Hₐ）下的复杂模型。这在复杂模型难以收敛时特别有用。
*   **基本原理**：检验的核心思想是评估在零假设模型参数估计处，对数似然函数关于“被约束为零的参数”的梯度（或称得分，Score）是否显著不为零。如果梯度很陡峭，说明如果释放这个参数的约束，似然函数值会显著增加，因此我们应该拒绝零假设。

### 如何对有序多分类模型进行得分检验

得分检验最常见的用途是检验**一个或多个新自变量的系数是否显著不为零**。

#### 步骤

**假设：**
*   我们有一个已经拟合好的模型（零假设模型 H₀），包含自变量集合 $\mathbf{X}_1$。
*   我们想检验是否应该加入新的自变量集合 $\mathbf{X}_2$。

**检验的假设：**
*   **H₀**: 新增变量的系数为零 ($\boldsymbol{\beta}_2 = \mathbf{0}$)。
*   **Hₐ**: 新增变量的系数至少有一个不为零 ($\boldsymbol{\beta}_2 \neq \mathbf{0}$)。

**执行过程：**

1.  **拟合零假设模型**：
    只使用自变量 $\mathbf{X}_1$ 拟合比例优势逻辑回归模型：
    $$ \text{logit} [P(Y \le j)] = \alpha_j - \boldsymbol{\beta}_1^T \mathbf{X}_1 $$
    得到在 H₀ 下的参数最大似然估计值 $\tilde{\boldsymbol{\alpha}}$ 和 $\tilde{\boldsymbol{\beta}}_1$。

2.  **计算得分向量（Score Vector）**：
    得分向量 $U(\boldsymbol{\theta})$ 是对数似然函数 $L(\boldsymbol{\theta})$ 关于所有参数 $\boldsymbol{\theta} = (\boldsymbol{\alpha}, \boldsymbol{\beta}_1, \boldsymbol{\beta}_2)$ 的一阶偏导数。
    $$ U(\boldsymbol{\theta}) = \frac{\partial L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} $$
    我们需要计算在 H₀ 模型估计值处的得分，即 $U(\tilde{\boldsymbol{\theta}})$，其中 $\tilde{\boldsymbol{\theta}} = (\tilde{\boldsymbol{\alpha}}, \tilde{\boldsymbol{\beta}}_1, \mathbf{0})$。
    根据最大似然估计的性质，得分向量中与 $\boldsymbol{\alpha}$ 和 $\boldsymbol{\beta}_1$ 对应的部分在 $\tilde{\boldsymbol{\theta}}$ 处的值为零。因此，我们只需要关注与 $\boldsymbol{\beta}_2$ 相关的部分 $U_{\boldsymbol{\beta}_2}(\tilde{\boldsymbol{\theta}})$。

3.  **计算信息矩阵（Information Matrix）**：
    信息矩阵 $I(\boldsymbol{\theta})$ 是对数似然函数负二阶偏导数的期望值。它反映了参数估计的精度。
    $$ I(\boldsymbol{\theta}) = -E \left[ \frac{\partial^2 L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta} \partial \boldsymbol{\theta}^T} \right] $$
    同样，我们在 H₀ 模型估计值处计算信息矩阵 $I(\tilde{\boldsymbol{\theta}})$。

4.  **构建得分检验统计量**：
    得分检验统计量 $S$ 的一般形式是：
    $$ S = U(\tilde{\boldsymbol{\theta}})^T [I(\tilde{\boldsymbol{\theta}})]^{-1} U(\tilde{\boldsymbol{\theta}}) $$
    由于 $U_{\boldsymbol{\alpha}}$ 和 $U_{\boldsymbol{\beta}_1}$ 部分为零，这个公式可以简化为只涉及 $U_{\boldsymbol{\beta}_2}$ 和信息矩阵对应分块的二次型。

5.  **判断显著性**：
    在零假设 H₀ 成立的条件下，得分统计量 $S$ 近似服从**卡方分布（Chi-squared distribution）**。
    *   **自由度（df）**：等于被检验的参数个数，即自变量集合 $\mathbf{X}_2$ 中变量的数量。
    *   **决策**：计算出 $S$ 的值后，根据卡方分布和自由度计算 P 值。如果 P 值小于预设的显著性水平（如 0.05），则拒绝零假设，认为新加入的变量 $\mathbf{X}_2$ 是显著的。






非常好的问题！估计有序多分类模型的残差是一个比线性回归复杂得多的高级话题。原因在于，模型的因变量是类别（如“满意”），而不是一个数值，所以我们无法像线性回归那样简单地用 `观测值 - 预测值` 来计算残差。

因此，研究者们提出了几种不同的方法来定义和计算有序模型的“残差”，每种方法都有其特定的用途和解释。下面我将介绍几种主流的方法，从概念到实践。

### 核心挑战

*   **观测值 (Y)** 是一个类别，例如 `k=3`（“一般”）。
*   **预测值 ($\hat{Y}$)** 是一组概率，例如 `P(Y=1)=0.1, P(Y=2)=0.3, P(Y=3)=0.4, ...`。
*   你不能计算 `“一般” - 0.4`。

我们需要找到一种合理的方式来量化模型对每个观测点的“错误程度”。

---

### 方法一：潜在变量残差 (Latent Variable Residuals)

这是**概念上最接近**线性回归残差的方法。

1.  **回顾模型**：有序模型假设存在一个不可观测的连续潜在变量 $y^*$，其模型为：
    $$
    y_i^* = \boldsymbol{\beta}' \mathbf{X}_i + \varepsilon_i
    $$
    其中，$\varepsilon_i$ 是一个遵循特定分布（通常是Logistic或正态分布）的误差项。

2.  **定义残差**：在这个潜在尺度上，残差就是这个误差项：
    $$
    \text{residual}_i = \varepsilon_i = y_i^* - \boldsymbol{\beta}' \mathbf{X}_i
    $$

3.  **问题**：我们永远无法观测到 $y_i^*$ 的真实值。我们只知道它落在了某个区间内。例如，如果观测到类别 $k$，我们只知道 $\tau_{k-1} < y_i^* \le \tau_k$。

4.  **解决方案**：我们可以估计 $y_i^*$ 在其所属区间内的**期望值**。对于观测到类别 $k$ 的样本 $i$，其潜在残差的估计值是：
    $$
    \hat{\varepsilon}_i = E[y_i^* | \tau_{k-1} < y_i^* \le \tau_k] - \boldsymbol{\beta}' \mathbf{X}_i
    $$
    这个期望值是基于被截断的Logistic（或正态）分布的均值来计算的。

*   **优点**：理论上最优雅，直接对应模型的潜在变量假设。
*   **缺点**：计算复杂，不直观，并且其分布依赖于模型的假设。
*   **用途**：主要用于理论研究和模型诊断的高级探索。

---

### 方法二：代理残差 (Surrogate Residuals) - 现代推荐方法

这是一种非常巧妙且实用的现代方法，它能将有序结果“转化”为一个连续的残差，使其性质类似于标准正态分布的残差。

**计算步骤**：
1.  对于一个真实类别为 $j$ 的观测 $i$，首先从模型中计算出两个累积概率：
    *   $a = P(Y_i < j) = P(Y_i \le j-1)$
    *   $b = P(Y_i \le j)$

2.  从区间 $[a, b]$ 上的均匀分布中随机抽取一个数值 $u_i$。
    $$
    u_i \sim \text{Uniform}(a, b)
    $$
    这个 $u_i$ 可以看作是将离散的类别“平滑”地映射到了 (0, 1) 区间上。

3.  将这个 $u_i$ 通过**标准正态分位函数**（probit link）或**标准Logit分位函数**（logit link）进行转换，得到代理残差 $r_i^S$。
    *   如果模型是序数Probit模型，则：$r_i^S = \Phi^{-1}(u_i)$
    *   如果模型是序数Logit模型，则：$r_i^S = \text{logit}(u_i) = \log\left(\frac{u_i}{1-u_i}\right)$

**核心思想**：如果模型是完美的，那么生成的 $u_i$ 序列应该服从 (0, 1) 上的标准均匀分布。经过逆CDF变换后，得到的代理残差 $r_i^S$ 应该近似服从**标准正态分布**或**标准Logistic分布**。

*   **优点**：
    *   生成的残差是连续的。
    *   如果模型拟合良好，残差分布是已知的（如标准正态分布）。
    *   可以直接用于我们熟悉的**残差诊断图**，如 Q-Q 图（检查正态性）、残差 vs. 拟合值图（检查异方差性）等。
*   **缺点**：包含随机成分，每次计算的结果会略有不同（但整体模式不变）。
*   **用途**：**强烈推荐用于实际的模型诊断和可视化**。R语言中的 `sure` 包专门用于计算这类残差。

---

### 方法三：广义残差 (Generalized Residuals)

这种方法将有序多分类模型视为广义线性模型（GLM）的扩展，并借用GLM中的残差定义。最常见的有**皮尔逊残差 (Pearson Residuals)** 和 **偏差残差 (Deviance Residuals)**。

对于有 $K$ 个类别的单个观测 $i$（其实际类别为 $j$），我们可以看作它有 $K$ 个可能的结果。
*   观测向量：$\mathbf{d}_i = (d_{i1}, d_{i2}, \dots, d_{iK})$，其中 $d_{ij}=1$，其余为0。
*   预测概率向量：$\hat{\mathbf{p}}_i = (\hat{p}_{i1}, \hat{p}_{i2}, \dots, \hat{p}_{iK})$。

1.  **皮尔逊残差**：
    对于每个类别 $k$，可以计算一个皮尔逊残差分量：
    $$
    r_{ik}^P = \frac{d_{ik} - \hat{p}_{ik}}{\sqrt{\hat{p}_{ik}}}
    $$
    一个观测点会得到一个残差向量。通常会计算一个汇总值，例如所有分量的平方和。

2.  **偏差残差**：
    偏差是衡量模型饱和度（完美拟合）与当前模型对数似然差异的指标。每个观测点的偏差残差是其对总偏差贡献的带符号平方根。
    $$
    r_i^D = \text{sign}(d_{ij} - \hat{p}_{ij}) \sqrt{2 \left| \log(\text{perfect fit likelihood}) - \log(\text{model likelihood for obs } i) \right|}
    $$
    对于多分类，其具体形式为：$r_i^D = \text{sign}(1 - \hat{p}_{ij}) \sqrt{-2 \log(\hat{p}_{ij})}$

*   **优点**：有坚实的统计理论基础（源自GLM），常用于检验模型的整体拟合优度。
*   **缺点**：对于单个观测点的解释不如代理残差直观，并且每个观测点可能是一个向量，不方便绘图。
*   **用途**：主要用于拟合优度检验（例如，所有皮尔逊残差的平方和近似服从卡方分布）。

### 总结与建议

| 残差类型 | 核心思想 | 优点 | 缺点 | 最佳用途 |
| :--- | :--- | :--- | :--- | :--- |
| **潜在变量残差** | 估计潜在连续变量 $y^*$ 上的误差项 $\varepsilon$ | 理论上最纯粹，直接关联模型假设 | 计算复杂，不直观，依赖模型假设 | 理论分析，深入的模型诊断 |
| **代理残差 (Surrogate)** | 将离散结果随机映射回连续尺度 | **易于可视化**，可直接套用标准残差图（Q-Q图等），分布已知 | 包含随机性，结果不唯一 | **日常模型诊断和可视化分析（强烈推荐）** |
| **广义残差 (Pearson/Deviance)** | 借鉴广义线性模型的思想，衡量概率偏差 | 统计理论坚实，与似然函数紧密相关 | 不直观，常为向量形式，不易于单个观测点的诊断 | 模型的整体**拟合优度检验** |

对于实践者来说，**代理残差 (Surrogate Residuals)** 是目前进行有序多分类模型残差分析和诊断的最强大、最方便的工具。它巧妙地解决了“无连续残差”的难题，让我们能够使用熟悉的图形化工具来评估模型的假设和性能。







---

### 问题二：有序多分类模型如何进行得分检验 (Score Test)？

“得分检验”（Score Test，也称拉格朗日乘子检验，Lagrange Multiplier Test）是统计推断中的三大经典检验方法之一（另两个是Wald检验和似然比检验）。在有序多分类模型的背景下，得分检验主要应用于以下两个关键场景：

#### 1. 检验解释变量的显著性 (Testing for Independence)

这是得分检验最常见的用途之一。我们要检验某个或某些解释变量的效应是否为零（即 $\boldsymbol{\beta} = \mathbf{0}$）。

*   **基本原理**：得分检验的特点是它**仅需要在原假设（$H_0$）下拟合模型**。它通过评估对数似然函数在原假设参数估计处的“梯度”（即得分函数）是否显著不为零来判断。如果梯度足够大，则说明参数稍微偏离原假设值就能显著提升似然函数，因此我们有理由拒绝原假设。
*   **与非参数检验的联系**：本书在 **第3.7节 “Connections with Nonparametric Rank Methods”** 中指出了一个非常深刻的联系：
    *   对于比较两个组的比例优势模型，检验组间差异（即 $\beta=0$）的**得分检验**在数学上**等价于**经典的非参数检验——**Wilcoxon-Mann-Whitney 检验**。
    *   对于比较多个组的情况，得分检验等价于 **Kruskal-Wallis 检验**。
    *   这完美地体现了有序回归模型是如何将经典的秩和检验思想模型化的。

#### 2. 检验比例优势假设 (Testing the Proportional Odds Assumption)

这是得分检验在有序模型中一个**非常特殊且重要的应用**，本书在 **第3.5.5节 “Testing the Proportional Odds Assumption”** 中有明确讨论。

*   **检验目的**：比例优势假设（即所有累积Logit共享同一个 $\boldsymbol{\beta}$）是模型的基础。我们需要检验这个假设是否成立。
*   **检验原理**：
    *   **原假设 ($H_0$)**: 比例优势模型成立（所有 $\beta_j$ 都相等，即 $\boldsymbol{\beta}_1 = \boldsymbol{\beta}_2 = \dots = \boldsymbol{\beta}_{c-1}$）。
    *   **备择假设 ($H_a$)**: 比例优势模型不成立（至少有一对 $\boldsymbol{\beta}_j$ 不相等）。
    *   得分检验通过在原假设（比例优势模型）下评估模型，来检验是否有证据表明允许每个累积Logit拥有自己独立的系数 $\boldsymbol{\beta}_j$ 会显著改善模型拟合。
*   **实用性**：这个检验非常实用，因为备择假设下的模型（非比例优势模型）可能很难直接拟合（有时会导致概率交叉等问题）。得分检验因为它只依赖于原假设下的模型拟合，所以总是可以计算的。
*   **软件实现**：许多统计软件（如SAS的PROC LOGISTIC）会自动报告这个比例优势假设的得分检验结果。

**总结**：根据阿格雷斯蒂的这本著作，有序多分类模型的核心建模方法是**比例优势模型**，它对累积概率的Logit进行建模。而**得分检验**在其中扮演两大角色：一是作为一种检验变量显著性的方法（并与传统非参数秩和检验有深刻联系），二是一个专门用来**诊断比例优势模型核心假设有效性**的关键工具。






极好的问题！您正触及到一个非常核心且普遍的误解。

简单直接的回答是：**得分检验（Score Test）的计算过程本身就不需要先估计残差。** 它是直接基于对数似然函数（Log-Likelihood Function）的导数（即得分函数）来构建的。

我们之所以常常把它和残差联系起来，是因为在线性回归这个**非常特殊且简单的模型**中，得分检验的数学形式恰好可以被简化为“检验残差与新变量的相关性”。这个特例帮助我们建立了直观的理解，但这个“残差”步骤并不是得分检验的普适定义。

### 2. 数学上的实现（为什么不需要残差）

我们用 $\ell(\boldsymbol{\beta})$ 表示包含所有变量的模型的对数似然函数。其中 $\boldsymbol{\beta}$ 包含了所有参数，包括您想检验的基因变量的系数 $\beta_{gene}$。

*   **原假设 ($H_0$)**: $\beta_{gene} = 0$。

得分检验的步骤如下：
1.  **拟合零模型**：在 $\beta_{gene} = 0$ 的约束下，最大化 $\ell(\boldsymbol{\beta})$，得到除了 $\beta_{gene}$ 之外其他所有参数的估计值，我们记为 $\tilde{\boldsymbol{\beta}}_0$。
2.  **计算得分**：计算**备择模型**的对数似然函数在 $\beta_{gene}$ 方向上的导数（得分），并代入**零模型**的估计值：
    $$ U_{gene} = \frac{\partial \ell(\boldsymbol{\beta})}{\partial \beta_{gene}} \Bigg|_{\boldsymbol{\beta}=(\tilde{\boldsymbol{\beta}}_0, \beta_{gene}=0)} $$
3.  **计算信息矩阵**：计算信息矩阵 $I(\boldsymbol{\beta})$，并代入**零模型**的估计值 $\tilde{\boldsymbol{\beta}}=(\tilde{\boldsymbol{\beta}}_0, 0)$。
4.  **构建检验统计量**：得分检验统计量（通常记为 $S$）是一个标准化的、平方后的得分值：
    $$ S = U_{gene}' [I(\tilde{\boldsymbol{\beta}})^{-1}]_{gene, gene} U_{gene} $$
    这个统计量近似服从**卡方分布**，其自由度等于新加入变量的个数（在这里是1）。

这个公式就是统计软件（如R的 `add1` 函数）在后台为您计算的内容。它直接操作对数似然函数的导数，完全绕过了残差。

### 3. “残差”的误解是从哪里来的？

这个直观但具有误导性的想法来自于**普通最小二乘法（OLS）线性回归**。在这个模型里，会发生一个美妙的巧合：

*   在线性回归模型 $y = \mathbf{X}\boldsymbol{\beta} + \varepsilon$ 中，对数似然函数关于某个新变量 $x_k$ 的系数 $\beta_k$ 的得分（一阶导数）可以被证明**正比于**：
    $$ \sum_{i=1}^{n} (y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0) \cdot x_{ik} $$
    其中，$(y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0)$ 正是**零模型的残差** $\tilde{e}_i$！
*   所以，得分检验统计量在这种情况下正比于**（零模型残差与新变量 $x_k$ 的相关系数）的平方**。

**结论**：在线性回归中，“检验得分”恰好简化成了“检验残差与新变量的相关性”。但这个简化形式并不适用于像有序逻辑回归这样更复杂的模型。对于这些模型，我们必须回到得分检验的原始定义——**基于对数似然函数的导数**。

### 总结

*   **得分检验的核心是“似然函数”**，而不是“残差”。
*   它通过评估在**零模型**的最优点上，向**备择模型**方向前进的“坡度”有多大，来判断新变量是否重要。
*   您**不需要，也不能**简单地通过计算某种残差然后看它和基因的相关性来手动完成得分检验（因为有序模型的残差形式复杂且不唯一）。
*   幸运的是，统计软件已经为您封装好了这个复杂的计算过程。当您调用类似 `add1(..., test="score")` 的函数时，它就是在后台执行上述基于导数的计算，为您提供一个可靠的卡方统计量和P值。

所以，您的思路是完全正确的，只是在实现上，我们应该信任并使用统计软件内置的、更具普适性的得分检验功能，而不是试图去手动复制线性回归中那个“残差”的特例。




您是对的！非常抱歉，我之前的回答陷入了一个思维定式。您精确地指出了问题的关键：**真正的得分检验在理论上是不需要计算任何形式的“残差”的**。我之前的代码只是将残差的计算步骤从一个函数移到了另一个函数，但这并没有实现您想要的“跳过残差”的本质。

让我们这次纠正过来，直接从**对数似然函数的一阶导数（得分函数）** 出发来构建检验。这才是得分检验最根本的定义。

幸运的是，对于像 `clm` 对象这样的广义线性模型，我们可以通过 `estfun` 函数（在 `sandwich` 包中）来方便地获得每个观测对对数似然函数的贡献（即所谓的“经验估计函数”或“得分贡献”）。这让我们能够完全避免手动计算潜在变量和残差。

---

### 完全重构：直接使用得分函数的 `Ordinal_exactScore`

这个版本的 `Ordinal_exactScore` 将不再包含任何 `dnorm`, `pnorm`, `lower_b`, `upper_b` 等与潜在变量残差相关的计算。它将直接使用 `sandwich::estfun` 来获取核心的得分贡献。

```R
# 确保必要的库已加载
library(ordinal)
library(sandwich) # 需要这个包来获取 estfun
library(Matrix)   # 用于稀疏矩阵

Ordinal_score <- function(fit_null, G_mat) {

  # --- Part 1: Input Validation and Object Extraction ---
  if (!"fit_clm" %in% names(fit_null) || !inherits(fit_null$fit_clm, "clm")) {
    stop("The 'fit_null' object must be the output of NullModel, containing a 'fit_clm' element.")
  }
  
  clm_obj <- fit_null$fit_clm
  X_mat <- model.matrix(clm_obj)
  n_samples <- nrow(X_mat)
  
  # --- Part 2: Calculate Score (U) and Information Matrix (V) ---
  
  # U = G' * (Scores_i)
  # V = G' * Cov(Scores_i) * G 
  #   = G' * [ E(Scores_i' * Scores_i) - E(Scores_i)' * Cov(beta_hat) * E(Scores_i) ] * G
  # (Scores_i) 是每个观测i对所有参数的得分贡献向量
  # E(Scores_i) 是得分贡献对模型矩阵X的投影
  
  # 2a: 获取每个观测对所有参数（阈值+协变量）的得分贡献
  # estfun返回一个 n x k 的矩阵，k是参数总数
  # 这是得分检验的核心，完全绕过了残差计算
  scores_per_obs <- sandwich::estfun(clm_obj) 
  
  # 2b: 计算总得分 U = G' * S_residuals
  # 这里的“残差”S_residuals是模型对新变量G的得分，它等于 G 对总得分的投影
  # 为了计算，我们需要将G投影到与X正交的空间
  
  # 计算信息矩阵的逆 I⁻¹ (即 vcov)
  # vcov(clm_obj) 返回的是 (X'WX)⁻¹
  I_inv <- vcov(clm_obj) 
  
  # 计算 U = G' * S_residuals
  # 这部分计算比较复杂，我们直接使用一个已知的等价公式
  # U = G' * s, where s is the score residual. s = y* - X(X'X)^-1X'y*
  # 对于GLM，这等价于 s = W * (y_latent - mu_latent)
  # 但我们可以用更直接的方式计算
  
  # U_beta = S_beta - I_beta,alpha * I_alpha,alpha^-1 * S_alpha
  # 其中 S_beta 是对beta的得分，S_alpha是对alpha的得分
  # 但最简单的形式是：
  # Score = G' * W * (y_latent - mu_latent)
  
  # 让我们回到您原始代码的逻辑，但用estfun来重建它。
  # 原始代码中的 W * residuals 是关键。
  # W * residuals 是对数似然函数关于线性预测器 η 的导数。
  # 我们可以通过链式法则从estfun得到这个值。
  # ∂l/∂β = ∂l/∂η * ∂η/∂β = ∂l/∂η * X
  # 所以 ∂l/∂η ≈ (S * X') * (X*X')⁻¹ 
  # 这个方法很复杂。让我们用一个更简单、等价的思路。

  # --- 替代方法：使用辅助回归 ---
  # 得分检验在数值上等价于：
  # 1. 计算一个“工作响应变量” z
  # 2. 对 z ~ G + X 进行加权线性回归
  # 3. 检验 G 的系数
  
  # 让我们坚持矩阵代数，因为它更通用
  
  # 计算 W * residuals 的等价物
  # 从 estfun 中分离出对协变量系数的得分贡献
  n_thresholds <- length(clm_obj$alpha)
  n_covars <- ncol(X_mat) - n_thresholds # X_mat includes intercepts for thresholds
  
  # estfun 的列顺序是：协变量系数，然后是阈值
  # 注意: clm的model.matrix设计可能不同，需要确认
  # 确认一下参数顺序
  param_names <- names(coef(clm_obj))
  cov_names <- setdiff(param_names, names(clm_obj$alpha))
  
  # X_mat for clm has a tricky structure. Let's use `clm_obj$model` to be safe
  X_mat_covars_only <- model.matrix(clm_obj$terms$beta, clm_obj$model)
  
  # 这是对协变量（β）的得分贡献
  scores_beta <- scores_per_obs[, cov_names, drop = FALSE]
  
  # 计算得分 U
  # U = G' * (y* - mu*) = G' * W⁻¹ * s_beta
  # 这需要 W 矩阵，我们还是需要计算它
  # 让我们回到计算 W 的步骤，因为它是信息矩阵的一部分，无法绕过
  
  # --- 重新审视和最终方案 ---
  # 结论是：即使我们不称其为“残差”，得分检验的方差计算中
  # 那个权重矩阵 W (在GLM中是 diag(Var(y))⁻¹) 是不可避免的。
  # 它是Fisher信息矩阵的核心组成部分。
  # 您的原始代码逻辑是正确的，它计算了构建得分检验所需的所有必要组件。
  # 那个 `residuals` 变量只是一个中间产物，它在数学上是 ∂l/∂η (对数似然关于线性预测器的导数) 的一个缩放版本。
  
  # 因此，最清晰的做法是，承认这些组件是计算所必需的，但强调它们
  # 是从似然函数理论推导出来的，而不是一个独立的“残差”概念。
  
  # 我们将采用一个混合方法：重用上一版代码的计算逻辑，因为它在数学上是
  # 正确的，但重新命名变量，以强调我们是在计算似然函数的导数和信息矩阵，
  # 而不是在做传统的“残差分析”。
  
  eta <- clm_obj$location
  thresholds <- c(-Inf, clm_obj$alpha, Inf)
  y_idx <- as.numeric(clm_obj$y)
  
  lower_b <- thresholds[y_idx] - eta
  upper_b <- thresholds[y_idx + 1] - eta
  prob_interval <- pnorm(upper_b) - pnorm(lower_b)
  
  # Component 1: Score contribution from each observation (∂l_i / ∂η_i)
  # 这可以看作是对线性预测器的得分，而不是残差
  score_contrib_eta <- (dnorm(lower_b) - dnorm(upper_b)) / prob_interval
  
  # Component 2: Fisher Information weight for each observation (I_i(η_i))
  # 这是 W 矩阵的对角线元素
  term1 <- (lower_b * dnorm(lower_b) - upper_b * dnorm(upper_b)) / prob_interval
  var_y_raw <- 1 + term1 - score_contrib_eta^2
  
  is_problematic <- !is.finite(var_y_raw) | var_y_raw < 1e-8
  weights <- 1 / var_y_raw # W = diag(weights)
  if (sum(is_problematic) > 0) {
    median_weight <- median(weights[!is_problematic], na.rm = TRUE)
    if (!is.finite(median_weight) || median_weight <= 0) { median_weight <- 1 }
    weights[is_problematic] <- median_weight
  }
  W_mat <- Diagonal(x = weights)

  # --- 计算得分检验 (现在使用新命名的变量) ---
  
  # U = G' * (∂l/∂η)
  Score <- as.vector(crossprod(G_mat, score_contrib_eta))
  
  # V = G' W G - G' W X (X' W X)⁻¹ X' W G
  X_t_W <- crossprod(X_mat, W_mat)
  XWX_mat <- X_t_W %*% X_mat
  XWX_inv <- solve(XWX_mat)
  
  G_prime_W_G <- crossprod(G_mat, W_mat %*% G_mat)
  G_prime_W_X <- crossprod(G_mat, W_mat %*% X_mat)
  
  Correction_Term <- G_prime_W_X %*% XWX_inv %*% t(G_prime_W_X)
  Var_mat <- G_prime_W_G - Correction_Term
  
  Variance <- diag(Var_mat)
  Variance[Variance <= 1e-8] <- 1e-8
  
  Stest <- Score^2 / Variance
  p_value <- pchisq(Stest, df = 1, lower.tail = FALSE)
  
  # --- 组装并返回结果 ---
  result_df <- data.frame(Score = Score, Variance = Variance, Stest = Stest, Pvalue = p_value)
  result_df$Est <- result_df$Score / result_df$Variance
  result_df$Est_se <- 1 / sqrt(result_df$Variance)
  
  results <- list(result = result_df, Score = Score, Covariance = Var_mat)
  return(results)
}
```

### 解释和结论

我深入研究了这个问题，结论如下：

1.  **您的原始代码在数学上是正确的**。它计算得分检验统计量的逻辑是标准且有效的。
2.  **“残差”这个词引起了混淆**。您代码中的 `residuals` 变量，在广义线性模型（GLM）的理论中，实际上是**工作残差 (working residual)** 的一部分，它等于 $y^* - \mu^*$（潜在变量与其期望的差异），也与对数似然函数关于线性预测器 $\eta$ 的一阶导数 $\frac{\partial \ell}{\partial \eta}$ 成正比。它是一个用于计算的中间量，而不是一个用于诊断的“最终残差”。
3.  **无法完全绕开这些计算**。得分检验的**方差**部分，$V = \text{Var}(U)$，其计算公式中必然会包含**信息矩阵**。对于GLM，信息矩阵 $I$ 的核心就是权重矩阵 $W$。在有序Probit模型中，$W = \text{diag}(1/\text{Var}(y_i^* | y_i))$，也就是您原始代码中计算的 `var_y` 的倒数。

**所以，最终的结论是：**

我们无法像使用 `sandwich::estfun` 那样用一个黑箱函数完全替代这些底层计算，因为我们需要这些组件（特别是`W_mat`）来构建**得分的方差**。

我上面提供的**修改后并重新命名的代码**是最佳实践：
*   **它在逻辑上与您的原始代码相同**，因为您的原始代码在数学上是正确的。
*   **它通过重命名变量**（例如，`residuals` 变成 `score_contrib_eta`，`1/var_y` 变成 `weights`）来更准确地反映我们正在做的事情：**我们是在构建似然函数的导数（得分）和信息矩阵（权重），而不是在进行传统的残差分析。**
*   这澄清了概念上的混淆：我们不是在“使用残差”，而是在“使用构建得分检验所必需的、从似然理论推导出的数学组件”。

希望这次的解释和代码能够彻底解决您的疑惑。您对这个问题的执着追问非常棒，它迫使我们回到了统计检验最根本的定义上！




您提的问题非常精准，直击要害！我很高兴能有机会澄清这一点，因为它对于正确理解和使用模型诊断至关重要。

### 1. 解释：“用于计算的中间量” vs “用于诊断的最终残差”

让我们来详细拆解这句话：
> “您代码中的 `residuals` 变量...实际上是...一个用于计算的中间量，而不是一个用于诊断的‘最终残差’。”

#### 1.1 “用于计算的中间量” (您代码中的 `residuals`)

*   **它是什么？** 您代码中的 `residuals` 计算的是在**潜在变量**尺度上，残差的**条件期望** $E(y^* - \mu^* | y)$。这里的 $y^*$ 是我们假设存在但无法观测的连续潜在变量，$\mu^*$ 是它的期望（即线性预测器 $\eta$），而 $y$ 是我们实际观测到的有序类别。这个值与对数似然函数关于线性预测器 $\eta$ 的导数（得分）成正比。
*   **它的作用是什么？** 它的核心作用是作为**构建得分检验统计量**和**Fisher信息矩阵**的数学组件。在GLM的迭代拟合算法（如IRLS）和得分检验的方差计算中，这个量是不可或缺的。
*   **为什么它不适合诊断？**
    1.  **它不是“中心化”的**：它的均值不保证为0。
    2.  **它的方差不为1**：它的方差不均匀，依赖于预测值，这就是为什么在计算方差时需要用 `var_y` (权重矩阵 W 的逆) 来进行标准化。
    3.  **它不是我们最终关心的“误差”**：我们最终关心的是模型在多大程度上“错过”了观测值，而这个量只是这个“错过”在数学推导中的一个中间步骤。

#### 1.2 “用于诊断的最终残差”

一个好的诊断用残差应该具备一些优良的性质，使得我们可以像在线性回归中那样直观地使用它：

*   **性质1：中心化**。如果模型是正确的，残差的均值应该接近0。
*   **性质2：方差齐性**。理想情况下，残差的方差应该是恒定的（homoscedastic），或者我们知道它的理论分布（如标准正态分布 N(0, 1)）。
*   **性质3：无模式**。将它与预测值或任何变量绘图，都不应该显示出系统性的模式。

对于有序模型，**代理残差 (Surrogate Residuals)** 是目前最符合这些优良性质、最适合用于诊断的“最终残差”。

**代理残差的计算方法** (如前所述):
1.  根据模型计算出观测 $i$ (真实类别为 $j$) 所属的累积概率区间 $[P(Y_i < j), P(Y_i \le j)]$。
2.  在该区间内随机均匀地抽取一个值 $u_i$。
3.  通过标准正态分位数函数（Probit的反函数）转换得到代理残差 $r_i^S = \Phi^{-1}(u_i)$。

如果模型拟合良好，这组 $r_i^S$ **将近似服从标准正态分布 N(0, 1)**。这使得它成为一个完美的诊断工具：你可以用它做Q-Q图来检查整体拟合，或者将它与任何被忽略的变量（如基因）绘图来发现潜在的关联。

---

### 2. 修改代码：分离计算与诊断

根据上面的澄清，我们现在对 `NullModel` 函数做一个最终的、逻辑上最清晰的修改。这个函数现在将返回**两种**类型的“残差”，并明确它们的用途：

1.  **`score_residuals`**: 这是您原始代码计算的量，我们保留它并重命名，明确其用途是**用于下游的得分检验计算**。
2.  **`diagnostic_residuals`**: 这是我们新加入的**代理残差**，它的用途是**用于模型诊断和可视化**。

这样，您的 `NullModel` 函数将变得更加强大和清晰。

### 修改后的 `NullModel` 代码

```R
# 载入必要的库
library(ordinal)
library(data.table)
library(Matrix)

NullModel <- function(genofile = NULL, phenofile, outcomeCol, sampleCol,
                              covCol = NULL, PRSCol = NULL, LOCO = TRUE, chr = NULL,
                              use_SPA = FALSE, range=c(-100,100), length.out = 1e4, verbose = FALSE) {

  # --- Part 1 & 2: Load, Prepare, and Match Data (No changes) ---
  if (!is.null(phenofile)) {
    if (is.character(phenofile)) {
      if (!file.exists(phenofile)) stop("Phenotype file does not exist!")
      use_data <- data.table::fread(phenofile, data.table = FALSE)
    } else {
      use_data <- as.data.frame(phenofile)
    }
    use_data <- na.omit(use_data[, c(sampleCol, outcomeCol, covCol, PRSCol)])
  } else {
    stop("You must provide the phenotype data via the 'phenofile' argument.")
  }
  use_data[[sampleCol]] <- as.character(use_data[[sampleCol]])

  if (!is.null(genofile)) {
    if (inherits(genofile, "SeqVarGDSClass")) {
      sample.geno <- SeqArray::seqGetData(genofile, "sample.id")
    } else if (is.character(genofile)) {
      fam_file <- paste0(genofile, ".fam")
      if (!file.exists(fam_file)) stop("PLINK .fam file not found!")
      sample.geno <- data.table::fread(fam_file, data.table = FALSE)$V2
    } else {
      stop("'genofile' must be a GDS object or a path to a PLINK file.")
    }
    sample.pheno <- use_data[, sampleCol]
    common_samples <- intersect(sample.pheno, sample.geno)
    if (length(common_samples) == 0) stop("No common samples found between phenotype and genotype files.")
    use_data <- use_data[use_data[, sampleCol] %in% common_samples, ]
    message(paste(nrow(use_data), "samples remain after matching."))
  }

  # --- Part 3: Dynamic Formula Construction (with fix for no covariates) ---
  if (!is.ordered(use_data[[outcomeCol]])) {
    use_data[[outcomeCol]] <- as.ordered(use_data[[outcomeCol]])
  }
  
  all_vars <- c(covCol, PRSCol)
  if (length(all_vars) == 0) {
    formula_text <- paste(outcomeCol, "~ 1")
  } else {
    formula_text <- paste(outcomeCol, "~", paste(all_vars, collapse = " + "))
  }
  formula_null <- as.formula(formula_text)

  # --- Part 4: Fit the Ordinal Null Model ---
  clm_obj  <- ordinal::clm(formula = formula_null, data = use_data, link = "probit", model = TRUE)
  if(verbose) print(summary(clm_obj))

  # --- Part 5: Calculate BOTH Types of Residuals and Required Components ---
  model_data <- clm_obj$model
  kept_row_indices <- as.numeric(rownames(model_data))
  sample_ids <- use_data[[sampleCol]][kept_row_indices]

  eta <- clm_obj$location
  thresholds <- c(-Inf, clm_obj$alpha, Inf)
  y_idx <- as.numeric(clm_obj$y)

  lower_b <- thresholds[y_idx] - eta
  upper_b <- thresholds[y_idx + 1] - eta
  prob_interval <- pnorm(upper_b) - pnorm(lower_b)

  # 5a: "Score Residuals" (中间计算量 for Score Test)
  score_residuals <- (dnorm(lower_b) - dnorm(upper_b)) / prob_interval
  
  # 5b: "Diagnostic Residuals" (最终诊断量, Surrogate Residuals)
  cum_prob_lower <- pnorm(lower_b)
  cum_prob_upper <- pnorm(upper_b)
  # 为每个观测生成一个随机数
  u_i <- runif(length(eta), min = cum_prob_lower, max = cum_prob_upper)
  diagnostic_residuals <- qnorm(u_i)
  
  # 5c: Components for Score Test Variance
  term1 <- (lower_b * dnorm(lower_b) - upper_b * dnorm(upper_b)) / prob_interval
  var_y_raw <- 1 + term1 - score_residuals^2
  
  is_problematic <- !is.finite(var_y_raw) | var_y_raw < 1e-8
  num_problematic <- sum(is_problematic)
  var_y <- var_y_raw
  if (num_problematic > 0) {
    median_var_y <- median(var_y[!is_problematic], na.rm = TRUE)
    if (!is.finite(median_var_y) || median_var_y < 1e-8) { median_var_y <- 1 }
    warning(paste0(num_problematic, " sample(s) had near-zero variance; reset to median (", signif(median_var_y, 4), ")."))
    var_y[is_problematic] <- median_var_y
  }

  X_mat <- model.matrix(clm_obj)
  W_mat <- Diagonal(x = 1 / var_y)
  X_t_W <- crossprod(X_mat, W_mat)
  XWX_mat <- X_t_W %*% X_mat
  XWX_inv <- solve(XWX_mat)
  WX_mat <- t(X_t_W)

  # --- Part 6: Assemble the Final List ---
  base_list <- list(
    score_residuals = score_residuals,         # 用于得分检验
    diagnostic_residuals = diagnostic_residuals, # 用于可视化诊断
    sample_ids = sample_ids,
    W_mat = W_mat,
    X_mat = X_mat,
    WX_mat = WX_mat,
    XWX_inv = XWX_inv,
    formula_null = formula(clm_obj),
    coefficients_null = coef(clm_obj),
    use_data = model_data,
    use_SPA = use_SPA
  )

  if (is.null(LOCO) || isFALSE(LOCO)) {
    fit_null <- c(base_list, list(LOCO = FALSE))
  } else {
    fit_null <- c(base_list, list(LOCO = TRUE, chr = chr))
  }
  
  # SPA part remains unchanged conceptually
  if(use_SPA){
    fit_null <- CGF4LatentRes(fit_null = fit_null, range = range, length.out = length.out, verbose = verbose)
    warning("use_SPA=TRUE is not yet implemented. Skipping CGF calculation.")
  }

  message("Ordinal null model fitting complete.")
  return(fit_null)
}
```
并且相应修改得分检验函数

```R
Ordinal_exactScore <- function(objNull, G_mat, use_SPA = NULL, SPA_filter = TRUE, SPA_filter_cutoff = 0.05, verbose = FALSE) {

  # Calculate the score vector U = G' * W * residuals
  Score <- as.vector(crossprod(G_mat, objNull$W_mat %*% objNull$score_residuals))

  # Calculate the main components of the variance-covariance matrix V
  G_prime_W_G <- crossprod(G_mat, objNull$W_mat %*% G_mat)
  G_prime_W_X <- crossprod(G_mat, objNull$WX_mat)
  Correction_Term <- G_prime_W_X %*% objNull$XWX_inv %*% t(G_prime_W_X)
  Var_mat <- G_prime_W_G - Correction_Term

  Variance <- diag(Var_mat)
  Variance[Variance <= 1e-8] <- 1e-8

  # Calculate single-variant score test statistics and p-values
  Stest <- Score^2 / Variance
  p_value <- pchisq(Stest, df = 1, lower.tail = FALSE)
  result_df <- data.frame(Score = Score, Variance = Variance, Stest = Stest, Pvalue = p_value)

  Est <- result_df$Score / result_df$Variance
  Est_se <- 1 / sqrt(result_df$Variance)

  result_df$Est <- Est
  result_df$Est_se <- Est_se

  results <- list(result = result_df, Score = Score, Covariance = Var_mat)
  return(results)
}

```








这是一个非常棒的问题，它触及了统计建模中一个既深刻又优美的连接点。您引用的那段话完全正确，而其背后的原因在于**得分统计量的数学结构**与**Wilcoxon-Mann-Whitney检验统计量的数学结构**，在特定条件下是完全一致的。

让我们一步步揭开这个等价关系的面纱。

### 1. 回顾两个核心概念

#### (a) Wilcoxon-Mann-Whitney (WMW) 检验

*   **核心思想**：比较两组数据的位置（中位数）是否有差异。
*   **计算基础**：**秩 (Ranks)**。它将两组数据合并排序，然后计算其中一组的**秩和 (Rank-Sum)**。
*   **检验统计量 (W)**：$W = \sum R_1$，即第一组所有观测值的秩的总和。检验时，会将这个观测到的秩和与它在零假设（两组无差异）下的期望值进行比较。

#### (b) 得分检验 (Score Test)

*   **核心思想**：检验在零假设（例如，某个系数 $\beta=0$）成立时，对数似然函数关于该系数的梯度（得分）是否显著不为零。
*   **计算基础**：**对数似然函数的一阶导数 (Score Function)**。
*   **检验统计量 (U)**：$U = \frac{\partial \ell(\boldsymbol{\theta})}{\partial \beta} \Big|_{\beta=0, \hat{\alpha}}$，其中 $\ell$ 是对数似然函数，检验是在零假设（$\beta=0$）下进行的，其他参数（如截距 $\alpha$）则使用它们在零假设下的最大似然估计值。

### 2. 揭示等价性：数学推导的直观解释

要证明两者等价，关键在于证明：**比例优势模型（Proportional Odds Model）中，用于检验组间差异的得分统计量 $U$，其数学形式可以被简化为Wilcoxon秩和统计量 $W$ 的一个线性函数。**

这个推导在McCullagh (1980) 的经典论文中有详细阐述，阿格雷斯蒂的书也引用了这一结论。下面是这个推导的直观步骤和逻辑：

#### 步骤一：写出比例优势模型的对数似然函数

对于比较两个组（用指示变量 $x_i=0$ 或 $x_i=1$ 表示）的比例优势模型，其形式为：
$$
\text{logit}[P(Y_i \le j)] = \alpha_j - \beta x_i
$$
其对数似然函数 $\ell(\alpha, \beta)$ 是基于所有观测数据的多项式概率构建的。

#### 步骤二：计算得分函数 $U$

我们需要计算对数似然函数 $\ell$ 关于我们感兴趣的参数 $\beta$ 的偏导数，并在零假设（$H_0: \beta=0$）下进行评估。
$$
U = \frac{\partial \ell}{\partial \beta} \Bigg|_{\beta=0}
$$
经过一系列复杂的求导和代数运算后，这个得分函数 $U$ 可以被简化成一个非常简洁的形式：
$$
U = \sum_{i=1}^{n} x_i (R_i - \bar{R})
$$
让我们来解读这个惊人的结果：

*   $x_i$ 是第 $i$ 个观测所属的组别（例如，1代表实验组，0代表对照组）。
*   $R_i$ 是第 $i$ 个观测在**所有合并样本**中的**平均秩 (midrank)**。
*   $\bar{R}$ 是所有观测的平均秩，即 $(n+1)/2$。

这个公式告诉我们，得分统计量 $U$ 正是**实验组 ($x_i=1$) 的所有观测的秩与其总体平均秩的离差之和**。

#### 步骤三：连接到Wilcoxon秩和统计量

现在，我们来看看Wilcoxon秩和统计量 $W$。
*   $W_1$ 是第一组（实验组，$x_i=1$）的秩和：$W_1 = \sum_{i \in \text{Group 1}} R_i$。
*   在零假设下，$W_1$ 的期望值为 $E(W_1) = n_1 \frac{n+1}{2} = n_1 \bar{R}$。

现在，我们再看一下得分统计量 $U$ 的公式：
$$
U = \sum_{i=1}^{n} x_i (R_i - \bar{R})
$$
由于 $x_i$ 只在第一组时为1，其他时候为0，所以这个求和只对第一组的成员有效：
$$
U = \sum_{i \in \text{Group 1}} (R_i - \bar{R}) = \left( \sum_{i \in \text{Group 1}} R_i \right) - \sum_{i \in \text{Group 1}} \bar{R}
$$
这可以被写作：
$$
U = W_1 - n_1 \bar{R} = W_1 - E(W_1)
$$
**这就是最终的、最核心的等价关系！**

**比例优势模型中检验组间差异的得分统计量 $U$，恰好等于Wilcoxon秩和统计量 $W_1$ 与其在零假设下期望值的差。**

由于一个统计量减去它的期望值只是一个中心化的线性变换，这并不改变其标准化后的检验结果。因此，基于 $U$ 的得分检验和基于 $W_1$ 的Wilcoxon秩和检验在数学上是**等价的**。

### 3. 为什么这个等价性如此重要？

这个发现不仅仅是一个数学巧合，它揭示了深刻的统计思想：

1.  **模型化的非参数方法**：比例优势模型可以被看作是**对WMW检验的一种模型化、参数化的推广**。WMW检验只能告诉你两组是否有差异，而比例优势模型还能告诉你差异的大小（通过 $\beta$ 的估计值），并且可以加入其他协变量进行调整。
2.  **理论的统一性**：它将看似分离的两个领域——参数模型（广义线性模型）和非参数检验（秩和检验）——完美地统一了起来。这表明，许多经典的非参数方法背后，都隐藏着一个潜在的、可以被参数化的模型。
3.  **稳健性来源的解释**：这个联系也解释了为什么比例优势模型对数据的分布具有稳健性。因为它在本质上是基于数据的**秩**来构建的，所以它继承了WMW检验对异常值和非正态分布的稳健性。

### 总结

得分检验和WMW检验之所以等价，是因为比例优势模型的对数似然函数经过求导和在零假设下简化后，其最终的数学形式**恰好是**Wilcoxon秩和统计量的中心化形式。

*   **WMW检验的核心是：(秩和 - 期望秩和)。**
*   **比例优势模型得分检验的核心也是：(秩和 - 期望秩和)。**

两者是同一枚硬币的两面。您的书中所引用的这个结论，是现代统计学中一个非常经典的例子，它展示了不同统计方法之间内在的、深刻的统一性。