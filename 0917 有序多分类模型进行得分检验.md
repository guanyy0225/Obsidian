把得分检验需要的组件放在Ordinal_exactScore 函数里

好的，这是一个非常专业的统计学问题。有序多分类模型（Ordered Multiclass Model），最常见的是**比例优势逻辑回归（Proportional Odds Logistic Regression）**，其得分检验（Score Test）是一种重要且高效的假设检验方法。

下面我将详细解释有序多分类模型中得分检验的原理、步骤和一个关键应用。

### 核心概念回顾

#### 1. 有序多分类模型（比例优势模型）
该模型用于因变量是有序类别（如：差、中、好；轻度、中度、重度）的情况。其核心公式是：
$$ \text{logit} [P(Y \le j)] = \log \left( \frac{P(Y \le j)}{1 - P(Y \le j)} \right) = \alpha_j - \boldsymbol{\beta}^T \mathbf{X} $$
其中：
*   $Y$ 是有序的因变量，有 $J$ 个类别。
*   $j$ 是类别，$j = 1, 2, ..., J-1$。
*   $P(Y \le j)$ 是观测值属于类别 $j$ 或更低类别的累积概率。
*   $\alpha_j$ 是第 $j$ 个类别的**截距**或**切点（cut-point）**，满足 $\alpha_1 < \alpha_2 < ... < \alpha_{J-1}$。
*   $\boldsymbol{\beta}$ 是自变量 $\mathbf{X}$ 的**系数向量**。关键假设是，这个 $\boldsymbol{\beta}$ 对所有的 $j$ 都是相同的，这就是“比例优势假设”。

#### 2. 得分检验（Score Test）
得分检验，也称拉格朗日乘数检验（Lagrange Multiplier Test），是与瓦尔德检验（Wald Test）和似然比检验（Likelihood Ratio Test）并列的三大经典假设检验方法。

*   **核心优势**：它**只需要拟合零假设（H₀）下的简化模型**，而不需要拟合备择假设（Hₐ）下的复杂模型。这在复杂模型难以收敛时特别有用。
*   **基本原理**：检验的核心思想是评估在零假设模型参数估计处，对数似然函数关于“被约束为零的参数”的梯度（或称得分，Score）是否显著不为零。如果梯度很陡峭，说明如果释放这个参数的约束，似然函数值会显著增加，因此我们应该拒绝零假设。

### 如何对有序多分类模型进行得分检验

得分检验最常见的用途是检验**一个或多个新自变量的系数是否显著不为零**。

#### 步骤

**假设：**
*   我们有一个已经拟合好的模型（零假设模型 H₀），包含自变量集合 $\mathbf{X}_1$。
*   我们想检验是否应该加入新的自变量集合 $\mathbf{X}_2$。

**检验的假设：**
*   **H₀**: 新增变量的系数为零 ($\boldsymbol{\beta}_2 = \mathbf{0}$)。
*   **Hₐ**: 新增变量的系数至少有一个不为零 ($\boldsymbol{\beta}_2 \neq \mathbf{0}$)。

**执行过程：**

1.  **拟合零假设模型**：
    只使用自变量 $\mathbf{X}_1$ 拟合比例优势逻辑回归模型：
    $$ \text{logit} [P(Y \le j)] = \alpha_j - \boldsymbol{\beta}_1^T \mathbf{X}_1 $$
    得到在 H₀ 下的参数最大似然估计值 $\tilde{\boldsymbol{\alpha}}$ 和 $\tilde{\boldsymbol{\beta}}_1$。

2.  **计算得分向量（Score Vector）**：
    得分向量 $U(\boldsymbol{\theta})$ 是对数似然函数 $L(\boldsymbol{\theta})$ 关于所有参数 $\boldsymbol{\theta} = (\boldsymbol{\alpha}, \boldsymbol{\beta}_1, \boldsymbol{\beta}_2)$ 的一阶偏导数。
    $$ U(\boldsymbol{\theta}) = \frac{\partial L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta}} $$
    我们需要计算在 H₀ 模型估计值处的得分，即 $U(\tilde{\boldsymbol{\theta}})$，其中 $\tilde{\boldsymbol{\theta}} = (\tilde{\boldsymbol{\alpha}}, \tilde{\boldsymbol{\beta}}_1, \mathbf{0})$。
    根据最大似然估计的性质，得分向量中与 $\boldsymbol{\alpha}$ 和 $\boldsymbol{\beta}_1$ 对应的部分在 $\tilde{\boldsymbol{\theta}}$ 处的值为零。因此，我们只需要关注与 $\boldsymbol{\beta}_2$ 相关的部分 $U_{\boldsymbol{\beta}_2}(\tilde{\boldsymbol{\theta}})$。

3.  **计算信息矩阵（Information Matrix）**：
    信息矩阵 $I(\boldsymbol{\theta})$ 是对数似然函数负二阶偏导数的期望值。它反映了参数估计的精度。
    $$ I(\boldsymbol{\theta}) = -E \left[ \frac{\partial^2 L(\boldsymbol{\theta})}{\partial \boldsymbol{\theta} \partial \boldsymbol{\theta}^T} \right] $$
    同样，我们在 H₀ 模型估计值处计算信息矩阵 $I(\tilde{\boldsymbol{\theta}})$。

4.  **构建得分检验统计量**：
    得分检验统计量 $S$ 的一般形式是：
    $$ S = U(\tilde{\boldsymbol{\theta}})^T [I(\tilde{\boldsymbol{\theta}})]^{-1} U(\tilde{\boldsymbol{\theta}}) $$
    由于 $U_{\boldsymbol{\alpha}}$ 和 $U_{\boldsymbol{\beta}_1}$ 部分为零，这个公式可以简化为只涉及 $U_{\boldsymbol{\beta}_2}$ 和信息矩阵对应分块的二次型。

5.  **判断显著性**：
    在零假设 H₀ 成立的条件下，得分统计量 $S$ 近似服从**卡方分布（Chi-squared distribution）**。
    *   **自由度（df）**：等于被检验的参数个数，即自变量集合 $\mathbf{X}_2$ 中变量的数量。
    *   **决策**：计算出 $S$ 的值后，根据卡方分布和自由度计算 P 值。如果 P 值小于预设的显著性水平（如 0.05），则拒绝零假设，认为新加入的变量 $\mathbf{X}_2$ 是显著的。




## 有序多分类的几种残差

非常好的问题！估计有序多分类模型的残差是一个比线性回归复杂得多的高级话题。原因在于，模型的因变量是类别（如“满意”），而不是一个数值，所以我们无法像线性回归那样简单地用 `观测值 - 预测值` 来计算残差。

因此，研究者们提出了几种不同的方法来定义和计算有序模型的“残差”，每种方法都有其特定的用途和解释。下面我将介绍几种主流的方法，从概念到实践。

### 核心挑战

*   **观测值 (Y)** 是一个类别，例如 `k=3`（“一般”）。
*   **预测值 ($\hat{Y}$)** 是一组概率，例如 `P(Y=1)=0.1, P(Y=2)=0.3, P(Y=3)=0.4, ...`。
*   你不能计算 `“一般” - 0.4`。

我们需要找到一种合理的方式来量化模型对每个观测点的“错误程度”。

---

### 方法一：潜在变量残差 (Latent Variable Residuals)

这是**概念上最接近**线性回归残差的方法。

1.  **回顾模型**：有序模型假设存在一个不可观测的连续潜在变量 $y^*$，其模型为：
    $$
    y_i^* = \boldsymbol{\beta}' \mathbf{X}_i + \varepsilon_i
    $$
    其中，$\varepsilon_i$ 是一个遵循特定分布（通常是Logistic或正态分布）的误差项。

2.  **定义残差**：在这个潜在尺度上，残差就是这个误差项：
    $$
    \text{residual}_i = \varepsilon_i = y_i^* - \boldsymbol{\beta}' \mathbf{X}_i
    $$

3.  **问题**：我们永远无法观测到 $y_i^*$ 的真实值。我们只知道它落在了某个区间内。例如，如果观测到类别 $k$，我们只知道 $\tau_{k-1} < y_i^* \le \tau_k$。

4.  **解决方案**：我们可以估计 $y_i^*$ 在其所属区间内的**期望值**。对于观测到类别 $k$ 的样本 $i$，其潜在残差的估计值是：
    $$
    \hat{\varepsilon}_i = E[y_i^* | \tau_{k-1} < y_i^* \le \tau_k] - \boldsymbol{\beta}' \mathbf{X}_i
    $$
    这个期望值是基于被截断的Logistic（或正态）分布的均值来计算的。

*   **优点**：理论上最优雅，直接对应模型的潜在变量假设。
*   **缺点**：计算复杂，不直观，并且其分布依赖于模型的假设。
*   **用途**：主要用于理论研究和模型诊断的高级探索。

---

### 方法二：代理残差 (Surrogate Residuals) - 现代推荐方法

这是一种非常巧妙且实用的现代方法，它能将有序结果“转化”为一个连续的残差，使其性质类似于标准正态分布的残差。

**计算步骤**：
1.  对于一个真实类别为 $j$ 的观测 $i$，首先从模型中计算出两个累积概率：
    *   $a = P(Y_i < j) = P(Y_i \le j-1)$
    *   $b = P(Y_i \le j)$

2.  从区间 $[a, b]$ 上的均匀分布中随机抽取一个数值 $u_i$。
    $$
    u_i \sim \text{Uniform}(a, b)
    $$
    这个 $u_i$ 可以看作是将离散的类别“平滑”地映射到了 (0, 1) 区间上。

3.  将这个 $u_i$ 通过**标准正态分位函数**（probit link）或**标准Logit分位函数**（logit link）进行转换，得到代理残差 $r_i^S$。
    *   如果模型是序数Probit模型，则：$r_i^S = \Phi^{-1}(u_i)$
    *   如果模型是序数Logit模型，则：$r_i^S = \text{logit}(u_i) = \log\left(\frac{u_i}{1-u_i}\right)$

**核心思想**：如果模型是完美的，那么生成的 $u_i$ 序列应该服从 (0, 1) 上的标准均匀分布。经过逆CDF变换后，得到的代理残差 $r_i^S$ 应该近似服从**标准正态分布**或**标准Logistic分布**。

*   **优点**：
    *   生成的残差是连续的。
    *   如果模型拟合良好，残差分布是已知的（如标准正态分布）。
    *   可以直接用于我们熟悉的**残差诊断图**，如 Q-Q 图（检查正态性）、残差 vs. 拟合值图（检查异方差性）等。
*   **缺点**：包含随机成分，每次计算的结果会略有不同（但整体模式不变）。
*   **用途**：**强烈推荐用于实际的模型诊断和可视化**。R语言中的 `sure` 包专门用于计算这类残差。

---

### 方法三：广义残差 (Generalized Residuals)

这种方法将有序多分类模型视为广义线性模型（GLM）的扩展，并借用GLM中的残差定义。最常见的有**皮尔逊残差 (Pearson Residuals)** 和 **偏差残差 (Deviance Residuals)**。

对于有 $K$ 个类别的单个观测 $i$（其实际类别为 $j$），我们可以看作它有 $K$ 个可能的结果。
*   观测向量：$\mathbf{d}_i = (d_{i1}, d_{i2}, \dots, d_{iK})$，其中 $d_{ij}=1$，其余为0。
*   预测概率向量：$\hat{\mathbf{p}}_i = (\hat{p}_{i1}, \hat{p}_{i2}, \dots, \hat{p}_{iK})$。

1.  **皮尔逊残差**：
    对于每个类别 $k$，可以计算一个皮尔逊残差分量：
    $$
    r_{ik}^P = \frac{d_{ik} - \hat{p}_{ik}}{\sqrt{\hat{p}_{ik}}}
    $$
    一个观测点会得到一个残差向量。通常会计算一个汇总值，例如所有分量的平方和。

2.  **偏差残差**：
    偏差是衡量模型饱和度（完美拟合）与当前模型对数似然差异的指标。每个观测点的偏差残差是其对总偏差贡献的带符号平方根。
    $$
    r_i^D = \text{sign}(d_{ij} - \hat{p}_{ij}) \sqrt{2 \left| \log(\text{perfect fit likelihood}) - \log(\text{model likelihood for obs } i) \right|}
    $$
    对于多分类，其具体形式为：$r_i^D = \text{sign}(1 - \hat{p}_{ij}) \sqrt{-2 \log(\hat{p}_{ij})}$

*   **优点**：有坚实的统计理论基础（源自GLM），常用于检验模型的整体拟合优度。
*   **缺点**：对于单个观测点的解释不如代理残差直观，并且每个观测点可能是一个向量，不方便绘图。
*   **用途**：主要用于拟合优度检验（例如，所有皮尔逊残差的平方和近似服从卡方分布）。

### 总结与建议

| 残差类型 | 核心思想 | 优点 | 缺点 | 最佳用途 |
| :--- | :--- | :--- | :--- | :--- |
| **潜在变量残差** | 估计潜在连续变量 $y^*$ 上的误差项 $\varepsilon$ | 理论上最纯粹，直接关联模型假设 | 计算复杂，不直观，依赖模型假设 | 理论分析，深入的模型诊断 |
| **代理残差 (Surrogate)** | 将离散结果随机映射回连续尺度 | **易于可视化**，可直接套用标准残差图（Q-Q图等），分布已知 | 包含随机性，结果不唯一 | **日常模型诊断和可视化分析（强烈推荐）** |
| **广义残差 (Pearson/Deviance)** | 借鉴广义线性模型的思想，衡量概率偏差 | 统计理论坚实，与似然函数紧密相关 | 不直观，常为向量形式，不易于单个观测点的诊断 | 模型的整体**拟合优度检验** |

对于实践者来说，**代理残差 (Surrogate Residuals)** 是目前进行有序多分类模型残差分析和诊断的最强大、最方便的工具。它巧妙地解决了“无连续残差”的难题，让我们能够使用熟悉的图形化工具来评估模型的假设和性能。








## 得分检验不需要残差的话可以怎么做

极好的问题！您正触及到一个非常核心且普遍的误解。

简单直接的回答是：**得分检验（Score Test）的计算过程本身就不需要先估计残差。** 它是直接基于对数似然函数（Log-Likelihood Function）的导数（即得分函数）来构建的。

我们之所以常常把它和残差联系起来，是因为在线性回归这个**非常特殊且简单的模型**中，得分检验的数学形式恰好可以被简化为“检验残差与新变量的相关性”。这个特例帮助我们建立了直观的理解，但这个“残差”步骤并不是得分检验的普适定义。

### 2. 数学上的实现（为什么不需要残差）

我们用 $\ell(\boldsymbol{\beta})$ 表示包含所有变量的模型的对数似然函数。其中 $\boldsymbol{\beta}$ 包含了所有参数，包括您想检验的基因变量的系数 $\beta_{gene}$。

*   **原假设 ($H_0$)**: $\beta_{gene} = 0$。

得分检验的步骤如下：
1.  **拟合零模型**：在 $\beta_{gene} = 0$ 的约束下，最大化 $\ell(\boldsymbol{\beta})$，得到除了 $\beta_{gene}$ 之外其他所有参数的估计值，我们记为 $\tilde{\boldsymbol{\beta}}_0$。
2.  **计算得分**：计算**备择模型**的对数似然函数在 $\beta_{gene}$ 方向上的导数（得分），并代入**零模型**的估计值：
    $$ U_{gene} = \frac{\partial \ell(\boldsymbol{\beta})}{\partial \beta_{gene}} \Bigg|_{\boldsymbol{\beta}=(\tilde{\boldsymbol{\beta}}_0, \beta_{gene}=0)} $$
3.  **计算信息矩阵**：计算信息矩阵 $I(\boldsymbol{\beta})$，并代入**零模型**的估计值 $\tilde{\boldsymbol{\beta}}=(\tilde{\boldsymbol{\beta}}_0, 0)$。
4.  **构建检验统计量**：得分检验统计量（通常记为 $S$）是一个标准化的、平方后的得分值：
    $$ S = U_{gene}' [I(\tilde{\boldsymbol{\beta}})^{-1}]_{gene, gene} U_{gene} $$
    这个统计量近似服从**卡方分布**，其自由度等于新加入变量的个数（在这里是1）。

这个公式就是统计软件（如R的 `add1` 函数）在后台为您计算的内容。它直接操作对数似然函数的导数，完全绕过了残差。

### 3. “残差”的误解是从哪里来的？

这个直观但具有误导性的想法来自于**普通最小二乘法（OLS）线性回归**。在这个模型里，会发生一个美妙的巧合：

*   在线性回归模型 $y = \mathbf{X}\boldsymbol{\beta} + \varepsilon$ 中，对数似然函数关于某个新变量 $x_k$ 的系数 $\beta_k$ 的得分（一阶导数）可以被证明**正比于**：
    $$ \sum_{i=1}^{n} (y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0) \cdot x_{ik} $$
    其中，$(y_i - \mathbf{X}_i'\tilde{\boldsymbol{\beta}}_0)$ 正是**零模型的残差** $\tilde{e}_i$！
*   所以，得分检验统计量在这种情况下正比于**（零模型残差与新变量 $x_k$ 的相关系数）的平方**。

**结论**：在线性回归中，“检验得分”恰好简化成了“检验残差与新变量的相关性”。但这个简化形式并不适用于像有序逻辑回归这样更复杂的模型。对于这些模型，我们必须回到得分检验的原始定义——**基于对数似然函数的导数**。

### 总结

*   **得分检验的核心是“似然函数”**，而不是“残差”。
*   它通过评估在**零模型**的最优点上，向**备择模型**方向前进的“坡度”有多大，来判断新变量是否重要。
*   您**不需要，也不能**简单地通过计算某种残差然后看它和基因的相关性来手动完成得分检验（因为有序模型的残差形式复杂且不唯一）。
*   幸运的是，统计软件已经为您封装好了这个复杂的计算过程。当您调用类似 `add1(..., test="score")` 的函数时，它就是在后台执行上述基于导数的计算，为您提供一个可靠的卡方统计量和P值。

所以，您的思路是完全正确的，只是在实现上，我们应该信任并使用统计软件内置的、更具普适性的得分检验功能，而不是试图去手动复制线性回归中那个“残差”的特例。







## **得分统计量与**Wilcoxon-Mann-Whitney检验统计量的等价性**

这是一个非常棒的问题，它触及了统计建模中一个既深刻又优美的连接点。您引用的那段话完全正确，而其背后的原因在于**得分统计量的数学结构**与**Wilcoxon-Mann-Whitney检验统计量的数学结构**，在特定条件下是完全一致的。

让我们一步步揭开这个等价关系的面纱。

### 1. 回顾两个核心概念

#### (a) Wilcoxon-Mann-Whitney (WMW) 检验

*   **核心思想**：比较两组数据的位置（中位数）是否有差异。
*   **计算基础**：**秩 (Ranks)**。它将两组数据合并排序，然后计算其中一组的**秩和 (Rank-Sum)**。
*   **检验统计量 (W)**：$W = \sum R_1$，即第一组所有观测值的秩的总和。检验时，会将这个观测到的秩和与它在零假设（两组无差异）下的期望值进行比较。

#### (b) 得分检验 (Score Test)

*   **核心思想**：检验在零假设（例如，某个系数 $\beta=0$）成立时，对数似然函数关于该系数的梯度（得分）是否显著不为零。
*   **计算基础**：**对数似然函数的一阶导数 (Score Function)**。
*   **检验统计量 (U)**：$U = \frac{\partial \ell(\boldsymbol{\theta})}{\partial \beta} \Big|_{\beta=0, \hat{\alpha}}$，其中 $\ell$ 是对数似然函数，检验是在零假设（$\beta=0$）下进行的，其他参数（如截距 $\alpha$）则使用它们在零假设下的最大似然估计值。

### 2. 揭示等价性：数学推导的直观解释

要证明两者等价，关键在于证明：**比例优势模型（Proportional Odds Model）中，用于检验组间差异的得分统计量 $U$，其数学形式可以被简化为Wilcoxon秩和统计量 $W$ 的一个线性函数。**

这个推导在McCullagh (1980) 的经典论文中有详细阐述，阿格雷斯蒂的书也引用了这一结论。下面是这个推导的直观步骤和逻辑：

#### 步骤一：写出比例优势模型的对数似然函数

对于比较两个组（用指示变量 $x_i=0$ 或 $x_i=1$ 表示）的比例优势模型，其形式为：
$$
\text{logit}[P(Y_i \le j)] = \alpha_j - \beta x_i
$$
其对数似然函数 $\ell(\alpha, \beta)$ 是基于所有观测数据的多项式概率构建的。

#### 步骤二：计算得分函数 $U$

我们需要计算对数似然函数 $\ell$ 关于我们感兴趣的参数 $\beta$ 的偏导数，并在零假设（$H_0: \beta=0$）下进行评估。
$$
U = \frac{\partial \ell}{\partial \beta} \Bigg|_{\beta=0}
$$
经过一系列复杂的求导和代数运算后，这个得分函数 $U$ 可以被简化成一个非常简洁的形式：
$$
U = \sum_{i=1}^{n} x_i (R_i - \bar{R})
$$
让我们来解读这个惊人的结果：

*   $x_i$ 是第 $i$ 个观测所属的组别（例如，1代表实验组，0代表对照组）。
*   $R_i$ 是第 $i$ 个观测在**所有合并样本**中的**平均秩 (midrank)**。
*   $\bar{R}$ 是所有观测的平均秩，即 $(n+1)/2$。

这个公式告诉我们，得分统计量 $U$ 正是**实验组 ($x_i=1$) 的所有观测的秩与其总体平均秩的离差之和**。

#### 步骤三：连接到Wilcoxon秩和统计量

现在，我们来看看Wilcoxon秩和统计量 $W$。
*   $W_1$ 是第一组（实验组，$x_i=1$）的秩和：$W_1 = \sum_{i \in \text{Group 1}} R_i$。
*   在零假设下，$W_1$ 的期望值为 $E(W_1) = n_1 \frac{n+1}{2} = n_1 \bar{R}$。

现在，我们再看一下得分统计量 $U$ 的公式：
$$
U = \sum_{i=1}^{n} x_i (R_i - \bar{R})
$$
由于 $x_i$ 只在第一组时为1，其他时候为0，所以这个求和只对第一组的成员有效：
$$
U = \sum_{i \in \text{Group 1}} (R_i - \bar{R}) = \left( \sum_{i \in \text{Group 1}} R_i \right) - \sum_{i \in \text{Group 1}} \bar{R}
$$
这可以被写作：
$$
U = W_1 - n_1 \bar{R} = W_1 - E(W_1)
$$
**这就是最终的、最核心的等价关系！**

**比例优势模型中检验组间差异的得分统计量 $U$，恰好等于Wilcoxon秩和统计量 $W_1$ 与其在零假设下期望值的差。**

由于一个统计量减去它的期望值只是一个中心化的线性变换，这并不改变其标准化后的检验结果。因此，基于 $U$ 的得分检验和基于 $W_1$ 的Wilcoxon秩和检验在数学上是**等价的**。

### 3. 为什么这个等价性如此重要？

这个发现不仅仅是一个数学巧合，它揭示了深刻的统计思想：

1.  **模型化的非参数方法**：比例优势模型可以被看作是**对WMW检验的一种模型化、参数化的推广**。WMW检验只能告诉你两组是否有差异，而比例优势模型还能告诉你差异的大小（通过 $\beta$ 的估计值），并且可以加入其他协变量进行调整。
2.  **理论的统一性**：它将看似分离的两个领域——参数模型（广义线性模型）和非参数检验（秩和检验）——完美地统一了起来。这表明，许多经典的非参数方法背后，都隐藏着一个潜在的、可以被参数化的模型。
3.  **稳健性来源的解释**：这个联系也解释了为什么比例优势模型对数据的分布具有稳健性。因为它在本质上是基于数据的**秩**来构建的，所以它继承了WMW检验对异常值和非正态分布的稳健性。

### 总结

得分检验和WMW检验之所以等价，是因为比例优势模型的对数似然函数经过求导和在零假设下简化后，其最终的数学形式**恰好是**Wilcoxon秩和统计量的中心化形式。

*   **WMW检验的核心是：(秩和 - 期望秩和)。**
*   **比例优势模型得分检验的核心也是：(秩和 - 期望秩和)。**

两者是同一枚硬币的两面。您的书中所引用的这个结论，是现代统计学中一个非常经典的例子，它展示了不同统计方法之间内在的、深刻的统一性。





## **有序多分类的得分检验与线性模型有什么不同？**

您提供的步骤非常专业和准确，完美地概述了在广义线性模型（包括有序逻辑回归）中进行得分检验（Score Test，也称为拉格朗日乘子检验，Lagrange Multiplier Test）的通用框架。

现在，我们来回答您的核心问题：**有序多分类的得分检验与线性模型有什么不同？**

答案的核心在于：**检验的理论框架是相同的，但底层的模型和数学细节完全不同。**

线性模型的得分检验（通常表现为 F 检验的特定形式）是这个通用框架在一个非常特殊且简化的场景下的应用。

下面我们从几个关键方面进行详细对比：

---

### 1. 模型结构与假设 (Model Structure & Assumptions)

*   **线性模型 (Linear Model)**:
    *   **模型方程**: $Y = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}$，其中 $\boldsymbol{\epsilon} \sim N(0, \sigma^2)$。
    *   **核心假设**: 因变量是连续的，误差项服从正态分布，且方差恒定。
    *   **似然函数**: 基于**正态分布的概率密度函数**构建。其对数似然函数与残差平方和（RSS）有直接关系：$L \propto -\frac{RSS}{2\sigma^2}$。

*   **有序逻辑回归 (Ordinal Logistic Regression)**:
    *   **模型方程**: $\text{logit} [P(Y \le j)] = \alpha_j - \boldsymbol{\beta}^T \mathbf{X}$。这是一个累积概率模型。
    *   **核心假设**: 因变量是有序分类的。关键的**比例优势假设（Proportional Odds Assumption）**要求自变量 $\mathbf{X}$ 对不同类别界点的影响是相同的（即只有一个 $\boldsymbol{\beta}$ 向量，而不是每个类别界点都有一个 $\boldsymbol{\beta}_j$）。
    *   **似然函数**: 基于**多项分布（Multinomial Distribution）的概率质量函数**构建。计算每个观测值落入其真实类别的概率 $P(Y=k_i | \mathbf{X}_i)$，然后将所有观测值的对数概率相加。这个概率 $P(Y=k_i)$ 是通过两个累积概率相减得到的：$P(Y \le k_i) - P(Y \le k_i - 1)$。

**主要区别**: 线性模型处理连续数据，基于正态分布；有序逻辑回归处理有序分类数据，基于多项分布和累积 Logit 连结函数。这导致了它们的对数似然函数在形式上天差地别。

### 2. 得分向量与信息矩阵的计算 (Calculation of Score & Information)

*   **线性模型**:
    *   由于其对数似然函数与残差平方和的简单关系，其得分向量（一阶导数）和信息矩阵（负二阶导数的期望）有非常简洁的**封闭解（closed-form solution）**。
    *   例如，在检验 $\boldsymbol{\beta}_2 = \mathbf{0}$ 时，得分向量与新变量 $\mathbf{X}_2$ 和零假设模型（只用 $\mathbf{X}_1$）的**残差**相关。信息矩阵与 $\mathbf{X}^T\mathbf{X}$ 和误差方差 $\sigma^2$ 有关。
    *   整个计算可以简化为矩阵代数运算，不涉及迭代。

*   **有序逻辑回归**:
    *   其对数似然函数非常复杂，涉及到对率函数（logistic function）的导数。
    *   得分向量和信息矩阵的计算**没有简单的封闭解**。它们是关于所有观测值和所有类别概率的复杂求和。
    *   计算这些导数需要用到链式法则，涉及到每个观测值属于每个类别的概率，这些概率本身又是模型参数的非线性函数。
    *   在实践中，这些值是通过数值方法在 H₀ 模型的最大似然估计值处计算得到的。

**主要区别**: 线性模型的计算是直接且解析的。有序模型的计算是复杂的、非线性的，并且依赖于在零模型参数估计值处的数值评估。

### 3. 检验统计量 (The Test Statistic)

*   **线性模型**:
    *   通用的得分统计量 $S = U^T I^{-1} U$ 依然适用。
    *   但更常见的是，这个检验可以直接用**残差平方和 (RSS)** 来表示，并最终化简为我们熟悉的 **F 检验** 统计量：
        $$ F = \frac{(RSS_0 - RSS_A) / q}{RSS_A / (n-p)} $$
        其中 $RSS_0$ 是零假设模型（小模型）的残差平方和，$RSS_A$ 是备择假设模型（大模型）的残差平方和，$q$ 是新增变量的个数。
    *   注意：虽然 F 检验通常通过比较两个模型的 RSS 来计算（这看起来更像似然比检验），但它可以被证明与得分检验和瓦尔德检验在代数上是等价的（在特定形式下）。

*   **有序逻辑回归**:
    *   我们**必须**使用通用的二次型公式 $S = U_{\boldsymbol{\beta}_2}^T [I(\tilde{\boldsymbol{\theta}})]^{-1}_{\boldsymbol{\beta}_2 \boldsymbol{\beta}_2} U_{\boldsymbol{\beta}_2}$（这里使用更精确的分块矩阵形式）。
    *   没有像“残差平方和”这样简单的替代品。检验完全依赖于对数似然函数的导数。

**主要区别**: 线性模型的得分检验可以等价地表示为更直观的 F 检验。有序逻辑回归没有这种简化，必须严格按照得分检验的定义进行计算。

### 4. 统计量的分布 (Distribution of the Statistic)

*   **线性模型**:
    *   在误差项服从正态分布的假设下，F 检验统计量在零假设下服从**精确的 F 分布**。这是一个小样本性质，不依赖于样本量 $n \to \infty$。

*   **有序逻辑回归**:
    *   得分统计量 $S$ 在零假设下**渐近服从（asymptotically follows）卡方分布**，自由度为新增变量的个数。
    *   “渐近”意味着这个结论只在大样本情况下才比较准确。对于小样本，卡方分布只是一个近似。

**主要区别**: 线性模型的 F 检验具有精确的有限样本分布。有序模型的得分检验依赖于大样本理论，其卡方分布是一个近似。

### 总结表格

| 特征 | 线性模型 (Score/F Test) | 有序逻辑回归 (Score Test) |
| :--- | :--- | :--- |
| **模型基础** | 正态分布，连续因变量 | 多项分布，有序分类因变量 |
| **核心假设** | 误差正态、独立、同方差 | 比例优势假设 |
| **对数似然函数** | 基于正态 PDF，与残差平方和(RSS)直接相关 | 基于多项 PMF，形式复杂，涉及累积概率 |
| **导数计算** | 简单，有封闭解（矩阵运算） | 复杂，无封闭解，需数值计算 |
| **检验统计量形式** | 可简化为基于 RSS 的 F 统计量 | 必须使用通用二次型 $U^T I^{-1} U$ |
| **统计量分布** | **精确的 F 分布**（小样本性质） | **渐近的卡方分布**（大样本性质） |
| **实际优势** | 理论简洁，有精确的小样本推断 | 框架通用，适用于各类广义线性模型 |

### 结论

您提供的步骤是进行得分检验的**通用“配方”**。

*   对于**有序逻辑回归**，您必须严格遵循这个配方中的每一步，处理复杂的对数似然函数、得分向量和信息矩阵。
*   对于**线性模型**，这个配方同样适用，但由于正态分布的优良数学性质，整个过程可以被大大简化，最终得到我们更熟悉的、基于残差平方和的 F 检验。

因此，可以说，**线性模型的得分检验（F检验）是有序模型得分检验这一通用框架下的一个高度简化和特化的案例**。您对通用框架的理解已经完全到位，并且它足以处理比线性模型复杂得多的有序多分类情况。





## **有序逻辑回归如何构建其似然函数**

好的，这是一个非常核心且巧妙的概念。我们来用一个形象的例子把它彻底讲清楚。

您引用的这段话，解释的是**有序逻辑回归如何构建其似然函数**。这是整个模型拟合（寻找最佳参数）的基础。

我们把它分解开来理解。

### 1. 目标：计算单个观测的概率

假设我们正在预测学生的成绩等级，有五个有序类别：A, B, C, D, F。

我们的模型需要能够回答这样一个问题：对于一个每天学习3小时（$X=3$）的学生，他/她获得 **“C”** 等级的概率是多少？即计算 $P(Y=\text{"C"} | X=3)$。

直接对 $P(Y=\text{"C"})$ 建模很困难，因为我们还需要同时对 $P(Y=\text{"A"})$, $P(Y=\text{"B"})$ 等建模，并且要保证它们之间的顺序关系（A > B > C...），这会非常复杂。

### 2. 巧妙的转换：从“特定等级”到“不高于某个等级”

有序逻辑回归不直接计算 $P(Y=\text{"C"})$，而是走了一条“迂回”但更聪明的路。它转而对**累积概率 (Cumulative Probability)** 进行建模。

它回答的是这些问题：
*   $P(Y \le \text{"A"})$：获得A级或更低等级的概率是多少？(逻辑上是 $P(Y=\text{A})$)
*   $P(Y \le \text{"B"})$：获得B级或更低等级的概率是多少？(即 $P(Y=\text{A 或 B})$)
*   $P(Y \le \text{"C"})$：获得C级或更低等级的概率是多少？(即 $P(Y=\text{A 或 B 或 C})$)
*   $P(Y \le \text{"D"})$：获得D级或更低等级的概率是多少？(即 $P(Y=\text{A 或 B 或 C 或 D})$)

模型的核心方程 `logit[P(Y ≤ j)] = αⱼ - βX` 就是在做这件事。它为每一个“分界点”（A和B之间、B和C之间等）建立了一个概率模型。

### 3. 关键一步：用累积概率相减得到特定概率

现在我们有了计算“不高于某个等级”概率的工具。如何回到我们最初的问题——计算获得特定等级“C”的概率呢？

这里就是“**相减**”的用武之地了。请看这个逻辑：

**获得“C”级的概率 = (获得C级或更低等级的概率) - (获得比C更低等级的概率)**

用数学语言表达就是：
$P(Y = \text{"C"}) = P(Y \le \text{"C"}) - P(Y \le \text{"B"})$

让我们来验证一下：
*   $P(Y \le \text{"C"})$  =  $P(Y=\text{A}) + P(Y=\text{B}) + P(Y=\text{C})$
*   $P(Y \le \text{"B"})$  =  $P(Y=\text{A}) + P(Y=\text{B})$

两者相减：
$[P(Y=\text{A}) + P(Y=\text{B}) + P(Y=\text{C})] - [P(Y=\text{A}) + P(Y=\text{B})] = P(Y=\text{C})$

**完全正确！**

这就是那句话 **“这个概率 $P(Y=k_i)$ 是通过两个累积概率相减得到的：$P(Y \le k_i) - P(Y \le k_i - 1)$”** 的确切含义。

*   $k_i$ 是第 $i$ 个观测值的真实类别（比如“C”）。
*   $k_i-1$ 是比它低一个的类别（比如“B”）。

### 4. 构建整个数据集的似然函数

现在，我们有了计算任何一个学生获得任何特定等级概率的方法。接下来的步骤就很标准了：

1.  **遍历每个观测值**：对于数据集中的第 $i$ 个学生（他/她的学习时长为 $\mathbf{X}_i$，实际成绩为 $y_i$），我们使用上面的方法计算出模型预测他/她获得这个真实成绩的概率 $P(Y=y_i | \mathbf{X}_i)$。

2.  **假设独立性**：我们假设每个学生是独立的。因此，我们观察到整个数据集（所有学生的真实成绩）的联合概率，就是把每个学生的概率乘起来。

    **似然函数 L = $P(\text{学生1}) \times P(\text{学生2}) \times \dots \times P(\text{学生n})$**
    $$ L(\boldsymbol{\alpha}, \boldsymbol{\beta} | \text{Data}) = \prod_{i=1}^{n} P(Y = y_i | \mathbf{X}_i) $$

3.  **取对数**：连乘运算在数学上（尤其是在求导时）非常麻烦。所以我们总是取对数，把连乘变成连加，得到**对数似然函数 (Log-Likelihood)**。

    $$ \ell = \log(L) = \sum_{i=1}^{n} \log[P(Y = y_i | \mathbf{X}_i)] $$
    $$ \ell = \sum_{i=1}^{n} \log[ P(Y \le y_i | \mathbf{X}_i) - P(Y \le y_i-1 | \mathbf{X}_i) ] $$

**最终，模型拟合的过程（比如用梯度下降法）就是去寻找一组参数 $\boldsymbol{\alpha}$ 和 $\boldsymbol{\beta}$，使得这个对数似然函数 $\ell$ 的值达到最大。** 这就是所谓的“最大似然估计”（Maximum Likelihood Estimation, MLE）。

### 总结

所以，您问的“这是什么”，可以总结为：

这是一种**构建有序分类模型似然函数的巧妙策略**。它通过对更容易建模的**累积概率**进行建模，然后利用**概率减法**来计算出我们真正关心的、属于某个特定类别的概率。最后，将所有观测值的对数概率相加，构建出整个模型的目标函数（对数似然函数），以便进行参数估计。







## 有序逻辑回归的得分检验

您提了一个非常棒的问题，直击要害！

确实，有序逻辑回归的对数似然函数非常复杂，包含“对数-差值-logistic函数”的嵌套结构，手动求导和计算简直是天方夜谭。

那么如何进行得分检验呢？答案是：**我们不手动计算，而是依赖计算机按照严格的数学定义进行数值计算。** 整个理论框架不变，只是将繁琐的代数运算交给了软件。

下面我们来拆解这个“计算机如何做到”的过程，这会揭示其背后的数学原理。

### 核心：一切都是可导的

尽管对数似然函数 $\ell(\boldsymbol{\theta})$ 形式复杂，但它是由我们熟悉的基本函数（对数、指数、加减乘除）构成的。这意味着它在数学上是**连续且可微的**。只要一个函数可微，我们就能求出它的一阶导数（得分向量）和二阶导数（信息矩阵）。

我们把这个过程具体化：

#### 1. 定义数学构件

首先，我们需要精确定义模型中的各个部分，这是软件进行计算的基础。
*   **线性预测器**: $\eta_{ij} = \alpha_j - \boldsymbol{\beta}^T \mathbf{X}_i$
    *   $\boldsymbol{\beta}$ 是所有自变量的系数向量，$\boldsymbol{\theta} = (\boldsymbol{\alpha}, \boldsymbol{\beta})$ 是所有参数的集合。
*   **累积概率**: $\pi_{ij} = P(Y_i \le j | \mathbf{X}_i) = \frac{1}{1 + e^{-\eta_{ij}}}$ (这是标准的 a logistic/sigmoid 函数)
*   **类别概率**: $p_{ik} = P(Y_i = k | \mathbf{X}_i) = \pi_{ik} - \pi_{i, k-1}$
*   **对数似然函数** (对单个观测 $i$ 其真实类别为 $k$): $\ell_i = \log(p_{ik}) = \log(\pi_{ik} - \pi_{i, k-1})$
*   **总对数似然函数**: $\ell(\boldsymbol{\theta}) = \sum_{i=1}^{n} \ell_i$

#### 2. 计算得分向量 $U(\boldsymbol{\theta})$ (一阶导数)

得分向量是 $\ell(\boldsymbol{\theta})$ 对每个参数（所有的 $\alpha_j$ 和 $\beta_m$）的偏导数。我们以一个新增变量 $X_{2m}$ 的系数 $\beta_{2m}$ 为例：
$$ U_{\beta_{2m}} = \frac{\partial \ell(\boldsymbol{\theta})}{\partial \beta_{2m}} = \sum_{i=1}^{n} \frac{\partial \ell_i}{\partial \beta_{2m}} $$
为了求这个导数，软件会严格应用**链式法则 (Chain Rule)**：

$$ \frac{\partial \ell_i}{\partial \beta_{2m}} = \underbrace{\frac{\partial \ell_i}{\partial p_{ik}}}_{1} \cdot \underbrace{\frac{\partial p_{ik}}{\partial \pi_{ik}}}_{2} \cdot \underbrace{\frac{\partial \pi_{ik}}{\partial \eta_{ik}}}_{3} \cdot \underbrace{\frac{\partial \eta_{ik}}{\partial \beta_{2m}}}_{4} $$
让我们看看每一步：
1.  $\frac{\partial \log(p_{ik})}{\partial p_{ik}} = \frac{1}{p_{ik}}$
2.  $\frac{\partial (\pi_{ik} - \pi_{i, k-1})}{\partial \pi_{ik}}$ 这一步比较复杂，涉及到 $p_{ik}$ 对其组成部分求导。
3.  $\frac{\partial \pi_{ik}}{\partial \eta_{ik}}$ 是对 logistic 函数求导，结果是 $\pi_{ik}(1-\pi_{ik})$。这是一个非常优美的性质。
4.  $\frac{\partial (\alpha_k - \dots - \beta_{2m}X_{i,2m} - \dots)}{\partial \beta_{2m}} = -X_{i,2m}$

尽管最终的表达式组合起来会非常长，但它是由这些定义清晰的、可计算的部分组成的。

**得分检验的关键一步**：
软件首先拟合零假设模型（不含 $\mathbf{X}_2$），得到估计值 $\tilde{\boldsymbol{\alpha}}$ 和 $\tilde{\boldsymbol{\beta}}_1$。然后，它将这些值和 $\boldsymbol{\beta}_2 = \mathbf{0}$ 代入上面那个长长的导数公式，**数值计算**出得分向量在这一点的值 $U(\tilde{\boldsymbol{\theta}})$。

#### 3. 计算信息矩阵 $I(\boldsymbol{\theta})$ (二阶导数)

信息矩阵需要对对数似然函数求**二阶偏导数**。这意味着要对上面那个已经很长的一阶导数公式再求一次导！

$$ I_{\beta_{2m}, \beta_{2l}} = -E \left[ \frac{\partial^2 \ell(\boldsymbol{\theta})}{\partial \beta_{2m} \partial \beta_{2l}} \right] $$
这在代数上会变得极其复杂，但原理是相同的：**反复应用链式法则和乘积法则**。

在实践中，通常使用**观测信息矩阵 (Observed Information Matrix)**，即直接计算二阶导数在 $\tilde{\boldsymbol{\theta}}$ 处的值，而不是其期望值。对于广义线性模型，这两者通常是等价的。

同样，软件将零假设模型的参数估计值 $\tilde{\boldsymbol{\theta}}$ 代入二阶导数公式中，**数值计算**出信息矩阵 $I(\tilde{\boldsymbol{\theta}})$。

### 实际工作流程总结

当你在R、Python、SAS等软件中请求一个得分检验时，后台发生的事情是这样的：

1.  **第一步：拟合零模型**
    *   你提供公式 `Y ~ X1`。
    *   软件通过迭代算法（如Newton-Raphson）找到最大化 $\ell(\boldsymbol{\alpha}, \boldsymbol{\beta}_1)$ 的参数 $\tilde{\boldsymbol{\alpha}}$ 和 $\tilde{\boldsymbol{\beta}}_1$。

2.  **第二步：执行得分检验**
    *   你要求检验变量 `X2` 的加入是否显著。
    *   软件在内存中构建一个**完整的参数向量** $\tilde{\boldsymbol{\theta}} = (\tilde{\boldsymbol{\alpha}}, \tildeboldsymbol{\beta}_1, \boldsymbol{\beta}_2 = \mathbf{0})$。
    *   软件内部已经**预先编程好了对数似然函数的一阶和二阶导数公式**（就是我们上面通过链式法则推导出的那些复杂公式）。
    *   它将 $\tilde{\boldsymbol{\theta}}$ 和你的数据（$\mathbf{X}_1, \mathbf{X}_2$）代入这些导数公式，**计算出两个数值结果**：
        *   得分向量 $U_{\boldsymbol{\beta}_2}(\tilde{\boldsymbol{\theta}})$（一个向量）。
        *   信息矩阵 $I(\tilde{\boldsymbol{\theta}})$（一个矩阵）。
    *   软件接着执行矩阵运算：$S = U_{\boldsymbol{\beta}_2}^T [I(\tilde{\boldsymbol{\theta}})]^{-1}_{\text{block for }\beta_2} U_{\boldsymbol{\beta}_2}$，得到一个**标量值**（一个数字），即得分统计量。
    *   最后，根据 $\mathbf{X}_2$ 中变量的个数（自由度），从卡方分布中查找 P 值。

### 结论

**对数似然函数的复杂性并没有改变得分检验的理论基础，它只是让手动计算变得不可能。**

这个过程完美地体现了现代统计学的特点：理论框架（如最大似然、得分检验）是普适的，而其在具体模型（如序数逻辑回归）上的应用则依赖于强大的计算能力和数值算法来实现。我们作为使用者，需要理解的是理论框架和每个步骤的**目的**，而将繁琐的微积分和矩阵运算交给经过严格测试的统计软件。








好的，这绝对是一个非常专业且有趣的任务。您提供的 `NullModel` 函数写得很好，它正确地使用了 `ordinal::clm` 来拟合零模型，并返回了完整的模型对象，这是进行后续计算的关键。

您提供的 `Ordinal_exactScore` 函数是基于 **标准广义线性模型 (GLM)** 的得分检验逻辑，它依赖于像 `residuals` 和单一的权重矩阵 `W_mat` 这样的构件。然而，正如我们之前讨论的，**有序逻辑回归模型的内部数学结构要复杂得多**，它没有单一的残差向量或权重矩阵。它的似然函数、得分和信息矩阵的计算涉及到每个观测值在所有 J-1 个类别阈值上的累积概率。

因此，我们需要编写一个**遵循得分检验基本定义**的新函数，直接从 `clm` 对象及其对数似然函数中提取或计算所需的导数信息。

最稳健、最直接的方法是利用数值微分来计算得分向量和信息矩阵，因为从头手动推导和编写这些复杂矩阵的代数形式非常容易出错。我们将使用 `numDeriv` 包来完成这个任务。

---

### 第1步：安装必要的包

如果尚未安装 `numDeriv`，请先安装。

```R
if (!requireNamespace("numDeriv", quietly = TRUE)) {
  install.packages("numDeriv")
}
library(numDeriv)
```

### 第2步：编写新的得分检验函数 `OrdinalScoreTest`

这个函数将严格遵循得分检验的理论步骤：
1.  定义包含新变量（基因型）的**完整模型的对数似然函数**。
2.  在**零模型参数**（即新变量系数为零）处，计算该函数的：
    a.  **梯度 (Gradient)**：这就是得分向量 $U$。
    b.  **海森矩阵 (Hessian)**：这是负信息矩阵 $-I$。
3.  提取与新变量对应的得分向量部分 $U_g$。
4.  计算完整的信息矩阵 $I$，求其逆 $I^{-1}$，并提取与新变量对应的分块 $(I^{-1})_{gg}$。
5.  计算得分统计量 $S = U_g^T (I^{-1})_{gg} U_g$。

```R
# 确保 numDeriv 已加载
library(numDeriv)
library(ordinal)

#' 对有序回归模型进行得分检验
#'
#' @param objNull NullModel() 函数返回的列表，其中包含一个 clm 对象。
#' @param G_mat 一个 N x p_g 的矩阵，其中 N 是样本数，p_g 是要检验的新变量（如基因型）的数量。
#'              行顺序必须与 objNull$sample_ids 匹配。
#' @return 一个包含得分统计量、自由度和P值的列表。
#'
OrdinalScoreTest <- function(objNull, G_mat) {
  
  # --- 1. 准备工作：从零模型对象中提取必要信息 ---
  fit_null <- objNull$fit_clm
  if (!inherits(fit_null, "clm")) {
    stop("objNull$fit_clm is not a valid 'clm' object.")
  }
  
  # 确保 G_mat 是矩阵格式
  if (!is.matrix(G_mat)) {
    G_mat <- as.matrix(G_mat)
  }
  
  # 检查维度是否匹配
  n_samples_model <- nrow(fit_null$model)
  if (nrow(G_mat) != n_samples_model) {
    stop(paste("Mismatch in number of samples. Model has", n_samples_model,
               "samples, but G_mat has", nrow(G_mat), "rows."))
  }
  
  # 零模型中的参数 (alpha 和 beta_cov)
  params_null <- fit_null$coefficients
  p_null <- length(params_null)
  
  # 新增基因型变量的数量
  p_g <- ncol(G_mat)
  
  # 完整模型的参数点 (在 H0 下)
  theta_h0 <- c(params_null, rep(0, p_g))

  # --- 2. 定义完整模型的对数似然函数 ---
  # 这个函数是核心，它计算给定参数下所有观测值的总对数似然
  loglik_ordinal_full <- function(params, y, X_null, G) {
    
    # 分离参数
    alpha_beta_null <- params[1:p_null]
    beta_g <- params[(p_null + 1):(p_null + p_g)]
    
    # 计算线性预测器
    # fit_null$model 包含了用于建模的所有变量
    eta_null <- model.matrix(fit_null) %*% alpha_beta_null
    eta_g <- G %*% beta_g
    
    # 比例优势假设下，beta对所有阈值的影响相同
    # fit_null$alpha 是阈值截距, fit_null$beta 是协变量系数
    # eta 向量需要根据 clm 的内部结构进行构建
    n_alpha <- length(fit_null$alpha)
    eta_full <- eta_null # eta_null 已经包含了 alpha 和 beta_null 的影响
    
    # 将 eta_g 的影响加到非阈值部分
    # clm 的 model.matrix 的前 n_alpha 列是阈值的伪变量
    # 我们只需要将 eta_g 加到协变量效应上
    lin_pred <- eta_full + eta_g

    # 获取累积概率 P(Y <= j)
    # clm link function 是 probit，所以用 pnorm
    # fit_null$Theta 是 alpha 参数
    cum_probs <- pnorm(matrix(fit_null$Theta, nrow = length(y), ncol = n_alpha, byrow = TRUE) - lin_pred)
    
    # 确保概率单调
    cum_probs <- t(apply(cum_probs, 1, function(x) c(0, x, 1)))
    
    # 计算类别概率 P(Y = j) = P(Y <= j) - P(Y <= j-1)
    cat_probs <- t(apply(cum_probs, 1, diff))
    
    # 避免 log(0)
    cat_probs[cat_probs <= 0] <- 1e-100 
    
    # y_idx 是一个 N x J 的矩阵，用于选择每个观测值对应的类别概率
    y_idx <- model.matrix(~ 0 + y)
    
    # 提取每个观测值实际类别的概率
    obs_probs <- rowSums(cat_probs * y_idx)
    
    # 返回总对数似然
    return(sum(log(obs_probs)))
  }

  # --- 3. 使用 numDeriv 计算梯度和海森矩阵 ---
  # 梯度 (得分向量)
  grad_vec <- grad(
    func = loglik_ordinal_full,
    x = theta_h0,
    y = fit_null$y,
    X_null = model.matrix(fit_null),
    G = G_mat
  )
  
  # 海森矩阵 (负信息矩阵)
  hess_mat <- hessian(
    func = loglik_ordinal_full,
    x = theta_h0,
    y = fit_null$y,
    X_null = model.matrix(fit_null),
    G = G_mat
  )
  
  # --- 4. 构建得分检验统计量 ---
  
  # a) 提取与新变量 G 相关的得分向量部分
  # 根据MLE的性质，与零模型参数对应的梯度应接近于0
  U_g <- grad_vec[(p_null + 1):(p_null + p_g)]
  
  # b) 计算信息矩阵的逆，并提取相应分块
  # 信息矩阵 I = -Hessian
  I_full <- -hess_mat
  # 使用广义逆以增加数值稳定性
  I_full_inv <- MASS::ginv(I_full)
  
  I_inv_gg <- I_full_inv[(p_null + 1):(p_null + p_g), (p_null + 1):(p_null + p_g), drop = FALSE]

  # c) 计算得分统计量
  Stest <- as.numeric(t(U_g) %*% I_inv_gg %*% U_g)
  
  # d) 计算 P 值
  p_value <- pchisq(Stest, df = p_g, lower.tail = FALSE)
  
  # --- 5. 返回结果 ---
  return(list(
    Stest = Stest,
    df = p_g,
    p_value = p_value,
    score_vector = U_g
  ))
}
```

