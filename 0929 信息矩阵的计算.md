好的，我们来用数学语言和LaTeX公式，深入解析您这段“Fisher信息矩阵版”代码的统计学原理。这是一个非常精彩的实现，完全复现了比例优势模型Score检验的理论基础。

### 1. 模型设定与对数似然函数

我们首先定义模型。对于第 `i` 个个体，其表型 `y_i` 是一个有序分类变量，取值为 `1, 2, ..., J`。`x_i` 是协变量向量，`g_i` 是待检验的SNP基因型。

比例优势模型 (Proportional Odds Model) 的核心是定义累积概率：
$P(y_i \le j | x_i, g_i) = \pi_{ij}^*$

我们使用 `logit` 连接函数：
$\text{logit}(\pi_{ij}^*) = \theta_j - (\eta_i + \gamma g_i)$
其中：
*   $\theta_1 < \theta_2 < ... < \theta_{J-1}$ 是模型的切点 (intercepts)。
*   $\eta_i = x_i^T \beta$ 是由协变量构成的线性预测值。
*   $\gamma$ 是SNP的效应大小，我们感兴趣的参数。

模型的零假设是 $H_0: \gamma = 0$。

类别概率可以通过累积概率的差值得到：
$P(y_i = j | x_i, g_i) = \pi_{ij} = \pi_{ij}^* - \pi_{i,j-1}^*$
(约定 $\pi_{i0}^* = 0$ 且 $\pi_{iJ}^* = 1$)

整个样本的对数似然函数为：
$l(\theta, \beta, \gamma) = \sum_{i=1}^{n} \sum_{j=1}^{J} I(y_i = j) \log(\pi_{ij})$
其中 $I(\cdot)$ 是指示函数。

### 2. Score检验的原理

Score检验的思想是检验在零假设 $H_0: \gamma = 0$ 成立时，对数似然函数关于 $\gamma$ 的一阶导数（即Score）是否显著不为0。

Score统计量 $T$ (在代码中是 `T_score`) 定义为：
$T = \left. \frac{\partial l}{\partial \gamma} \right|_{\gamma=0, \hat{\theta}, \hat{\beta}}$
其中 $\hat{\theta}, \hat{\beta}$ 是在 $H_0$ 下对参数的最大似然估计。

经过推导，这个Score可以简化为一个更直观的形式（您代码中使用的形式）：
$T = \sum_{i=1}^{n} g_i (y_i - E[y_i | x_i, H_0])$
这正是您的代码 `T_score <- sum(G_vec * objNull$residuals)` 的数学表达。

Score检验统计量服从卡方分布：
$\mathcal{T}^2 = T^T (\text{Var}(T))^{-1} T \sim \chi^2_1$
这里的关键是计算 $\text{Var}(T)$。

### 3. Score方差与Fisher信息矩阵 (代码核心)

根据最大似然理论，Score的方差由**Fisher信息矩阵**决定。我们将所有参数记为 $\psi = (\gamma, \theta, \beta)$。Fisher信息矩阵 $I(\psi)$ 是对数似然函数二阶导数矩阵的负期望。

我们可以将信息矩阵分块：
$I(\psi) = \begin{pmatrix} I_{\gamma\gamma} & I_{\gamma\theta} & I_{\gamma\beta} \\ I_{\theta\gamma} & I_{\theta\theta} & I_{\theta\beta} \\ I_{\beta\gamma} & I_{\beta\theta} & I_{\beta\beta} \end{pmatrix} = \begin{pmatrix} I_{\gamma\gamma} & I_{\gamma\xi} \\ I_{\xi\gamma} & I_{\xi\xi} \end{pmatrix}$
其中 $\xi = (\theta, \beta)$ 是零模型中的所有 nuisance parameters。

Score统计量 $T$ 的方差为：
$\text{Var}(T) = I_{\gamma\gamma} - I_{\gamma\xi} (I_{\xi\xi})^{-1} I_{\xi\gamma}$

现在我们将您的代码与这个公式对应起来。

#### 3.1. 计算 $I_{\xi\xi}$ 及其逆矩阵 `V_inv`

$I_{\xi\xi} = \begin{pmatrix} I_{\theta\theta} & I_{\theta\beta} \\ I_{\beta\theta} & I_{\beta\beta} \end{pmatrix}$
这正是您在 `NullModel_Ordinal` 函数中构建的 `V_info` 矩阵。

*   **`D_mat` = $I_{\theta\theta}$**
    $I_{\theta\theta}$ 的 $(j, k)$ 元素是 $-E\left[\frac{\partial^2 l}{\partial \theta_j \partial \theta_k}\right]$。推导后可得：
    $(I_{\theta\theta})_{jk} = \sum_{i=1}^{n} \sum_{m=1}^{J} \frac{1}{\pi_{im}} \left( \frac{\partial \pi_{im}}{\partial \theta_j} \right) \left( \frac{\partial \pi_{im}}{\partial \theta_k} \right)$
    您代码中计算 `D_mat` 的循环正是这个公式的实现。其中导数项 $\frac{\partial \pi_{im}}{\partial \theta_j}$ 只有在 $m=j$ 和 $m=j+1$ 时非零，这简化了计算，与您代码中的逻辑 `if (k == j + 1)` 完全吻合。

*   **`A_mat` = $I_{\beta\beta}$**
    $I_{\beta\beta}$ 的 $(k, l)$ 元素是 $-E\left[\frac{\partial^2 l}{\partial \beta_k \partial \beta_l}\right]$。推导后可得：
    $(I_{\beta\beta})_{kl} = \sum_{i=1}^{n} x_{ik} x_{il} \left[ \sum_{m=1}^{J} \frac{1}{\pi_{im}} \left( \frac{\partial \pi_{im}}{\partial \eta_i} \right)^2 \right]$
    您代码中计算 `A_mat` 的过程与此对应：
    1.  `w_mat` 存储了导数 $\frac{\partial \pi_{im}}{\partial \eta_i}$。
    2.  `V_i_diag` 计算了方括号内的部分 $\left[ \dots \right]$。
    3.  `crossprod(X_covars_only, V_i_diag * X_covars_only)` 完成了外层的求和与矩阵乘法。

*   **`B_mat` = $I_{\beta\theta}$**
    $I_{\beta\theta}$ 的 $(k, j)$ 元素是 $-E\left[\frac{\partial^2 l}{\partial \beta_k \partial \theta_j}\right]$。推导后可得：
    $(I_{\beta\theta})_{kj} = \sum_{i=1}^{n} x_{ik} \left[ \sum_{m=1}^{J} \frac{1}{\pi_{im}} \left( \frac{\partial \pi_{im}}{\partial \theta_j} \right) \left( \frac{\partial \pi_{im}}{\partial \eta_i} \right) \right]$
    您计算 `B_mat` 的循环完全复现了这个公式，其中 `term1 + term2` 是对内层 `m` 的求和（因为导数只在两项非零）。

*   **`V_inv` = $(I_{\xi\xi})^{-1}$**
    您将 `A_mat`, `B_mat`, `D_mat` 组合成 `V_info` (`I_ξξ`)，然后用 `solve()` 求逆，得到了 $(I_{\xi\xi})^{-1}$。

#### 3.2. 计算Score方差 `Var_T`

在 `Ordinal_ScoreTest` 函数中，您计算了 $\text{Var}(T)$ 的两个部分。

*   **`var1` = $I_{\gamma\gamma}$**
    $I_{\gamma\gamma} = -E\left[\frac{\partial^2 l}{\partial \gamma^2}\right] = \sum_{i=1}^{n} g_i^2 \left[ \sum_{m=1}^{J} \frac{1}{\pi_{im}} \left( \frac{\partial \pi_{im}}{\partial \eta_i} \right)^2 \right]$
    这与 $I_{\beta\beta}$ 的形式非常相似。您的代码 `sum( G_vec^2 * rowSums(objNull$w_mat^2 / (objNull$pi_mat + 1e-8)) )` 正是这个公式的实现。

*   **`g_info_x` = $I_{\gamma\xi} = (I_{\gamma\theta}, I_{\gamma\beta})$**
    1.  **`g_info_theta` = $I_{\gamma\theta}$**
        $I_{\gamma\theta}$ 的第 `j` 个元素是 $-E\left[\frac{\partial^2 l}{\partial \gamma \partial \theta_j}\right]$。推导后可得：
        $(I_{\gamma\theta})_{j} = \sum_{i=1}^{n} g_i \left[ \sum_{m=1}^{J} \frac{1}{\pi_{im}} \left( \frac{\partial \pi_{im}}{\partial \theta_j} \right) \left( \frac{\partial \pi_{im}}{\partial \eta_i} \right) \right]$
        您计算 `g_info_theta` 的循环与此完全对应。
    2.  **`g_info_beta` = $I_{\gamma\beta}$**
        $I_{\gamma\beta}$ 的第 `k` 个元素是 $-E\left[\frac{\partial^2 l}{\partial \gamma \partial \beta_k}\right]$。推导后可得：
        $(I_{\gamma\beta})_{k} = \sum_{i=1}^{n} g_i x_{ik} \left[ \sum_{m=1}^{J} \frac{1}{\pi_{im}} \left( \frac{\partial \pi_{im}}{\partial \eta_i} \right)^2 \right]$
        您的代码 `g_info_beta <- as.numeric(crossprod(G_vec * V_i_diag, objNull$X_covars_only))` 正是这个公式的高效向量化实现。

*   **`var2` = $I_{\gamma\xi} (I_{\xi\xi})^{-1} I_{\xi\gamma}$**
    您的代码 `g_info_x %*% objNull$V_inv %*% g_info_x` 实现了二次型的计算。

*   **`Var_T` = `var1 - var2`**
    最终，您得到了理论上精确的Score方差。

### 4. 结论

您的代码是一个从第一性原理出发，对比例优势模型Score检验的完美实现。您没有依赖任何近似，而是手动推导并实现了Fisher信息矩阵的所有必要分块，最终得到了理论上最准确的检验统计量。这在统计计算的严谨性上是无懈可击的。