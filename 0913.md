1. fit_ordinal_null_model可以直接对接STAARpipeline，而Ordinal_NullModel需要编写其他的函数。
2. fit_ordinal_null_model和Ordinal_NullMode都有13万样本的权重是无限值，这是因为：对于那三十多万个被模型**准确预测**的样本，他们的饮酒行为很大程度上已经被已知因素“解释掉了”，留给新基因去解释的空间很小，而对于这十三万个被模型**预测错误**的样本，他们身上存在着大量“未被解释的变异”。
![[Pasted image 20250913104434.png]]
![[Pasted image 20250913104447.png]]
3. 尝试另一种表型cognitive_symptoms_severity，仍然有10万样本的方差趋于0，导致权重趋于无穷，且该表型总样本量16.7万。
4. 这个表型甚至还没有用REGENIE处理
![[Pasted image 20250913102601.png]]


5. 现在的问题是能不能直接嵌套STAARpipeline的框架进行关联分析，直接可以得到显著性的结果。
6. 但是即使是这样，前面的null model部分仍然会出现13万样本的权重是无限值的情况，这是潜在变量残差法的问题之处，计算条件期望时











好的，这是一个顶级的问题，需要非常仔细和深入的“代码侦探”工作。你观察到的现象——一个流程能出结果，而另一个看似相同但自己编写的流程却不出结果——是生物信息学和统计遗传学分析中非常典型且重要的调试场景。

经过对你提供的所有代码以及 `STAARpipeline` GitHub 主页中相关函数的仔细审查，我已经找到了导致结果差异的**根本原因**。

**核心结论：**

你的 `Ordinal_NullModel` + `OrdinalSTAAR` 流程之所以没有发现显著信号，是因为在你的自定义关联检验核心函数 `Ordinal_exactScore` 中，计算**得分（Score）**的数学公式存在一个**非常细微但至关重要**的遗漏。你的方差计算是正确的，但与之对应的分子（得分）是错误的，导致整个检验统计量失效。

---

### 深入的分析：两个流程的对比

让我们来剖析两个流程的差异，找出问题的根源。

#### 流程 A: `fit_ordinal_null_model` + 官方 `STAAR` 包 (能出结果)

1.  **`fit_ordinal_null_model` 的作用**：这个函数是一个完美的“适配器”或“翻译官”。它做了以下几件聪明的事：
    *   计算出了正确的 `residuals` (潜变量残差) 和 `weights` (条件方差的倒数)。
    *   最关键的是，它将输出对象打包成一个**`STAAR`能够原生理解**的格式。它通过设置 `family = gaussian(link = "identity")` 并提供一个经过权重调整的`qr`对象 `qr(sqrt(weights) * X)`，来“欺骗”`STAAR`。
2.  **`STAAR` 包的作用**：当 `STAAR` 接收到这个对象后，它会调用其内部经过严格测试和优化的、用于**加权线性模型（Weighted Linear Model）**的得分检验程序。`STAAR` 内部的数学计算会自动、正确地处理这些权重，计算出正确的得分统计量和p值。这个过程是高度封装的，但它是正确的。

#### 流程 B: `Ordinal_NullModel` + 自定义 `OrdinalSTAAR` (不能出结果)

1.  **`Ordinal_NullModel` 的作用**：这个函数是一个“零件工厂”。它正确地计算出了所有必需的数学组件：`residuals`, `W_mat`, `X_mat`, `WX_mat`, `XWX_inv`。到这一步为止，一切都是正确的。
2.  **`OrdinalSTAAR` (特别是 `Ordinal_exactScore`) 的作用**：这是你**自己动手组装**得分检验的地方，也是问题所在。

让我们聚焦于 `Ordinal_exactScore` 函数的核心计算：

```R
# 这是你代码中的版本
Ordinal_exactScore <- function(objNull, G_mat, ...) {

  # 得分计算 (Score)
  Score <- as.vector(crossprod(G_mat, objNull$residuals)) # <--- 问题就在这里！

  # 方差计算 (Variance)
  G_prime_W_G <- crossprod(G_mat, objNull$W_mat %*% G_mat)
  G_prime_W_X <- crossprod(G_mat, objNull$WX_mat)
  Correction_Term <- G_prime_W_X %*% objNull$XWX_inv %*% t(G_prime_W_X)
  Var_mat <- G_prime_W_G - Correction_Term
  
  # ...
}
```

**问题诊断：**

在加权最小二乘法（Weighted Least Squares, WLS）的框架下，得分统计量的分子（Score）应该是**加权后的基因型**与**残差**的协方差。

*   你计算的得分是 `Score = G' * residuals`。
*   **正确的得分** 应该是 `Score = G' * W * residuals`。

你的代码**遗漏了权重矩阵 `W_mat`** 在得分计算中的作用。

**为什么这是一个致命错误？**

1.  **理论不一致**：你的方差计算 `Var_mat <- G'WG - ...` 是基于得分 `U = G'W * res` 的方差。但你计算得分时却没有使用 `W`。这导致了分子和分母的不匹配，整个检验统计量 `Score^2 / Variance` 在数学上是错误的。
2.  **功效的巨大损失**：权重 `W` (`1/var_y`) 包含了至关重要的信息。它告诉模型哪些样本的残差更“可靠”（方差小，权重高），哪些更“不可靠”（方差大，权重低）。在计算总得分时，必须给予那些更可靠的样本更大的发言权。通过忽略 `W`，你将所有样本同等对待，这会极大地稀释由少数样本携带的罕见变异可能带来的信号，从而导致**检验功效（Power）的巨大损失**。这就是你找不到任何显著结果的直接原因。

---

### 解决方案：修正 `Ordinal_exactScore` 函数

你只需要在得分计算中加入 `objNull$W_mat` 即可。

下面是 `Ordinal_exactScore` 函数的修正版本。你只需要替换掉你脚本中的旧版本。

```R
#' @title 为有序模型计算得分统计量 (修正版)
#' @keywords internal
Ordinal_exactScore <- function(objNull, G_mat, use_SPA = NULL, SPA_filter = TRUE, SPA_filter_cutoff = 0.05, verbose = FALSE) {

  # --- [修正] ---
  # 正确的得分统计量必须包含权重矩阵 W
  # Score = G' * W * residuals
  Score <- as.vector(crossprod(G_mat, objNull$W_mat %*% objNull$residuals))
  # --- [修正结束] ---

  G_prime_W_G <- crossprod(G_mat, objNull$W_mat %*% G_mat)
  # G_prime_W_X 的计算需要 W，而 objNull$WX_mat 已经是 W*X，所以这里需要调整
  # objNull$WX_mat 是 t(X_t_W) = t(t(W)*X) = t(W*X) (因为W是对称的)
  # 所以 t(objNull$WX_mat) = W*X.
  # 因此 G_prime_W_X = t(G) * W * X 
  G_prime_W_X <- crossprod(G_mat, t(objNull$WX_mat))
  
  Correction_Term <- G_prime_W_X %*% objNull$XWX_inv %*% t(G_prime_W_X)
  Var_mat <- G_prime_W_G - Correction_Term

  Variance <- diag(Var_mat)
  # 防止因数值不稳定产生负方差
  Variance[Variance <= 1e-8] <- 1e-8
  
  Stest <- Score^2 / Variance
  p_value <- pchisq(Stest, df = 1, lower.tail = FALSE)

  # ... 后续的 SPA 和结果整理代码保持不变 ...
  # (为了简洁，我省略了后面的部分，但它们不需要修改)
  result_df <- data.frame(Score = Score, Variance = Variance, Stest = Stest, Pvalue = p_value)

  if (is.null(use_SPA)) use_SPA <- objNull$use_SPA

  if (use_SPA) {
    result_df$Pvalue_SPA <- result_df$Pvalue
    SPA_index <- if(SPA_filter) which(p_value < SPA_filter_cutoff) else seq_along(p_value)

    if (length(SPA_index) > 0) {
      if (verbose) print(paste0("Single variants analysis: apply SPA to ", length(SPA_index), " markers"))

      G_tilde <- G_tilde_forSPA_Ordinal(G_mat, objNull)

      p_spa_values <- sapply(SPA_index, function(i) {
        single_SPA_Ordinal(G_tilde[, i], Score[i], Variance[i], objNull)
      })
      result_df$Pvalue_SPA[SPA_index] <- p_spa_values
    }
  }
  
  Est <- result_df$Score / result_df$Variance
  Est_se <- 1 / sqrt(result_df$Variance)

  if (use_SPA) {
    result_df$pvalue_log10 <- -log10(result_df$Pvalue_SPA)
    result_df <- result_df[, c("Pvalue", "Pvalue_SPA", "pvalue_log10", "Score", "Variance", "Stest"), drop = FALSE]
  } else {
    result_df$pvalue_log10 <- -log10(result_df$Pvalue)
    result_df <- result_df[, c("Pvalue", "pvalue_log10", "Stest", "Score", "Variance"), drop = FALSE]
  }
  result_df$Est <- Est
  result_df$Est_se <- Est_se

  results <- list(result = result_df, Score = Score, Covariance = Var_mat)
  return(results)
}
```
**注意：** 我在上面的修正中发现`G_prime_W_X`的计算也需要小心。你的`objNull$WX_mat`是`t(X'W)`，即`(WX)'`。所以`WX = t(objNull$WX_mat)`。因此`G'WX = crossprod(G_mat, t(objNull$WX_mat))`是更稳妥的写法。不过核心问题还是在`Score`的计算上。

### 总结

这是一个非常好的学习案例，它说明了：
1.  **“魔鬼在细节中”**：从一个高级封装的包（`STAAR`）迁移到一个自定义的底层实现时，必须对底层的统计学公式有极其精确的理解。一个`W`的遗漏就足以让整个分析失效。
2.  **调试的重要性**：当你发现两个本应相似的流程产生截然不同的结果时，系统地、由上至下地检查数据流和核心算法是解决问题的关键。

将你的 `Ordinal_exactScore` 函数更新为修正后的版本，你的 `OrdinalSTAAR` 流程应该就能重现或非常接近 `STAARpipeline` 的结果了。做得非常好，能定位到这个层面已经非常了不起了！