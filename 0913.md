1. fit_ordinal_null_model可以直接对接STAARpipeline，而Ordinal_NullModel需要编写其他的函数。
2. fit_ordinal_null_model和Ordinal_NullMode都有13万样本的权重是无限值，这是因为：对于那三十多万个被模型**准确预测**的样本，他们的饮酒行为很大程度上已经被已知因素“解释掉了”，留给新基因去解释的空间很小，而对于这十三万个被模型**预测错误**的样本，他们身上存在着大量“未被解释的变异”。
![[Pasted image 20250913104434.png]]
![[Pasted image 20250913104447.png]]
3. 尝试另一种表型cognitive_symptoms_severity，仍然有10万样本的方差趋于0，导致权重趋于无穷，且该表型总样本量16.7万。
4. 这个表型甚至还没有用REGENIE处理
![[Pasted image 20250913102601.png]]


5. 现在的问题是能不能直接嵌套STAARpipeline的框架进行关联分析，直接可以得到显著性的结果。
6. 但是即使是这样，前面的null model部分仍然会出现13万样本的权重是无限值的情况，这是潜在变量残差法的问题之处，计算条件期望时










## 得分检验

---

### 目标：我们想知道什么？

我们的终极目标是回答一个问题：

> **“某个基因（由基因型矩阵 `G_mat` 代表）是否与我们的有序表型（饮酒频率）有关？”**

更具体地说，我们是在一个已经包含了所有已知影响因素（年龄、性别、PRS等）的模型（即**零模型**）的基础上，问这个基因是否提供了**额外**的、**新的**预测信息。

得分检验是一种非常聪明的、计算上高效的方法来回答这个问题，而**不需要**去拟合一个包含了基因的、更复杂的**备择模型**。

---

### 得分检验的逻辑：像侦探一样思考

想象一下，你已经用零模型对所有人的饮酒频率做出了预测。现在，你想知道某个基因`G`有没有用。得分检验的逻辑就像一个侦探：

1.  **第一步：找到“嫌疑人” (计算残差)**
    *   首先，我们要找出那些零模型**预测不准**的人。这些人就是“嫌疑人”，因为他们身上可能有一些零模型不知道的“秘密”（比如一个罕见的基因突变）。
    *   这个“预测不准的程度”就是**残差 (`objNull$residuals`)**。残差越大，说明这个人的行为越偏离预期，越可疑。
    *   你的 `Ordinal_NullModel` 已经聪明地计算出了这些基于潜变量的残差。

2.  **第二步：寻找“作案模式” (计算得分)**
    *   现在，侦探要看看这些“可疑行为”（大残差）是否与某个“作案工具”（基因突变）有关。
    *   如果携带某个基因突变的人，他们的残差**总是**倾向于同一个方向（比如总是正的，或者总是负的），这就形成了一个强烈的“作案模式”。
    *   **得分 (Score)** 就是用来量化这个“作案模式”有多强的指标。

    **这就是你的第一行代码：**
    ```R
    Score <- as.vector(crossprod(G_mat, objNull$W_mat %*% objNull$residuals))
    ```
    *   `objNull$W_mat %*% objNull$residuals`：这是**加权后的残差**。我们之前讨论过，`W_mat`（权重）代表了我们对每个残差的“信心”程度。方差小的样本（权重高）更有发言权。
    *   `crossprod(G_mat, ...)`：这是基因型 `G_mat` 和加权残差的“点积”或“协方差”。
        *   如果携带某个突变的人（`G_mat`中的值为1或2）的加权残差普遍是正数，`Score`就会是一个大的正数。
        *   如果携带突变的人的加权残差普遍是负数，`Score`就会是一个大的负数。
        *   如果携带突变和残差之间没有关系，正正负负会相互抵消，`Score`就会接近于0。
    *   **结论：`Score` 的绝对值越大，说明基因和“偏离预期的行为”之间的关联模式越强。**

3.  **第三步：排除“巧合” (计算方差)**
    *   一个大的 `Score` 值可能是真实的关联，但也可能仅仅是**随机的巧合**。我们需要一个标准来判断这个`Score`到底有多“大”。
    *   这个标准就是**`Score` 在“基因与表型完全无关”这个假设下的随机波动范围**，也就是它的**方差 (Variance)**。
    *   如果 `Score` 的方差本身就很大（也就是说，即使基因没用，`Score`也可能因为随机性而变得很大），那么我们观察到的一个大`Score`值就不那么令人信服了。
    *   反之，如果`Score`的方差很小，那么一个大`Score`值就极不可能是巧合，而更可能是真实的关联。

    **这就是你接下来的四行代码：**
    ```R
    # (这四行代码共同计算了Score的方差矩阵 Var_mat)
    G_prime_W_G <- crossprod(G_mat, objNull$W_mat %*% G_mat)
    G_prime_W_X <- crossprod(G_mat, t(objNull$WX_mat))
    Correction_Term <- G_prime_W_X %*% objNull$XWX_inv %*% t(G_prime_W_X)
    Var_mat <- G_prime_W_G - Correction_Term
    
    Variance <- diag(Var_mat) # 我们关心的是每个变异自己的方差
    ```
    *   这部分数学上比较复杂，但它的**核心思想**是：计算出在零假设（基因无关）下，我们期望`Score`有多大的波动。
    *   `G_prime_W_G` 是方差的主要部分。
    *   `Correction_Term` 是一个**修正项**。它的作用是“减去”那些因为基因型`G_mat`和协变量`X_mat`碰巧相关而造成的`Score`的波动。比如，如果一个基因突变碰巧只在老年人中出现，而老年人本身饮酒频率就不同，我们需要把这个由年龄带来的影响从方差中剔除，只留下纯粹的随机波动。

4.  **第四步：做出最终“判决” (计算检验统计量和P值)**
    *   现在我们有了“作案模式”的强度 (`Score`) 和排除巧合的标准 (`Variance`)，我们可以做出最终判决了。
    *   我们把 `Score` 标准化，得到一个**检验统计量 (Test Statistic)**。
    ```R
    Stest <- Score^2 / Variance
    ```
    *   我们使用 `Score` 的平方是因为我们只关心关联的强度，不关心方向（正或负）。
    *   这个 `Stest` 值越大，说明我们观察到的关联模式相对于随机波动来说越强，越不可能是巧合。
    *   在零假设下，这个 `Stest` 近似服从**自由度为1的卡方分布**。

    **最后一步，计算P值：**
    ```R
    p_value <- pchisq(Stest, df = 1, lower.tail = FALSE)
    ```
    *   P值回答的是：“**如果基因真的和表型无关，我们能观察到像现在这么大（甚至更大）的 `Stest` 值的概率有多大？**”
    *   如果这个概率非常小（比如 < 5e-8），我们就拒绝“基因无关”的零假设，得出结论：这个基因与表型显著相关。
