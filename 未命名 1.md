# --- Step 0: 加载所有需要的库和函数 ---

library(ordinal)  
library(Matrix)  
library(data.table)  
library(dplyr)

# ==============================================================================

# 粘贴您的 NullModel (潜在变量版)

# ==============================================================================

NullModel <- function(phenofile, outcomeCol, sampleCol,  
covCol = NULL, PRSCol = NULL, LOCO = TRUE, chr = NULL,  
use_SPA = FALSE, range=c(-100,100), length.out = 1e4, verbose = FALSE) {

# --- Part 1: Load and Prepare Phenotype Data ---

if (!is.null(phenofile)) {  
if (is.character(phenofile)) {  
if (!file.exists(phenofile)) stop("Phenotype file does not exist!")  
use_data <- as.data.frame(data.table::fread(phenofile, data.table = FALSE))  
} else {  
use_data <- as.data.frame(phenofile)  
}  
# 使用 dplyr::select 来安全地选择列  
all_cols <- c(sampleCol, outcomeCol, covCol, PRSCol)  
use_data <- use_data %>% select(all_of(all_cols)) %>% na.omit()  
} else {  
stop("You must provide the phenotype data via the 'phenofile' argument.")  
}

use_data[[sampleCol]] <- as.character(use_data[[sampleCol]])

# ... Genotype matching part (omitted for this simulation) ...

# --- Part 3: Dynamic Formula Construction ---

if (!is.ordered(use_data[[outcomeCol]])) {  
use_data[[outcomeCol]] <- as.ordered(use_data[[outcomeCol]])  
}

all_covars_final <- c(covCol, PRSCol)  
if (is.null(all_covars_final) || length(all_covars_final) == 0) {  
formula_string <- paste0("", outcomeCol, " ~ 1")  
} else {  
safe_covars <- paste0("", all_covars_final, "")  
formula_string <- paste0("", outcomeCol, " ~ ", paste(safe_covars, collapse = " + "))  
}  
formula_null <- as.formula(formula_string)

# --- Part 4: Fit the Ordinal Null Model (Using probit link) ---

message("Fitting the ordinal null model using ordinal::clm with probit link...")  
clm_obj <- ordinal::clm(formula = formula_null, data = use_data, link = "probit", model = TRUE)  
if(verbose) print(summary(clm_obj ))

# --- Part 5: Calculate Residuals and Variance Components ---

model_data <- clm_obj$model  
sample_ids <- use_data[[sampleCol]][as.numeric(rownames(model_data))]

# 确保系数和设计矩阵对齐

X_mat <- model.matrix(object = formula(clm_obj ), data = model_data)

eta <- rep(0, nrow(X_mat))  
if(length(clm_obj

beta), drop = FALSE] %*% clm_obj$beta)  
}

thresholds <- c(-Inf, clm_obj

        `alpha,Inf)yidx<−as.numeric(clmobjalpha, Inf) y_idx <- as.numeric(clm_objalpha,Inf)yi​dx<−as.numeric(clmo​bj`
      

y)

lower_b <- thresholds[y_idx] - eta  
upper_b <- thresholds[y_idx + 1] - eta

# 增加数值稳定性

prob_interval <- pnorm(upper_b) - pnorm(lower_b)  
prob_interval[prob_interval < 1e-100] <- 1e-100

residuals <- (dnorm(lower_b) - dnorm(upper_b)) / prob_interval

term1 <- (lower_b * dnorm(lower_b) - upper_b * dnorm(upper_b)) / prob_interval  
var_y_raw <- 1 + term1 - residuals^2

is_problematic <- !is.finite(var_y_raw) | var_y_raw < 1e-8  
num_problematic <- sum(is_problematic)  
var_y <- var_y_raw  
if (num_problematic > 0) {  
median_var_y <- median(var_y[!is_problematic], na.rm = TRUE)  
if (!is.finite(median_var_y) || median_var_y < 1e-8) { median_var_y <- 1 }  
warning(paste0(num_problematic, " sample(s) had near-zero variance; reset to median (", signif(median_var_y, 4), ")."))  
var_y[is_problematic] <- median_var_y  
}

W_mat <- Diagonal(x = var_y) # 使用 Var(y) 作为权重  
X_t_W <- crossprod(X_mat, W_mat)  
XWX_mat <- X_t_W %*% X_mat  
XWX_inv <- solve(XWX_mat)  
WX_mat <- t(X_t_W)

# --- Part 6: Assemble the Final List ---

fit_null <- list(  
residuals = residuals,  
sample_ids = sample_ids,  
W_mat = W_mat, # W = Diag(Var(y))  
X_mat = X_mat,  
WX_mat = WX_mat,  
XWX_inv = XWX_inv,  
clm_fit = clm_obj, # for comparison  
use_SPA = use_SPA  
)

message("Ordinal null model fitting complete.")  
return(fit_null)  
}

# ==============================================================================

# 粘贴 ScoreTest_Latent 函数

# ==============================================================================

ScoreTest_Latent <- function(null_model_fit, G_vec) {  
if (length(G_vec) != length(null_model_fit$sample_ids)) {  
stop("Length of G_vec does not match the number of samples in the null model.")  
}

residuals <- null_model_fit

        `residualsWmat<−nullmodelfitresiduals W_mat <- null_model_fitresidualsWm​at<−nullm​odelf​it`
      

W_mat  
X_mat <- null_model_fit

        `XmatXWXinv<−nullmodelfitX_mat XWX_inv <- null_model_fitXm​atXWXi​nv<−nullm​odelf​it`
      

XWX_inv

# T = G' * r (在 probit 模型中，权重已隐含在残差定义中)

T_score <- sum(G_vec * residuals)

# Var(T) = G'WG - (G'WX)(X'WX)^-1(X'WG)

# W_mat = Diagonal(var_y), so G'WG is correct.

G_t_W_X <- crossprod(G_vec, null_model_fit$WX_mat)  
G_t_W_G <- as.numeric(crossprod(G_vec, W_mat %% G_vec))  
var_component <- G_t_W_X %% XWX_inv %*% t(G_t_W_X)  
Var_T <- G_t_W_G - as.numeric(var_component)

if (is.na(Var_T) || Var_T <= 1e-8) {  
z_stat <- 0  
p_value <- 1.0  
} else {  
z_stat <- T_score / sqrt(Var_T)  
p_value <- 2 * pnorm(abs(z_stat), lower.tail = FALSE)  
}

return(list(  
T_score = T_score,  
Var_T = Var_T,  
z_stat = z_stat,  
p_value = p_value  
))  
}

# ==============================================================================

# 运行 Simulation

# ==============================================================================

# --- Step 1: 生成模拟数据 (与之前相同，但使用 Probit link 生成) ---

cat("--- Step 1: Generating Simulation Data (for Probit Model) ---\n\n")  
set.seed(123)  
n_samples <- 2000  
J_categories <- 4

# ... (协变量和SNP生成代码不变) ...

cov1 <- rnorm(n_samples)  
maf_causal <- 0.20  
maf_null <- 0.01  
SNP_causal <- rbinom(n_samples, 2, maf_causal)  
SNP_null <- rbinom(n_samples, 2, maf_null)  
beta_cov1 <- 0.5  
gamma_causal <- 0.4  
gamma_null <- 0.0  
linear_pred <- cov1 * beta_cov1 + SNP_causal * gamma_causal + SNP_null * gamma_null

# 使用与 Probit 匹配的阈值

true_intercepts <- qnorm(c(0.3, 0.6, 0.85))

# 生成潜在变量 y*

y_star <- linear_pred + rnorm(n_samples)

# 根据阈值生成观测变量 y

phenotype_ord <- cut(y_star, breaks = c(-Inf, true_intercepts, Inf), labels = 1:J_categories)

sim_data <- data.frame(  
sampleID = paste0("ID_", 1:n_samples),  
phenotype = factor(phenotype_ord, ordered = TRUE),  
cov1 = cov1,  
SNP_causal = SNP_causal,  
SNP_null = SNP_null  
)

# --- Step 2: 拟合零模型 ---

cat("--- Step 2: Fitting the Latent Variable Null Model ---\n\n")  
null_model_fit <- NullModel(  
phenofile = sim_data,  
outcomeCol = "phenotype",  
sampleCol = "sampleID",  
covCol = "cov1",  
verbose = TRUE  
)

# --- Step 3: 执行 Score 检验 ---

cat("\n--- Step 3: Performing Score Tests ---\n\n")  
model_samples <- null_model_fit

sampleID %in% model_samples, "SNP_causal"]  
aligned_G_null <- sim_data[sim_data$sampleID %in% model_samples, "SNP_null"]

cat("Testing Causal SNP:\n")  
score_result_causal <- ScoreTest_Latent(null_model_fit, aligned_G_causal)  
print(score_result_causal)

cat("\nTesting Null SNP:\n")  
score_result_null <- ScoreTest_Latent(null_model_fit, aligned_G_null)  
print(score_result_null)

# --- Step 4: 结果验证 ---

cat("\n--- Step 4: Verifying with Wald Tests ---\n\n")  
cat("Fitting full model for Causal SNP...\n")  
full_model_causal <- ordinal::clm(phenotype ~ cov1 + SNP_causal, data = sim_data, link = "probit", Hess = TRUE)  
p_wald_causal <- summary(full_model_causal)

p_value, "\n")

cat("\nFitting full model for Null SNP...\n")  
full_model_null <- ordinal::clm(phenotype ~ cov1 + SNP_null, data = sim_data, link = "probit", Hess = TRUE)  
p_wald_null <- summary(full_model_null)

p_value, "\n")

# install.packages(c("ordinal", "data.table", "Matrix"))

library(ordinal)  
library(data.table)  
library(Matrix)

# ==============================================================================

# Step 1: 拟合 Null Model (POLMM的固定效应部分)

# 这个函数的作用是拟合 Y ~ Covariates 模型，并预计算Score检验所需的所有组件。

# 这完全等价于POLMM在没有随机效应时的第一步。

# ==============================================================================

NullModel_Ordinal <- function(phenofile, outcomeCol, sampleCol,  
covCol = NULL, PRSCol = NULL, verbose = FALSE) {

# --- 数据准备 (与POLMM类似) ---

if (is.character(phenofile)) {  
if (!file.exists(phenofile)) stop("Phenotype file does not exist!")  
use_data <- as.data.frame(data.table::fread(phenofile, data.table = FALSE))  
} else {  
use_data <- as.data.frame(phenofile)  
}

# ... (您的数据清洗和dummy variable转换代码保持不变, 这部分是标准操作) ...

# For brevity, I'm assuming the dummy variable part is the same as your original code

all_cols_to_check <- c(sampleCol, outcomeCol, covCol, PRSCol)  
cols_exist <- all_cols_to_check[all_cols_to_check %in% colnames(use_data)]  
use_data <- use_data[, cols_exist, drop=FALSE]  
use_data <- use_data[complete.cases(use_data), ]  
rownames(use_data) <- use_data[[sampleCol]]

if (!is.ordered(use_data[[outcomeCol]])) {  
use_data[[outcomeCol]] <- as.ordered(use_data[[outcomeCol]])  
}

all_covars_final <- c(covCol, PRSCol)  
if (is.null(all_covars_final) || length(all_covars_final) == 0) {  
formula_string <- paste0("", outcomeCol, " ~ 1")  
} else {  
safe_covars <- paste0("", all_covars_final, "")  
formula_string <- paste0("", outcomeCol, " ~ ", paste(safe_covars, collapse = " + "))  
}  
formula_null <- as.formula(formula_string)

# --- 核心：拟合固定效应比例优势模型 ---

# 使用 ordinal::clm，这是R中进行此类分析的标准方法。

# POLMM的复杂拟合算法(PQL/AI-REML)在 τ=0 时理论上会收敛到这个结果。

message("Fitting the fixed-effects ordinal null model using ordinal::clm...")  
clm_obj <- ordinal::clm(formula = formula_null, data = use_data, model = TRUE, link="logit")  
if(verbose) print(summary(clm_obj))

# --- 预计算Score检验组件 (与POLMM逻辑一致) ---

message("Pre-computing components for the score test...")

model_data <- clm_obj

        `modelsampleids<−rownames(modeldata)n<−clmobjmodel sample_ids <- rownames(model_data) n <- clm_objmodelsamplei​ds<−rownames(modeld​ata)n<−clmo​bj`
      

n  
J <- length(clm_obj$y.levels)

# y: 观测到的序数表型 (数值形式, 1, 2, ..., J)

y_numeric <- as.numeric(clm_obj$y)

# E[y]: 在null model下的期望值

# Var[y]: 在null model下的方差 (这是权重 W)

# y - E[y]: 残差 (这是 r)

# fitted() 函数可以直接从clm对象中获得每个类别的预测概率

fitted_probs <- fitted(clm_obj)  
y_levels_numeric <- 1:J  
expected_y <- as.numeric(fitted_probs %*% y_levels_numeric)  
residuals <- y_numeric - expected_y

expected_y_sq <- as.numeric(fitted_probs %*% (y_levels_numeric^2))  
weights <- expected_y_sq - (expected_y^2)

# 防止权重过小导致数值不稳定

eps <- 1e-8  
weights[weights < eps] <- eps

# X: 包含截距和协变量的设计矩阵

X_mat <- model.matrix(formula(clm_obj), data = model_data)

# 预计算 (X'WX)^-1，这是Score检验方差计算中最耗时的部分

# 在GWAS中，这一步只需要做一次

W_mat_diag <- Diagonal(x = weights)  
X_t_W <- crossprod(X_mat, W_mat_diag)  
XWX_mat <- X_t_W %*% X_mat  
XWX_inv <- solve(XWX_mat)

# --- 组装返回对象 ---

objNull <- list(  
residuals = residuals, # 残差 r = y - E[y]  
W_diag = weights, # 对角权重矩阵 W = Var(y)  
sample_ids = sample_ids,  
X_mat = X_mat, # 设计矩阵 X  
X_t_W_X_inv = XWX_inv # 预计算的 (X'WX)^-1  
)

message("Fixed-effects ordinal null model fitting complete.")  
return(objNull)  
}

# ==============================================================================

# Step 2: 执行 Score 检验 (POLMM的Score Test简化版)

# 这个函数对每个遗传变异 G 计算Score统计量和p值。

# 它使用的是正态近似，是POLMM使用的鞍点近似(SPA)的简化版本。

# ==============================================================================

Ordinal_ScoreTest <- function(objNull, G_vec) {

# --- 从Null Model对象中提取预计算好的组件 ---

residuals_eff <- objNull

        `residualsWdiagval<−objNullresiduals W_diag_val <- objNullresidualsWd​iagv​al<−objNull`
      

W_diag  
X_mat <- objNull

        `XmatXWXinv<−objNullX_mat XWX_inv <- objNullXm​atXWXi​nv<−objNull`
      

X_t_W_X_inv

# --- 计算Score统计量 T ---

# T = G' * r = G' * W * r (因为 W*r = r)

T_score <- sum(G_vec * residuals_eff)

# --- 计算Score统计量的方差 Var(T) ---

# Var(T) = G'WG - (G'WX)(X'WX)⁻¹(X'WG)

G_t_W <- W_diag_val * G_vec  
G_t_W_X <- crossprod(G_t_W, X_mat)  
G_t_W_G <- sum(G_t_W * G_vec)

var_component <- G_t_W_X %% XWX_inv %% t(G_t_W_X)  
Var_T <- as.numeric(G_t_W_G - var_component)

# --- 计算Z-score和p值 (正态近似) ---

if (is.na(Var_T) || Var_T <= 1e-8) {  
Z_stat <- 0  
p_value <- 1.0  
} else {  
Z_stat <- T_score / sqrt(Var_T)  
p_value <- 2 * pnorm(abs(Z_stat), lower.tail = FALSE)  
}

return(list(  
T_score = as.numeric(T_score),  
Var_T = as.numeric(Var_T),  
Z_stat = as.numeric(Z_stat),  
p_value = as.numeric(p_value)  
))  
}  
那这两个零模型哪一个更好